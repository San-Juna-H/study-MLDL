{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Introduction\n","\n","based on : https://github.com/bentrevett/pytorch-sentiment-analysis\n","\n","one-layer RNN Classifier with IMDB datasets\n","used custom RNN"]},{"cell_type":"markdown","metadata":{},"source":["# 0. Set Environment"]},{"cell_type":"code","execution_count":133,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T05:51:20.087127Z","iopub.status.busy":"2024-05-09T05:51:20.086594Z","iopub.status.idle":"2024-05-09T05:51:20.094575Z","shell.execute_reply":"2024-05-09T05:51:20.092979Z","shell.execute_reply.started":"2024-05-09T05:51:20.087090Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n","import torchtext\n","torchtext.disable_torchtext_deprecation_warning()\n","from torchtext.data import get_tokenizer\n","from torchtext.vocab import build_vocab_from_iterator\n","from torch.utils.tensorboard import SummaryWriter\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","from pprint import pprint\n","\n","import subprocess\n","import os\n","import sys\n","\n","import datasets"]},{"cell_type":"code","execution_count":134,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T04:33:02.055460Z","iopub.status.busy":"2024-05-09T04:33:02.055071Z","iopub.status.idle":"2024-05-09T04:33:02.061661Z","shell.execute_reply":"2024-05-09T04:33:02.060618Z","shell.execute_reply.started":"2024-05-09T04:33:02.055426Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Selected device: cuda\n"]}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(\"Selected device:\", device)"]},{"cell_type":"code","execution_count":135,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T04:33:02.063226Z","iopub.status.busy":"2024-05-09T04:33:02.062835Z","iopub.status.idle":"2024-05-09T04:33:02.076477Z","shell.execute_reply":"2024-05-09T04:33:02.075456Z","shell.execute_reply.started":"2024-05-09T04:33:02.063197Z"},"trusted":true},"outputs":[],"source":["seed = 42\n","\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)\n","torch.backends.cudnn.deterministic = True"]},{"cell_type":"code","execution_count":136,"metadata":{},"outputs":[],"source":["model_dir = './models/Custom_RNN_Classifier_model.pth'\n","pretrained_embedding_dir = './models/Glove_pretrained.pth'"]},{"cell_type":"markdown","metadata":{},"source":["# 1. Data processing"]},{"cell_type":"markdown","metadata":{},"source":["## 1-1. Get Data"]},{"cell_type":"code","execution_count":137,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T04:33:02.087466Z","iopub.status.busy":"2024-05-09T04:33:02.087111Z","iopub.status.idle":"2024-05-09T04:33:08.436868Z","shell.execute_reply":"2024-05-09T04:33:08.435884Z","shell.execute_reply.started":"2024-05-09T04:33:02.087440Z"},"trusted":true},"outputs":[],"source":["train_data, test_data = datasets.load_dataset(\"imdb\", split=[\"train\", \"test\"])"]},{"cell_type":"code","execution_count":138,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T04:33:08.438998Z","iopub.status.busy":"2024-05-09T04:33:08.438560Z","iopub.status.idle":"2024-05-09T04:33:08.444485Z","shell.execute_reply":"2024-05-09T04:33:08.443340Z","shell.execute_reply.started":"2024-05-09T04:33:08.438942Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataset({\n","    features: ['text', 'label'],\n","    num_rows: 25000\n","}) Dataset({\n","    features: ['text', 'label'],\n","    num_rows: 25000\n","})\n"]}],"source":["print(train_data, test_data)"]},{"cell_type":"code","execution_count":139,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T04:33:08.446093Z","iopub.status.busy":"2024-05-09T04:33:08.445726Z","iopub.status.idle":"2024-05-09T04:33:08.458119Z","shell.execute_reply":"2024-05-09T04:33:08.456858Z","shell.execute_reply.started":"2024-05-09T04:33:08.446065Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{'label': 0,\n"," 'text': 'I rented I AM CURIOUS-YELLOW from my video store because of all the '\n","         'controversy that surrounded it when it was first released in 1967. I '\n","         'also heard that at first it was seized by U.S. customs if it ever '\n","         'tried to enter this country, therefore being a fan of films '\n","         'considered \"controversial\" I really had to see this for myself.<br '\n","         '/><br />The plot is centered around a young Swedish drama student '\n","         'named Lena who wants to learn everything she can about life. In '\n","         'particular she wants to focus her attentions to making some sort of '\n","         'documentary on what the average Swede thought about certain '\n","         'political issues such as the Vietnam War and race issues in the '\n","         'United States. In between asking politicians and ordinary denizens '\n","         'of Stockholm about their opinions on politics, she has sex with her '\n","         'drama teacher, classmates, and married men.<br /><br />What kills me '\n","         'about I AM CURIOUS-YELLOW is that 40 years ago, this was considered '\n","         'pornographic. Really, the sex and nudity scenes are few and far '\n","         \"between, even then it's not shot like some cheaply made porno. While \"\n","         'my countrymen mind find it shocking, in reality sex and nudity are a '\n","         'major staple in Swedish cinema. Even Ingmar Bergman, arguably their '\n","         'answer to good old boy John Ford, had sex scenes in his films.<br '\n","         '/><br />I do commend the filmmakers for the fact that any sex shown '\n","         'in the film is shown for artistic purposes rather than just to shock '\n","         'people and make money to be shown in pornographic theaters in '\n","         'America. I AM CURIOUS-YELLOW is a good film for anyone wanting to '\n","         'study the meat and potatoes (no pun intended) of Swedish cinema. But '\n","         \"really, this film doesn't have much of a plot.\"}\n"]}],"source":["pprint(train_data[0])"]},{"cell_type":"markdown","metadata":{},"source":["## 1-2. Tokenize"]},{"cell_type":"code","execution_count":140,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T04:33:12.928637Z","iopub.status.busy":"2024-05-09T04:33:12.928257Z","iopub.status.idle":"2024-05-09T04:33:12.934105Z","shell.execute_reply":"2024-05-09T04:33:12.933039Z","shell.execute_reply.started":"2024-05-09T04:33:12.928609Z"},"trusted":true},"outputs":[],"source":["tokenizer = get_tokenizer(\"basic_english\")"]},{"cell_type":"code","execution_count":141,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T04:33:13.937339Z","iopub.status.busy":"2024-05-09T04:33:13.936963Z","iopub.status.idle":"2024-05-09T04:33:13.943484Z","shell.execute_reply":"2024-05-09T04:33:13.942206Z","shell.execute_reply.started":"2024-05-09T04:33:13.937311Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["['hello',\n"," 'world',\n"," '!',\n"," 'how',\n"," 'are',\n"," 'you',\n"," 'doing',\n"," 'today',\n"," '?',\n"," 'i',\n"," \"'\",\n"," 'm',\n"," 'doing',\n"," 'fantastic',\n"," '!']\n"]}],"source":["pprint(tokenizer(\"Hello world! How are you doing today? I'm doing fantastic!\"))"]},{"cell_type":"code","execution_count":142,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T04:33:17.496593Z","iopub.status.busy":"2024-05-09T04:33:17.495530Z","iopub.status.idle":"2024-05-09T04:33:17.500898Z","shell.execute_reply":"2024-05-09T04:33:17.500118Z","shell.execute_reply.started":"2024-05-09T04:33:17.496548Z"},"trusted":true},"outputs":[],"source":["def tokenize_example(example, tokenizer, max_length):\n","    tokens = tokenizer(example[\"text\"])[:max_length]\n","    length = len(tokens)\n","    return {\"tokens\": tokens, \"length\": length}"]},{"cell_type":"code","execution_count":143,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T04:33:18.079017Z","iopub.status.busy":"2024-05-09T04:33:18.076194Z","iopub.status.idle":"2024-05-09T04:33:18.092531Z","shell.execute_reply":"2024-05-09T04:33:18.091640Z","shell.execute_reply.started":"2024-05-09T04:33:18.078945Z"},"trusted":true},"outputs":[],"source":["max_length = 256\n","\n","train_data = train_data.map(\n","    tokenize_example, fn_kwargs={\"tokenizer\": tokenizer, \"max_length\": max_length}\n",")\n","test_data = test_data.map(\n","    tokenize_example, fn_kwargs={\"tokenizer\": tokenizer, \"max_length\": max_length}\n",")"]},{"cell_type":"code","execution_count":144,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T04:33:19.985437Z","iopub.status.busy":"2024-05-09T04:33:19.982307Z","iopub.status.idle":"2024-05-09T04:33:19.991178Z","shell.execute_reply":"2024-05-09T04:33:19.990103Z","shell.execute_reply.started":"2024-05-09T04:33:19.985384Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataset({\n","    features: ['text', 'label', 'tokens', 'length'],\n","    num_rows: 25000\n","}) Dataset({\n","    features: ['text', 'label', 'tokens', 'length'],\n","    num_rows: 25000\n","})\n"]}],"source":["print(train_data, test_data)"]},{"cell_type":"code","execution_count":145,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T04:33:22.231214Z","iopub.status.busy":"2024-05-09T04:33:22.230795Z","iopub.status.idle":"2024-05-09T04:33:22.239807Z","shell.execute_reply":"2024-05-09T04:33:22.238731Z","shell.execute_reply.started":"2024-05-09T04:33:22.231178Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{'label': 0,\n"," 'length': 256,\n"," 'text': 'I rented I AM CURIOUS-YELLOW from my video store because of all the '\n","         'controversy that surrounded it when it was first released in 1967. I '\n","         'also heard that at first it was seized by U.S. customs if it ever '\n","         'tried to enter this country, therefore being a fan of films '\n","         'considered \"controversial\" I really had to see this for myself.<br '\n","         '/><br />The plot is centered around a young Swedish drama student '\n","         'named Lena who wants to learn everything she can about life. In '\n","         'particular she wants to focus her attentions to making some sort of '\n","         'documentary on what the average Swede thought about certain '\n","         'political issues such as the Vietnam War and race issues in the '\n","         'United States. In between asking politicians and ordinary denizens '\n","         'of Stockholm about their opinions on politics, she has sex with her '\n","         'drama teacher, classmates, and married men.<br /><br />What kills me '\n","         'about I AM CURIOUS-YELLOW is that 40 years ago, this was considered '\n","         'pornographic. Really, the sex and nudity scenes are few and far '\n","         \"between, even then it's not shot like some cheaply made porno. While \"\n","         'my countrymen mind find it shocking, in reality sex and nudity are a '\n","         'major staple in Swedish cinema. Even Ingmar Bergman, arguably their '\n","         'answer to good old boy John Ford, had sex scenes in his films.<br '\n","         '/><br />I do commend the filmmakers for the fact that any sex shown '\n","         'in the film is shown for artistic purposes rather than just to shock '\n","         'people and make money to be shown in pornographic theaters in '\n","         'America. I AM CURIOUS-YELLOW is a good film for anyone wanting to '\n","         'study the meat and potatoes (no pun intended) of Swedish cinema. But '\n","         \"really, this film doesn't have much of a plot.\",\n"," 'tokens': ['i',\n","            'rented',\n","            'i',\n","            'am',\n","            'curious-yellow',\n","            'from',\n","            'my',\n","            'video',\n","            'store',\n","            'because',\n","            'of',\n","            'all',\n","            'the',\n","            'controversy',\n","            'that',\n","            'surrounded',\n","            'it',\n","            'when',\n","            'it',\n","            'was',\n","            'first',\n","            'released',\n","            'in',\n","            '1967',\n","            '.',\n","            'i',\n","            'also',\n","            'heard',\n","            'that',\n","            'at',\n","            'first',\n","            'it',\n","            'was',\n","            'seized',\n","            'by',\n","            'u',\n","            '.',\n","            's',\n","            '.',\n","            'customs',\n","            'if',\n","            'it',\n","            'ever',\n","            'tried',\n","            'to',\n","            'enter',\n","            'this',\n","            'country',\n","            ',',\n","            'therefore',\n","            'being',\n","            'a',\n","            'fan',\n","            'of',\n","            'films',\n","            'considered',\n","            'controversial',\n","            'i',\n","            'really',\n","            'had',\n","            'to',\n","            'see',\n","            'this',\n","            'for',\n","            'myself',\n","            '.',\n","            'the',\n","            'plot',\n","            'is',\n","            'centered',\n","            'around',\n","            'a',\n","            'young',\n","            'swedish',\n","            'drama',\n","            'student',\n","            'named',\n","            'lena',\n","            'who',\n","            'wants',\n","            'to',\n","            'learn',\n","            'everything',\n","            'she',\n","            'can',\n","            'about',\n","            'life',\n","            '.',\n","            'in',\n","            'particular',\n","            'she',\n","            'wants',\n","            'to',\n","            'focus',\n","            'her',\n","            'attentions',\n","            'to',\n","            'making',\n","            'some',\n","            'sort',\n","            'of',\n","            'documentary',\n","            'on',\n","            'what',\n","            'the',\n","            'average',\n","            'swede',\n","            'thought',\n","            'about',\n","            'certain',\n","            'political',\n","            'issues',\n","            'such',\n","            'as',\n","            'the',\n","            'vietnam',\n","            'war',\n","            'and',\n","            'race',\n","            'issues',\n","            'in',\n","            'the',\n","            'united',\n","            'states',\n","            '.',\n","            'in',\n","            'between',\n","            'asking',\n","            'politicians',\n","            'and',\n","            'ordinary',\n","            'denizens',\n","            'of',\n","            'stockholm',\n","            'about',\n","            'their',\n","            'opinions',\n","            'on',\n","            'politics',\n","            ',',\n","            'she',\n","            'has',\n","            'sex',\n","            'with',\n","            'her',\n","            'drama',\n","            'teacher',\n","            ',',\n","            'classmates',\n","            ',',\n","            'and',\n","            'married',\n","            'men',\n","            '.',\n","            'what',\n","            'kills',\n","            'me',\n","            'about',\n","            'i',\n","            'am',\n","            'curious-yellow',\n","            'is',\n","            'that',\n","            '40',\n","            'years',\n","            'ago',\n","            ',',\n","            'this',\n","            'was',\n","            'considered',\n","            'pornographic',\n","            '.',\n","            'really',\n","            ',',\n","            'the',\n","            'sex',\n","            'and',\n","            'nudity',\n","            'scenes',\n","            'are',\n","            'few',\n","            'and',\n","            'far',\n","            'between',\n","            ',',\n","            'even',\n","            'then',\n","            'it',\n","            \"'\",\n","            's',\n","            'not',\n","            'shot',\n","            'like',\n","            'some',\n","            'cheaply',\n","            'made',\n","            'porno',\n","            '.',\n","            'while',\n","            'my',\n","            'countrymen',\n","            'mind',\n","            'find',\n","            'it',\n","            'shocking',\n","            ',',\n","            'in',\n","            'reality',\n","            'sex',\n","            'and',\n","            'nudity',\n","            'are',\n","            'a',\n","            'major',\n","            'staple',\n","            'in',\n","            'swedish',\n","            'cinema',\n","            '.',\n","            'even',\n","            'ingmar',\n","            'bergman',\n","            ',',\n","            'arguably',\n","            'their',\n","            'answer',\n","            'to',\n","            'good',\n","            'old',\n","            'boy',\n","            'john',\n","            'ford',\n","            ',',\n","            'had',\n","            'sex',\n","            'scenes',\n","            'in',\n","            'his',\n","            'films',\n","            '.',\n","            'i',\n","            'do',\n","            'commend',\n","            'the',\n","            'filmmakers',\n","            'for',\n","            'the',\n","            'fact',\n","            'that',\n","            'any',\n","            'sex',\n","            'shown',\n","            'in',\n","            'the',\n","            'film',\n","            'is']}\n"]}],"source":["pprint(train_data[0])"]},{"cell_type":"markdown","metadata":{},"source":["## 1-3. Build Vocab "]},{"cell_type":"code","execution_count":146,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T04:33:50.933785Z","iopub.status.busy":"2024-05-09T04:33:50.933393Z","iopub.status.idle":"2024-05-09T04:33:57.179373Z","shell.execute_reply":"2024-05-09T04:33:57.178242Z","shell.execute_reply.started":"2024-05-09T04:33:50.933754Z"},"trusted":true},"outputs":[],"source":["min_freq = 5\n","special_tokens = [\"<unk>\", \"<pad>\"]\n","\n","vocab = build_vocab_from_iterator(train_data['tokens'],\n","                                  min_freq = min_freq,\n","                                  specials = special_tokens)"]},{"cell_type":"code","execution_count":147,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T04:34:23.087226Z","iopub.status.busy":"2024-05-09T04:34:23.086817Z","iopub.status.idle":"2024-05-09T04:34:23.092281Z","shell.execute_reply":"2024-05-09T04:34:23.091119Z","shell.execute_reply.started":"2024-05-09T04:34:23.087194Z"},"trusted":true},"outputs":[],"source":["unk_index = vocab[\"<unk>\"]\n","pad_index = vocab[\"<pad>\"]\n","\n","vocab.set_default_index(unk_index)"]},{"cell_type":"code","execution_count":148,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T04:34:19.316350Z","iopub.status.busy":"2024-05-09T04:34:19.315940Z","iopub.status.idle":"2024-05-09T04:34:19.321833Z","shell.execute_reply":"2024-05-09T04:34:19.320775Z","shell.execute_reply.started":"2024-05-09T04:34:19.316319Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["24897\n"]}],"source":["print(len(vocab))"]},{"cell_type":"code","execution_count":149,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T04:34:31.160191Z","iopub.status.busy":"2024-05-09T04:34:31.158981Z","iopub.status.idle":"2024-05-09T04:34:31.165946Z","shell.execute_reply":"2024-05-09T04:34:31.164645Z","shell.execute_reply.started":"2024-05-09T04:34:31.160142Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["0 1\n"]}],"source":["print(unk_index, pad_index)"]},{"cell_type":"markdown","metadata":{},"source":["## 1-4. Numericalize Text"]},{"cell_type":"code","execution_count":150,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T04:41:08.959882Z","iopub.status.busy":"2024-05-09T04:41:08.958858Z","iopub.status.idle":"2024-05-09T04:41:08.964755Z","shell.execute_reply":"2024-05-09T04:41:08.963746Z","shell.execute_reply.started":"2024-05-09T04:41:08.959844Z"},"trusted":true},"outputs":[],"source":["def numericalize_example(example, vocab):\n","    ids = vocab.lookup_indices(example[\"tokens\"])\n","    return {\"ids\": ids}"]},{"cell_type":"code","execution_count":151,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T04:41:09.115654Z","iopub.status.busy":"2024-05-09T04:41:09.115293Z","iopub.status.idle":"2024-05-09T04:42:03.364867Z","shell.execute_reply":"2024-05-09T04:42:03.363650Z","shell.execute_reply.started":"2024-05-09T04:41:09.115628Z"},"trusted":true},"outputs":[],"source":["train_data = train_data.map(numericalize_example, fn_kwargs={\"vocab\": vocab})\n","test_data = test_data.map(numericalize_example, fn_kwargs={\"vocab\": vocab})"]},{"cell_type":"code","execution_count":152,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T04:44:34.503457Z","iopub.status.busy":"2024-05-09T04:44:34.502345Z","iopub.status.idle":"2024-05-09T04:44:34.511254Z","shell.execute_reply":"2024-05-09T04:44:34.510035Z","shell.execute_reply.started":"2024-05-09T04:44:34.503402Z"},"trusted":true},"outputs":[],"source":["train_data = train_data.with_format(type=\"torch\", columns=[\"ids\", \"label\", \"length\"])\n","test_data = test_data.with_format(type=\"torch\", columns=[\"ids\", \"label\", \"length\"])"]},{"cell_type":"code","execution_count":153,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T04:44:35.730619Z","iopub.status.busy":"2024-05-09T04:44:35.730222Z","iopub.status.idle":"2024-05-09T04:44:35.735753Z","shell.execute_reply":"2024-05-09T04:44:35.734458Z","shell.execute_reply.started":"2024-05-09T04:44:35.730587Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataset({\n","    features: ['text', 'label', 'tokens', 'length', 'ids'],\n","    num_rows: 25000\n","}) Dataset({\n","    features: ['text', 'label', 'tokens', 'length', 'ids'],\n","    num_rows: 25000\n","})\n"]}],"source":["print(train_data, test_data)"]},{"cell_type":"code","execution_count":154,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T04:44:38.108447Z","iopub.status.busy":"2024-05-09T04:44:38.107826Z","iopub.status.idle":"2024-05-09T04:44:38.118189Z","shell.execute_reply":"2024-05-09T04:44:38.117021Z","shell.execute_reply.started":"2024-05-09T04:44:38.108413Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["{'ids': tensor([   12,  1242,    12,   220,     0,    44,    61,   362,  1035,    90,\n","            7,    37,     2,  7142,    15,  3319,    11,    60,    11,    17,\n","           80,   569,    13,  7559,     3,    12,    99,   508,    15,    38,\n","           80,    11,    17, 24372,    40,  1095,     3,    16,     3, 10340,\n","           52,    11,   125,   747,     8,  2389,    14,   644,     4,  1644,\n","          123,     5,   314,     7,   116,  1121,  3029,    12,    68,    72,\n","            8,    73,    14,    21,   496,     3,     2,   114,    10,  5778,\n","          195,     5,   182,  3517,   442,  1306,   726,  5178,    42,   509,\n","            8,   865,   293,    63,    59,    47,   126,     3,    13,   859,\n","           63,   509,     8,  1157,    51, 11838,     8,   263,    55,   457,\n","            7,   606,    27,    54,     2,   811,     0,   190,    47,   805,\n","         1045,  1284,   145,    19,     2,  2353,   331,     6,  1506,  1284,\n","           13,     2,  2238,  1530,     3,    13,   215,  2240,  6937,     6,\n","         1940, 16877,     7, 18793,    47,    77,  4485,    27,  2307,     4,\n","           63,    50,   405,    20,    51,   442,  1537,     4,  6999,     4,\n","            6,   979,   366,     3,    54,  1150,    75,    47,    12,   220,\n","            0,    10,    15,  1577,   152,   529,     4,    14,    17,  1121,\n","         9576,     3,    68,     4,     2,   405,     6,   973,   150,    30,\n","          175,     6,   244,   215,     4,    67,   103,    11,     9,    16,\n","           29,   351,    45,    55,  5867,    97,  4098,     3,   147,    61,\n","        22993,   357,   171,    11,  1636,     4,    13,   664,   405,     6,\n","          973,    30,     5,   648,  9633,    13,  3517,   437,     3,    67,\n","        14400,  4202,     4,  4150,    77,  1583,     8,    57,   165,   407,\n","          291,  1933,     4,    72,   405,   150,    13,    32,   116,     3,\n","           12,    93, 14971,     2,  1078,    21,     2,   202,    15,   110,\n","          405,   628,    13,     2,    23,    10]),\n"," 'label': tensor(0),\n"," 'length': tensor(256)}\n"]}],"source":["pprint(train_data[0])"]},{"cell_type":"markdown","metadata":{},"source":["## 1-5. Word Embedding"]},{"cell_type":"code","execution_count":155,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T04:47:01.763729Z","iopub.status.busy":"2024-05-09T04:47:01.763352Z","iopub.status.idle":"2024-05-09T05:01:19.461687Z","shell.execute_reply":"2024-05-09T05:01:19.457096Z","shell.execute_reply.started":"2024-05-09T04:47:01.763701Z"},"trusted":true},"outputs":[],"source":["if not os.path.exists(pretrained_embedding_dir):\n","    vectors = torchtext.vocab.GloVe()\n","    pretrained_embedding = vectors.get_vecs_by_tokens(vocab.get_itos())\n","    torch.save(pretrained_embedding, pretrained_embedding_dir)\n","else:\n","    pretrained_embedding = torch.load(pretrained_embedding_dir)"]},{"cell_type":"code","execution_count":156,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T06:07:50.700769Z","iopub.status.busy":"2024-05-09T06:07:50.700280Z","iopub.status.idle":"2024-05-09T06:07:50.706472Z","shell.execute_reply":"2024-05-09T06:07:50.705381Z","shell.execute_reply.started":"2024-05-09T06:07:50.700733Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([24897, 300])\n"]}],"source":["print(pretrained_embedding.size())"]},{"cell_type":"markdown","metadata":{},"source":["## 1-6. Prepare for Data Loading"]},{"cell_type":"code","execution_count":157,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T06:32:36.896177Z","iopub.status.busy":"2024-05-09T06:32:36.894792Z","iopub.status.idle":"2024-05-09T06:32:36.902278Z","shell.execute_reply":"2024-05-09T06:32:36.901112Z","shell.execute_reply.started":"2024-05-09T06:32:36.896132Z"},"trusted":true},"outputs":[],"source":["class CustomDataset(Dataset):\n","    def __init__(self, data):\n","        self.data = data\n","    \n","    def __len__(self):\n","        return len(self.data)\n","    \n","    def __getitem__(self, idx):\n","        item = self.data[idx]\n","        return item"]},{"cell_type":"code","execution_count":158,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T06:32:37.040510Z","iopub.status.busy":"2024-05-09T06:32:37.040090Z","iopub.status.idle":"2024-05-09T06:32:37.046037Z","shell.execute_reply":"2024-05-09T06:32:37.044861Z","shell.execute_reply.started":"2024-05-09T06:32:37.040475Z"},"trusted":true},"outputs":[],"source":["train_dataset = CustomDataset(train_data)\n","test_dataset = CustomDataset(test_data)"]},{"cell_type":"code","execution_count":159,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T06:32:37.192543Z","iopub.status.busy":"2024-05-09T06:32:37.191817Z","iopub.status.idle":"2024-05-09T06:32:37.198607Z","shell.execute_reply":"2024-05-09T06:32:37.197333Z","shell.execute_reply.started":"2024-05-09T06:32:37.192501Z"},"trusted":true},"outputs":[],"source":["def custom_collate_fn(batch):\n","    \n","    batch_inputs = [sample['ids'] for sample in batch]\n","    batch_labels = [sample['label'] for sample in batch]\n","    \n","    collate_inputs = pad_sequence(batch_inputs, \n","                                  padding_value = pad_index, \n","                                  batch_first = True)\n","    collate_labels = torch.tensor(batch_labels)\n","    \n","    return collate_inputs, collate_labels"]},{"cell_type":"code","execution_count":160,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T06:32:37.329915Z","iopub.status.busy":"2024-05-09T06:32:37.328765Z","iopub.status.idle":"2024-05-09T06:32:37.336910Z","shell.execute_reply":"2024-05-09T06:32:37.335768Z","shell.execute_reply.started":"2024-05-09T06:32:37.329870Z"},"trusted":true},"outputs":[],"source":["batch_size = 128\n","pad_index = pad_index\n","shuffle = True\n","\n","trainloader = DataLoader(dataset = train_dataset,\n","                         batch_size = batch_size,\n","                         collate_fn = custom_collate_fn,\n","                         shuffle = shuffle)\n","testloader = DataLoader(dataset = test_dataset,\n","                         batch_size = batch_size,\n","                         collate_fn = custom_collate_fn,\n","                         shuffle = shuffle)"]},{"cell_type":"markdown","metadata":{},"source":["# 2. Define Model"]},{"cell_type":"markdown","metadata":{},"source":["## 2-1. Model Structure"]},{"cell_type":"code","execution_count":161,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T06:33:20.701605Z","iopub.status.busy":"2024-05-09T06:33:20.700381Z","iopub.status.idle":"2024-05-09T06:33:20.708647Z","shell.execute_reply":"2024-05-09T06:33:20.707310Z","shell.execute_reply.started":"2024-05-09T06:33:20.701564Z"},"trusted":true},"outputs":[],"source":["class CustomRNNCell(nn.Module):\n","    def __init__(self, input_dim, hidden_dim):\n","        super().__init__()\n","        self.input_dim = input_dim\n","        self.hidden_dim = hidden_dim\n","\n","        self.Wi = nn.Linear(input_dim + hidden_dim, hidden_dim)\n","        \n","    def forward(self, inputs, hidden):\n","        h = hidden\n","        concat_ih = torch.cat((inputs,h), 1)\n","\n","        h = self.Wi(concat_ih)\n","        \n","        return h"]},{"cell_type":"code","execution_count":162,"metadata":{},"outputs":[],"source":["class CustomRNN(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, num_layers):\n","        super().__init__()\n","        self.hidden_dim = hidden_dim\n","        self.num_layer = num_layers\n","        self.Layers = nn.ModuleList([CustomRNNCell(input_dim, hidden_dim)])\n","        for _ in range(1, num_layers):\n","            self.Layers.append(CustomRNNCell(hidden_dim, hidden_dim))\n","\n","    def forward(self, inputs, hidden):\n","        \n","        batch_size = inputs.size(0)\n","        seq_length = inputs.size(1)\n","\n","        h0 = hidden\n","\n","        output_h = torch.zeros(self.num_layers, batch_size, seq_length, self.hidden_dim).to(device)\n","\n","        for layer_idx, layer in enumerate(self.Layers):\n","\n","            if layer_idx == 0:\n","                layer_inputs = inputs\n","            else:\n","                layer_inputs = output_h[layer_idx - 1, :, :, :]\n","            \n","            h = h0[layer_idx, : :]\n","            for t in range(seq_length):\n","                h = layer(layer_inputs[:, t, :], h)\n","                output_h[layer_idx, :, t, :] = h\n","\n","        return output_h[-1, :, :, :], output_h[:, :, -1, :]"]},{"cell_type":"code","execution_count":163,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T06:33:20.862529Z","iopub.status.busy":"2024-05-09T06:33:20.862120Z","iopub.status.idle":"2024-05-09T06:33:20.873691Z","shell.execute_reply":"2024-05-09T06:33:20.872514Z","shell.execute_reply.started":"2024-05-09T06:33:20.862497Z"},"trusted":true},"outputs":[],"source":["class CustomRNNClassifier(nn.Module):\n","    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, num_layers, pad_index):\n","        super().__init__()\n","        self.embedding_dim = embedding_dim\n","        self.hidden_dim = hidden_dim\n","        self.output_dim = output_dim\n","        self.num_layers = num_layers\n","        \n","        self.embedding = nn.Embedding(input_dim, embedding_dim, padding_idx = pad_index)\n","        self.embedding.requires_grad_(False)\n","\n","        self.rnn = CustomRNN(embedding_dim, hidden_dim, num_layers)\n","\n","        self.fc = nn.Linear(hidden_dim, output_dim)\n","\n","    def forward(self, inputs):\n","\n","        batch_size = inputs.size(0)\n","        \n","        x = self.embedding(inputs)\n","        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(device)\n","\n","        output, h = self.rnn(x, h0)\n","\n","        logit = self.fc(h[-1, :, :])\n","\n","        return logit"]},{"cell_type":"markdown","metadata":{},"source":["## 2-2. Hyperparameter & functions"]},{"cell_type":"code","execution_count":164,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T06:33:21.025116Z","iopub.status.busy":"2024-05-09T06:33:21.024663Z","iopub.status.idle":"2024-05-09T06:33:21.111777Z","shell.execute_reply":"2024-05-09T06:33:21.110479Z","shell.execute_reply.started":"2024-05-09T06:33:21.025080Z"},"trusted":true},"outputs":[],"source":["vocab_size = len(vocab)\n","embedding_dim = 300\n","hidden_dim = 128\n","num_layers = 1\n","output_dim = 1\n","pad_index = pad_index\n","lr = 5e-4\n","\n","model = CustomRNNClassifier(vocab_size, embedding_dim, hidden_dim, output_dim, num_layers, pad_index)\n","\n","criterion = nn.BCEWithLogitsLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr)"]},{"cell_type":"markdown","metadata":{},"source":["## 2-3. Weight Initialization"]},{"cell_type":"code","execution_count":165,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T06:33:21.345375Z","iopub.status.busy":"2024-05-09T06:33:21.344933Z","iopub.status.idle":"2024-05-09T06:33:21.352661Z","shell.execute_reply":"2024-05-09T06:33:21.351278Z","shell.execute_reply.started":"2024-05-09T06:33:21.345343Z"},"trusted":true},"outputs":[],"source":["def initialize_weights(m):\n","    if isinstance(m, nn.Linear):\n","        nn.init.xavier_normal_(m.weight)\n","        nn.init.zeros_(m.bias)\n","    elif isinstance(m, CustomRNNCell):\n","        for name, param in m.named_parameters():\n","            if \"bias\" in name:\n","                nn.init.zeros_(param)\n","            elif \"Wi\" in name:\n","                nn.init.orthogonal_(param)"]},{"cell_type":"code","execution_count":166,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T06:33:21.522657Z","iopub.status.busy":"2024-05-09T06:33:21.522278Z","iopub.status.idle":"2024-05-09T06:33:21.532722Z","shell.execute_reply":"2024-05-09T06:33:21.531867Z","shell.execute_reply.started":"2024-05-09T06:33:21.522629Z"},"trusted":true},"outputs":[{"data":{"text/plain":["CustomRNNClassifier(\n","  (embedding): Embedding(24897, 300, padding_idx=1)\n","  (rnn): CustomRNN(\n","    (Layers): ModuleList(\n","      (0): CustomRNNCell(\n","        (Wi): Linear(in_features=428, out_features=128, bias=True)\n","      )\n","      (1-2): 2 x CustomRNNCell(\n","        (Wi): Linear(in_features=256, out_features=128, bias=True)\n","      )\n","    )\n","  )\n","  (fc): Linear(in_features=128, out_features=1, bias=True)\n",")"]},"execution_count":166,"metadata":{},"output_type":"execute_result"}],"source":["model.apply(initialize_weights)"]},{"cell_type":"code","execution_count":167,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T06:33:21.675452Z","iopub.status.busy":"2024-05-09T06:33:21.674714Z","iopub.status.idle":"2024-05-09T06:33:21.679695Z","shell.execute_reply":"2024-05-09T06:33:21.678909Z","shell.execute_reply.started":"2024-05-09T06:33:21.675417Z"},"trusted":true},"outputs":[],"source":["model.embedding.weight.data = pretrained_embedding"]},{"cell_type":"code","execution_count":168,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\"Model's state_dict:\"\n","Parameter name: embedding.weight\n","    Size : torch.Size([24897, 300])\n","    Value: Parameter containing:\n","tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [ 0.2720, -0.0620, -0.1884,  ...,  0.1302, -0.1832,  0.1323],\n","        ...,\n","        [ 0.6701, -0.2717,  0.4766,  ...,  0.2786,  0.3312,  0.0230],\n","        [-0.1503,  0.5624, -0.5622,  ..., -0.4224, -0.6836,  0.0726],\n","        [ 1.1741, -0.4386,  0.3310,  ...,  0.3193, -0.2292, -0.0887]])\n","Parameter name: rnn.Layers.0.Wi.weight\n","    Size : torch.Size([128, 428])\n","    Value: Parameter containing:\n","tensor([[ 0.0305, -0.0240,  0.0291,  ..., -0.0672,  0.0179,  0.0439],\n","        [-0.0524,  0.0628,  0.0119,  ...,  0.0646, -0.0570,  0.0005],\n","        [ 0.0324, -0.1108, -0.0452,  ..., -0.0172,  0.0443, -0.0367],\n","        ...,\n","        [ 0.0388,  0.0423,  0.0163,  ..., -0.1018, -0.0417, -0.0136],\n","        [ 0.0046, -0.0277,  0.1003,  ..., -0.0173,  0.0160, -0.0136],\n","        [-0.0793,  0.0156, -0.0557,  ..., -0.0109,  0.0188,  0.0069]],\n","       requires_grad=True)\n","Parameter name: rnn.Layers.0.Wi.bias\n","    Size : torch.Size([128])\n","    Value: Parameter containing:\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n","Parameter name: rnn.Layers.1.Wi.weight\n","    Size : torch.Size([128, 256])\n","    Value: Parameter containing:\n","tensor([[-0.0846,  0.0274, -0.0961,  ..., -0.0451,  0.0184, -0.1245],\n","        [-0.0826, -0.0249, -0.0488,  ...,  0.0851,  0.1123,  0.0179],\n","        [ 0.1287, -0.1014,  0.0832,  ..., -0.0885,  0.0342,  0.0494],\n","        ...,\n","        [-0.0194,  0.1266, -0.0833,  ...,  0.0202,  0.1116,  0.0209],\n","        [-0.0786, -0.0095,  0.0143,  ...,  0.0474,  0.0045, -0.1812],\n","        [-0.0731,  0.1758,  0.1220,  ..., -0.0349, -0.0320,  0.0815]],\n","       requires_grad=True)\n","Parameter name: rnn.Layers.1.Wi.bias\n","    Size : torch.Size([128])\n","    Value: Parameter containing:\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n","Parameter name: rnn.Layers.2.Wi.weight\n","    Size : torch.Size([128, 256])\n","    Value: Parameter containing:\n","tensor([[-0.0989,  0.0138,  0.0197,  ...,  0.0395, -0.0272,  0.0094],\n","        [ 0.0071,  0.0372,  0.0608,  ..., -0.0148, -0.0454, -0.0030],\n","        [ 0.0065, -0.0409, -0.0325,  ..., -0.0078,  0.0299,  0.0408],\n","        ...,\n","        [-0.0605,  0.0486, -0.0391,  ...,  0.0453,  0.0251,  0.0291],\n","        [-0.0671, -0.0293,  0.0087,  ...,  0.0581, -0.0687,  0.0248],\n","        [ 0.0108, -0.0002,  0.0580,  ...,  0.0784, -0.0007, -0.0410]],\n","       requires_grad=True)\n","Parameter name: rnn.Layers.2.Wi.bias\n","    Size : torch.Size([128])\n","    Value: Parameter containing:\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n","Parameter name: fc.weight\n","    Size : torch.Size([1, 128])\n","    Value: Parameter containing:\n","tensor([[-0.0243,  0.1225, -0.1640,  0.0851,  0.1508,  0.2279,  0.2114, -0.1111,\n","          0.1938,  0.0949, -0.0120,  0.1787, -0.1600,  0.0329,  0.1397,  0.0795,\n","         -0.1223, -0.1341, -0.1071, -0.0837, -0.0981,  0.0059, -0.0785, -0.1533,\n","         -0.2239, -0.1003,  0.1892, -0.0090,  0.0582,  0.2240, -0.1640, -0.1306,\n","          0.1029, -0.0456, -0.1170,  0.2036, -0.0337, -0.0769, -0.1554, -0.0011,\n","          0.0484,  0.1183, -0.0192, -0.1174, -0.0752, -0.1989, -0.1213,  0.1695,\n","         -0.2595, -0.0173,  0.2432, -0.0381,  0.1187,  0.0163, -0.1627, -0.1027,\n","         -0.1421,  0.0044,  0.0619,  0.0058, -0.0729,  0.0545,  0.3212,  0.1300,\n","          0.3290, -0.1144, -0.1476, -0.0679, -0.2141, -0.0844, -0.2055, -0.0798,\n","          0.1608, -0.1272,  0.0827, -0.2002,  0.1904,  0.0873, -0.1412,  0.1418,\n","         -0.0548,  0.0094, -0.0853,  0.1563,  0.1026, -0.0318, -0.0128,  0.0667,\n","         -0.0026,  0.2585,  0.0062,  0.0174, -0.0699, -0.0928,  0.0481, -0.0752,\n","         -0.2061,  0.0031, -0.0420, -0.0678,  0.1470, -0.1996, -0.0542,  0.1922,\n","          0.1362,  0.1221,  0.1132, -0.0916,  0.0209,  0.1579,  0.0698, -0.0666,\n","          0.1832, -0.0078,  0.0675, -0.2524, -0.2301,  0.0749, -0.1051, -0.0798,\n","          0.1000,  0.0920, -0.1336,  0.1182, -0.0311, -0.0649, -0.1241, -0.0441]],\n","       requires_grad=True)\n","Parameter name: fc.bias\n","    Size : torch.Size([1])\n","    Value: Parameter containing:\n","tensor([0.], requires_grad=True)\n"]}],"source":["pprint(\"Model's state_dict:\")\n","for name, param in model.named_parameters():\n","    print(f\"Parameter name: {name}\")\n","    print(f\"    Size : {param.size()}\")\n","    print(f\"    Value: {param}\")"]},{"cell_type":"code","execution_count":169,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T06:33:21.189251Z","iopub.status.busy":"2024-05-09T06:33:21.188799Z","iopub.status.idle":"2024-05-09T06:33:21.194891Z","shell.execute_reply":"2024-05-09T06:33:21.193696Z","shell.execute_reply.started":"2024-05-09T06:33:21.189216Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["The model has 120,833 trainable parameters\n"]}],"source":["def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","\n","print(f\"The model has {count_parameters(model):,} trainable parameters\")"]},{"cell_type":"code","execution_count":170,"metadata":{},"outputs":[{"data":{"text/plain":["BCEWithLogitsLoss()"]},"execution_count":170,"metadata":{},"output_type":"execute_result"}],"source":["model.to(device)\n","criterion.to(device)"]},{"cell_type":"markdown","metadata":{},"source":["## 2-4. Tensorboard"]},{"cell_type":"code","execution_count":171,"metadata":{},"outputs":[],"source":["writer = SummaryWriter()"]},{"cell_type":"markdown","metadata":{},"source":["# 3. Train Model"]},{"cell_type":"code","execution_count":172,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T06:33:22.006416Z","iopub.status.busy":"2024-05-09T06:33:22.005155Z","iopub.status.idle":"2024-05-09T06:33:22.014644Z","shell.execute_reply":"2024-05-09T06:33:22.013435Z","shell.execute_reply.started":"2024-05-09T06:33:22.006378Z"},"trusted":true},"outputs":[],"source":["def train_model(model, criterion, optimizer, trainloader, num_epochs):\n","    print(\"-----Training Started------\")\n","    for epoch in range(num_epochs):\n","        \n","        model.train()\n","        \n","        running_loss = 0.0\n","        \n","        for inputs, labels in tqdm(trainloader):\n","            \n","            inputs, labels = inputs.to(device), labels.to(device)\n","            \n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            loss = criterion(outputs.view(-1), labels.float())\n","            loss.backward()\n","            optimizer.step()\n","\n","            writer.add_scalar('Loss/train', loss.item(), epoch)\n","\n","            running_loss += loss.item() * inputs.size(0)\n","\n","        epoch_loss = running_loss / len(trainloader.dataset)\n","        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss: .4f}\")\n","\n","        torch.save(model.state_dict(), model_dir)\n","    \n","    writer.close()\n","    \n","    print(\"-----Training Completed-----\")"]},{"cell_type":"code","execution_count":173,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T06:33:22.183260Z","iopub.status.busy":"2024-05-09T06:33:22.182381Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["-----Training Started------\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 196/196 [01:26<00:00,  2.25it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/16], Loss:  0.6936\n"]},{"name":"stderr","output_type":"stream","text":[" 17%|█▋        | 33/196 [00:14<01:12,  2.24it/s]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[173], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m16\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[172], line 14\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, trainloader, num_epochs)\u001b[0m\n\u001b[1;32m     11\u001b[0m inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     13\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 14\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m), labels\u001b[38;5;241m.\u001b[39mfloat())\n\u001b[1;32m     16\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n","File \u001b[0;32m~/miniconda3/envs/study-mldl/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/study-mldl/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[163], line 23\u001b[0m, in \u001b[0;36mCustomRNNClassifier.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     20\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(inputs)\n\u001b[1;32m     21\u001b[0m h0 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layers, batch_size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_dim)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 23\u001b[0m output, h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh0\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m logit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(h)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m logit\n","File \u001b[0;32m~/miniconda3/envs/study-mldl/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/study-mldl/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[162], line 25\u001b[0m, in \u001b[0;36mCustomRNN.forward\u001b[0;34m(self, inputs, h)\u001b[0m\n\u001b[1;32m     22\u001b[0m         layer_inputs \u001b[38;5;241m=\u001b[39m output\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(seq_length):\n\u001b[0;32m---> 25\u001b[0m         h[layer_idx, :, :] \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayer_inputs\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m         output[:, t, :] \u001b[38;5;241m=\u001b[39m h[layer_idx, :, :]\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output, h[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :, :]\n","File \u001b[0;32m~/miniconda3/envs/study-mldl/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/study-mldl/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[161], line 11\u001b[0m, in \u001b[0;36mCustomRNNCell.forward\u001b[0;34m(self, inputs, hidden)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, hidden):\n\u001b[1;32m     10\u001b[0m     h \u001b[38;5;241m=\u001b[39m hidden\n\u001b[0;32m---> 11\u001b[0m     concat_ih \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mWi(concat_ih)\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m h\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["num_epochs = 16\n","\n","train_model(model, criterion, optimizer, trainloader, num_epochs)"]},{"cell_type":"markdown","metadata":{},"source":["# 4. Test"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def test_model(model, testloader):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    TP = 0  # True Positives\n","    TN = 0  # True Negatives\n","    FP = 0  # False Positives\n","    FN = 0  # False Negatives\n","\n","    with torch.no_grad():\n","        for inputs, labels in testloader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            outputs = model(inputs)\n","            predictions = torch.round(F.sigmoid(outputs))\n","            total += labels.size(0)\n","\n","            predictions, labels = predictions.view(-1).cpu(), labels.cpu()\n","            \n","            correct += (predictions == labels).sum().item()\n","\n","            TP += ((predictions == 1) & (labels == 1)).sum().item()\n","            TN += ((predictions == 0) & (labels == 0)).sum().item()\n","            FP += ((predictions == 1) & (labels == 0)).sum().item()\n","            FN += ((predictions == 0) & (labels == 1)).sum().item()\n","\n","    accuracy = correct / total\n","    precision = TP / (TP + FP) if TP + FP != 0 else 0\n","    recall = TP / (TP + FN) if TP + FN != 0 else 0\n","    f1 = 2 * (precision * recall) / (precision + recall) if precision + recall != 0 else 0\n","\n","    print(f\"Accuracy on test set: {accuracy:.4f}\")\n","    print(f\"Precision on test set: {precision:.4f}\")\n","    print(f\"Recall on test set: {recall:.4f}\")\n","    print(f\"F1 Score on test set: {f1:.4f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["CustomRNNClassifier(\n","  (embedding): Embedding(24897, 300, padding_idx=1)\n","  (rnn): CustomRNN(\n","    (Layers): ModuleList(\n","      (0): CustomRNNCell(\n","        (Wi): Linear(in_features=428, out_features=128, bias=True)\n","      )\n","      (1): CustomRNNCell(\n","        (Wi): Linear(in_features=256, out_features=128, bias=True)\n","      )\n","    )\n","  )\n","  (fc): Linear(in_features=128, out_features=1, bias=True)\n",")"]},"execution_count":125,"metadata":{},"output_type":"execute_result"}],"source":["model.load_state_dict(torch.load(model_dir))\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy on test set: 0.5097\n","Precision on test set: 0.5280\n","Recall on test set: 0.1834\n","F1 Score on test set: 0.2723\n"]}],"source":["test_model(model, testloader)"]},{"cell_type":"markdown","metadata":{},"source":["# 5. Inference"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def inference(text, model, tokenizer, vocab):\n","    tokens = tokenizer(text)\n","    ids = vocab.lookup_indices(tokens)\n","    tensor = torch.LongTensor(ids).unsqueeze(dim=0).to(device)\n","\n","    output = model(tensor)\n","\n","    prediction = torch.round(F.sigmoid(output))\n","\n","    return prediction"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["CustomRNNClassifier(\n","  (embedding): Embedding(24897, 300, padding_idx=1)\n","  (rnn): CustomRNN(\n","    (Layers): ModuleList(\n","      (0): CustomRNNCell(\n","        (Wi): Linear(in_features=428, out_features=128, bias=True)\n","      )\n","      (1): CustomRNNCell(\n","        (Wi): Linear(in_features=256, out_features=128, bias=True)\n","      )\n","    )\n","  )\n","  (fc): Linear(in_features=128, out_features=1, bias=True)\n",")"]},"execution_count":128,"metadata":{},"output_type":"execute_result"}],"source":["model.load_state_dict(torch.load(model_dir))\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.0\n"]}],"source":["text = 'This film is terrible!'\n","\n","prediction = inference(text, model, tokenizer, vocab)\n","\n","print(prediction.item())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.0\n"]}],"source":["text = 'This film is great!'\n","\n","prediction = inference(text, model, tokenizer, vocab)\n","\n","print(prediction.item())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1.0\n"]}],"source":["text = 'The best film I have ever seen!'\n","\n","prediction = inference(text, model, tokenizer, vocab)\n","\n","print(prediction.item())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1.0\n"]}],"source":["text = \"This film is not terrible, it's great!\"\n","\n","prediction = inference(text, model, tokenizer, vocab)\n","\n","print(prediction.item())"]},{"cell_type":"markdown","metadata":{},"source":["# Limitation\n","\n","padding 토큰 연산 제외 / dropout / validation"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30698,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
