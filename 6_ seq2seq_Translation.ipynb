{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "based on : https://github.com/bentrevett/pytorch-seq2seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task : De-EN Translation    \n",
    "Method : seq2seq  \n",
    "Dataset : 'bentrevett' custom dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Set Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n",
    "import torchtext\n",
    "torchtext.disable_torchtext_deprecation_warning()\n",
    "from torchtext.data import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from torch import Tensor\n",
    "from typing import List, Dict, Tuple, Union, Annotated\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "import spacy\n",
    "import random\n",
    "from dataclasses import dataclass, field\n",
    "\n",
    "\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Selected device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = './models/seq2seq_Translation_model.pth'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-1. Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_dataset(\"bentrevett/multi30k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, valid_data, test_data = (dataset[\"train\"],\n",
    "                                     dataset[\"validation\"],\n",
    "                                     dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['en', 'de'],\n",
      "    num_rows: 29000\n",
      "}) Dataset({\n",
      "    features: ['en', 'de'],\n",
      "    num_rows: 1014\n",
      "}) Dataset({\n",
      "    features: ['en', 'de'],\n",
      "    num_rows: 1000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(train_data, valid_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'de': 'Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.',\n",
      " 'en': 'Two young, White males are outside near many bushes.'}\n"
     ]
    }
   ],
   "source": [
    "pprint(train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-2. Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_nlp = spacy.load(\"en_core_web_sm\")\n",
    "de_nlp = spacy.load(\"de_core_news_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_example(example, en_nlp, de_nlp, max_length, lower, sos_token, eos_token):\n",
    "    en_tokens = [token.text for token in en_nlp.tokenizer(example[\"en\"])][:max_length]\n",
    "    de_tokens = [token.text for token in de_nlp.tokenizer(example[\"de\"])][:max_length]\n",
    "    if lower:\n",
    "        en_tokens = [token.lower() for token in en_tokens]\n",
    "        de_tokens = [token.lower() for token in de_tokens]\n",
    "    en_tokens = [sos_token] + en_tokens + [eos_token]\n",
    "    de_tokens = [sos_token] + de_tokens + [eos_token]\n",
    "    return {\"en_tokens\": en_tokens, \"de_tokens\": de_tokens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 256\n",
    "\n",
    "lower = True\n",
    "sos_token = \"<sos>\"\n",
    "eos_token = \"<eos>\"\n",
    "\n",
    "fn_kwargs = {\"en_nlp\": en_nlp,\n",
    "             \"de_nlp\": de_nlp,\n",
    "             \"max_length\": max_length,\n",
    "             \"lower\": lower,\n",
    "             \"sos_token\": sos_token,\n",
    "             \"eos_token\": eos_token}\n",
    "\n",
    "train_data = train_data.map(tokenize_example, fn_kwargs = fn_kwargs)\n",
    "valid_data = valid_data.map(tokenize_example, fn_kwargs = fn_kwargs)\n",
    "test_data = test_data.map(tokenize_example, fn_kwargs = fn_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['en', 'de', 'en_tokens', 'de_tokens'],\n",
      "    num_rows: 29000\n",
      "}) Dataset({\n",
      "    features: ['en', 'de', 'en_tokens', 'de_tokens'],\n",
      "    num_rows: 1014\n",
      "}) Dataset({\n",
      "    features: ['en', 'de', 'en_tokens', 'de_tokens'],\n",
      "    num_rows: 1000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(train_data, valid_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'de': 'Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.',\n",
      " 'de_tokens': ['<sos>',\n",
      "               'zwei',\n",
      "               'junge',\n",
      "               'weiße',\n",
      "               'männer',\n",
      "               'sind',\n",
      "               'im',\n",
      "               'freien',\n",
      "               'in',\n",
      "               'der',\n",
      "               'nähe',\n",
      "               'vieler',\n",
      "               'büsche',\n",
      "               '.',\n",
      "               '<eos>'],\n",
      " 'en': 'Two young, White males are outside near many bushes.',\n",
      " 'en_tokens': ['<sos>',\n",
      "               'two',\n",
      "               'young',\n",
      "               ',',\n",
      "               'white',\n",
      "               'males',\n",
      "               'are',\n",
      "               'outside',\n",
      "               'near',\n",
      "               'many',\n",
      "               'bushes',\n",
      "               '.',\n",
      "               '<eos>']}\n"
     ]
    }
   ],
   "source": [
    "pprint(train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-3. Build Vocab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_freq = 1\n",
    "unk_token = \"<unk>\"\n",
    "pad_token = \"<pad>\"\n",
    "\n",
    "special_tokens = [unk_token,\n",
    "                  pad_token,\n",
    "                  sos_token,\n",
    "                  eos_token]\n",
    "\n",
    "en_vocab = build_vocab_from_iterator(train_data[\"en_tokens\"],\n",
    "                                     min_freq = min_freq,\n",
    "                                     specials = special_tokens)\n",
    "\n",
    "de_vocab = build_vocab_from_iterator(train_data[\"de_tokens\"],\n",
    "                                     min_freq = min_freq,\n",
    "                                     specials = special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9797, 18669)"
      ]
     },
     "execution_count": 591,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(en_vocab), len(de_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert en_vocab[unk_token] == de_vocab[unk_token]\n",
    "assert en_vocab[pad_token] == de_vocab[pad_token]\n",
    "\n",
    "unk_index = en_vocab[unk_token]\n",
    "pad_index = en_vocab[pad_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "en_vocab.set_default_index(unk_index)\n",
    "de_vocab.set_default_index(unk_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = [\"i\", \"love\", \"watching\", \"crime\", \"shows\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[956, 2169, 173, 6799, 821]"
      ]
     },
     "execution_count": 595,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vocab.lookup_indices(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'love', 'watching', 'crime', 'shows']"
      ]
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_vocab.lookup_tokens(en_vocab.lookup_indices(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-4. Numericalize Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numericalize_example(example, en_vocab, de_vocab):\n",
    "    en_ids = en_vocab.lookup_indices(example[\"en_tokens\"])\n",
    "    de_ids = de_vocab.lookup_indices(example[\"de_tokens\"])\n",
    "    return {\"en_ids\": en_ids, \"de_ids\": de_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_kwargs = {\"en_vocab\": en_vocab, \"de_vocab\": de_vocab}\n",
    "\n",
    "train_data = train_data.map(numericalize_example, fn_kwargs = fn_kwargs)\n",
    "valid_data = valid_data.map(numericalize_example, fn_kwargs = fn_kwargs)\n",
    "test_data = test_data.map(numericalize_example, fn_kwargs = fn_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['en', 'de', 'en_tokens', 'de_tokens', 'en_ids', 'de_ids'],\n",
      "    num_rows: 29000\n",
      "}) Dataset({\n",
      "    features: ['en', 'de', 'en_tokens', 'de_tokens', 'en_ids', 'de_ids'],\n",
      "    num_rows: 1014\n",
      "}) Dataset({\n",
      "    features: ['en', 'de', 'en_tokens', 'de_tokens', 'en_ids', 'de_ids'],\n",
      "    num_rows: 1000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(train_data, valid_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'de': 'Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.',\n",
      " 'de_ids': [2, 18, 26, 253, 30, 84, 20, 88, 7, 15, 110, 7647, 3171, 4, 3],\n",
      " 'de_tokens': ['<sos>',\n",
      "               'zwei',\n",
      "               'junge',\n",
      "               'weiße',\n",
      "               'männer',\n",
      "               'sind',\n",
      "               'im',\n",
      "               'freien',\n",
      "               'in',\n",
      "               'der',\n",
      "               'nähe',\n",
      "               'vieler',\n",
      "               'büsche',\n",
      "               '.',\n",
      "               '<eos>'],\n",
      " 'en': 'Two young, White males are outside near many bushes.',\n",
      " 'en_ids': [2, 16, 24, 15, 25, 778, 17, 57, 80, 202, 1312, 5, 3],\n",
      " 'en_tokens': ['<sos>',\n",
      "               'two',\n",
      "               'young',\n",
      "               ',',\n",
      "               'white',\n",
      "               'males',\n",
      "               'are',\n",
      "               'outside',\n",
      "               'near',\n",
      "               'many',\n",
      "               'bushes',\n",
      "               '.',\n",
      "               '<eos>']}\n"
     ]
    }
   ],
   "source": [
    "pprint(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_type = \"torch\"\n",
    "format_columns = [\"en_ids\", \"de_ids\"]\n",
    "\n",
    "train_data = train_data.with_format(type = data_type, \n",
    "                                    columns = format_columns, \n",
    "                                    output_all_columns = False)\n",
    "\n",
    "valid_data = valid_data.with_format(type = data_type,\n",
    "                                    columns = format_columns,\n",
    "                                    output_all_columns = False)\n",
    "\n",
    "test_data = test_data.with_format(type = data_type,\n",
    "                                  columns = format_columns,\n",
    "                                  output_all_columns = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['en', 'de', 'en_tokens', 'de_tokens', 'en_ids', 'de_ids'],\n",
      "    num_rows: 29000\n",
      "}) Dataset({\n",
      "    features: ['en', 'de', 'en_tokens', 'de_tokens', 'en_ids', 'de_ids'],\n",
      "    num_rows: 1014\n",
      "}) Dataset({\n",
      "    features: ['en', 'de', 'en_tokens', 'de_tokens', 'en_ids', 'de_ids'],\n",
      "    num_rows: 1000\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(train_data, valid_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'de_ids': tensor([   2,   18,   26,  253,   30,   84,   20,   88,    7,   15,  110, 7647,\n",
      "        3171,    4,    3]),\n",
      " 'en_ids': tensor([   2,   16,   24,   15,   25,  778,   17,   57,   80,  202, 1312,    5,\n",
      "           3])}\n"
     ]
    }
   ],
   "source": [
    "pprint(train_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-5. Word Embedding\n",
    "\n",
    "you can add word embedding here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [],
   "source": [
    "# en_pretrained_embedding =\n",
    "# de_pretrained_embedding ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-6. Prepare for Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_data)\n",
    "test_dataset = CustomDataset(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(batch):\n",
    "\n",
    "    batch_en_ids = [sample[\"en_ids\"] for sample in batch]\n",
    "    batch_de_ids = [sample[\"de_ids\"] for sample in batch]\n",
    "\n",
    "    collate_en = pad_sequence(batch_en_ids,\n",
    "                              padding_value = pad_index,\n",
    "                              batch_first = True)\n",
    "    collate_de = pad_sequence(batch_de_ids,\n",
    "                              padding_value = pad_index,\n",
    "                              batch_first = True)\n",
    "    \n",
    "    batch = {\"en_ids\": collate_en,\n",
    "             \"de_ids\": collate_de}\n",
    "    \n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "pad_index = pad_index\n",
    "shuffle = True\n",
    "\n",
    "trainloader = DataLoader(dataset = train_dataset,\n",
    "                         batch_size = batch_size,\n",
    "                         collate_fn = custom_collate_fn,\n",
    "                         shuffle = shuffle)\n",
    "\n",
    "validloader = DataLoader(dataset = train_dataset,\n",
    "                         batch_size = batch_size,\n",
    "                         collate_fn = custom_collate_fn,\n",
    "                         shuffle = shuffle)\n",
    "\n",
    "testloader = DataLoader(dataset = test_dataset,\n",
    "                         batch_size = batch_size,\n",
    "                         collate_fn = custom_collate_fn,\n",
    "                         shuffle = shuffle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Define Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-1. Model Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_dim: int, \n",
    "                 embedding_dim: int, \n",
    "                 hidden_dim: int, \n",
    "                 num_layers: int, \n",
    "                 dropout_rate: float, \n",
    "                 pad_idx: int):\n",
    "        \n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.pad_idx = pad_idx\n",
    "        \n",
    "        self.embedding = nn.Embedding(num_embeddings=self.input_dim, \n",
    "                                      embedding_dim=self.embedding_dim, \n",
    "                                      padding_idx=self.pad_idx)\n",
    "        \n",
    "        self.LSTM = nn.LSTM(input_size=self.embedding_dim, \n",
    "                            hidden_size=self.hidden_dim, \n",
    "                            num_layers=self.num_layers, \n",
    "                            dropout=self.dropout_rate, \n",
    "                            batch_first=True)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=self.dropout_rate)\n",
    "\n",
    "    def forward(self, \n",
    "                inputs: Annotated[Tensor, 'batch_size, seq_length'],\n",
    "                h0:     Annotated[Tensor, 'num_layers, batch_size, hidden_dim'],\n",
    "                c0:     Annotated[Tensor, 'num_layers, batch_size, hidden_dim']) -> Tuple[Annotated[Tensor, 'num_layers, batch_size, hidden_dim'], \n",
    "                                                                                          Annotated[Tensor, 'num_layers, batch_size, hidden_dim']]:\n",
    "\n",
    "        # x: Tensor, 'batch_size, seq_length, embedding_dim'\n",
    "        x = self.dropout(self.embedding(inputs))\n",
    "\n",
    "        # output: Tensor, 'batch_size, seq_length, hidden_dim'\n",
    "        # h: Tensor, 'num_layers, batch_size, hidden_dim'\n",
    "        # c: Tensor, 'num_layers, batch_size, hidden_dim'\n",
    "        output, (h, c) = self.LSTM(x, (h0, c0))\n",
    "        \n",
    "\n",
    "        \n",
    "        return h, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 output_dim: int, \n",
    "                 embedding_dim: int, \n",
    "                 hidden_dim: int, \n",
    "                 num_layers: int, \n",
    "                 dropout_rate: float, \n",
    "                 pad_idx: int):\n",
    "        \n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.output_dim = output_dim\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.pad_idx = pad_idx\n",
    "        \n",
    "        self.embedding = nn.Embedding(num_embeddings=self.output_dim, \n",
    "                                      embedding_dim=self.embedding_dim, \n",
    "                                      padding_idx=self.pad_idx)\n",
    "        \n",
    "        self.LSTM = nn.LSTM(input_size=self.embedding_dim, \n",
    "                            hidden_size=self.hidden_dim, \n",
    "                            num_layers=self.num_layers, \n",
    "                            dropout=self.dropout_rate, \n",
    "                            batch_first=True)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=self.dropout_rate)\n",
    "        \n",
    "        self.fc = nn.Linear(in_features=self.hidden_dim, \n",
    "                            out_features=self.output_dim)\n",
    "\n",
    "    def forward(self, \n",
    "                inputs: Annotated[Tensor, \"batch_size, 1\"], \n",
    "                h:      Annotated[Tensor, \"num_layers, batch_size, hidden_dim\"], \n",
    "                c:      Annotated[Tensor, \"num_layers, batch_size, hidden_dim\"]) -> Tuple[Annotated[Tensor, \"logit : batch_size, 1, output_dim\"],\n",
    "                                                                                          Annotated[Tensor, \"h : num_layers, batch_size, hidden_dim\"],\n",
    "                                                                                          Annotated[Tensor, \"c : num_layers, batch_size, hidden_dim\"]]:\n",
    "\n",
    "        # x: Tensor, 'batch_size, 1, embedding_dim'\n",
    "        x = self.dropout(self.embedding(inputs))\n",
    "        \n",
    "        # output: Tensor, 'batch_size, 1, hidden_dim'\n",
    "        # h: Tensor, 'num_layers, batch_size, hidden_dim' \n",
    "        # c: Tensor, 'num_layers, batch_size, hidden_dim' \n",
    "        output, (h, c) = self.LSTM(x, (h, c))\n",
    "\n",
    "        # logit: Tensor, 'batch_size, 1, output_dim'\n",
    "        logit = self.fc(output)\n",
    "\n",
    "        return logit, h, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "class seq2seq_Translation(nn.Module):\n",
    "    def __init__(self, Encoder, Decoder):\n",
    "        super().__init__()\n",
    "        self.Encoder = Encoder\n",
    "        self.Decoder = Decoder\n",
    "\n",
    "        assert (\n",
    "            self.Encoder.hidden_dim == self.Decoder.hidden_dim\n",
    "        ), \"Hidden dimensions of encoder and decoder must be equal!\"\n",
    "        assert (\n",
    "            self.Encoder.num_layers == self.Decoder.num_layers\n",
    "        ), \"Encoder and decoder must have equal number of layers!\"\n",
    "\n",
    "    def forward(self, \n",
    "                source: Annotated[Tensor, 'batch_size, seq_length'], \n",
    "                target: Annotated[Tensor, 'batch_size, seq_length'], \n",
    "                teacher_forcing_ratio: float)                                      -> Annotated[Tensor, 'batch_size, seq_length, output_dim']:\n",
    "\n",
    "        target_batch_size = target.size(0)\n",
    "        target_seq_length = target.size(1)\n",
    "        target_vocab_size = self.Decoder.output_dim\n",
    "\n",
    "        source_batch_size = source.size(0)\n",
    "\n",
    "        logit_seq = torch.zeros(target_batch_size, target_seq_length, target_vocab_size).to(device)\n",
    "\n",
    "        h0 = torch.zeros(self.Encoder.num_layers, source_batch_size, self.Encoder.hidden_dim).to(device)\n",
    "        c0 = torch.zeros(self.Encoder.num_layers, source_batch_size, self.Encoder.hidden_dim).to(device)\n",
    "\n",
    "        # h_encoder: Tensor, 'num_layers, batch_size, hidden_dim'\n",
    "        # c_encoder: Tensor, 'num_layers, batch_size, hidden_dim'         \n",
    "        h_encoder, c_encoder = self.Encoder(source, h0, c0)\n",
    "\n",
    "        # x: Tensor, 'batch_size, 1'\n",
    "        x = target[:, 0].unsqueeze(1)\n",
    "\n",
    "        h, c = h_encoder, c_encoder\n",
    "        for t in range(1, target_seq_length):\n",
    "\n",
    "            # logit: Tensor, 'batch_size, 1, output_dim'\n",
    "            # h: Tensor, 'num_layers, batch_size, hidden_dim'\n",
    "            # c: Tensor, 'num_layers, batch_size, hidden_dim'\n",
    "            logit, h, c = self.Decoder(x, h, c)\n",
    "\n",
    "            # logit_seq: Tensor, 'batch_size, seq_length, output_dim'\n",
    "            logit_seq[:, t, :] = logit.squeeze(1)\n",
    "            \n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "\n",
    "            # predicted_vocab: Tensor, 'batch_size, 1'\n",
    "            predicted_vocab = logit.argmax(2)\n",
    "\n",
    "            # x: Tensor, 'batch_size, 1, output_dim'\n",
    "            x = target[:, t].unsqueeze(1) if teacher_force else predicted_vocab\n",
    "\n",
    "        return logit_seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-2. Hyperparameter & functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Model's state_dict:\"\n",
      "Parameter name: embedding.weight\n",
      "    Size : torch.Size([18669, 300])\n",
      "    Value: Parameter containing:\n",
      "tensor([[ 1.9269,  1.4873,  0.9007,  ...,  0.2539,  0.9364,  0.7122],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.4982, -1.2000,  0.1271,  ..., -0.3867,  0.9578, -0.8225],\n",
      "        ...,\n",
      "        [ 1.3966, -0.0912, -0.7094,  ...,  1.3549,  0.0225, -0.0448],\n",
      "        [-0.2576,  1.1460, -0.1860,  ...,  0.1697, -0.1309,  0.7459],\n",
      "        [ 0.2618, -0.9730, -0.8111,  ..., -1.0894,  0.3437, -0.2883]],\n",
      "       requires_grad=True)\n",
      "Parameter name: LSTM.weight_ih_l0\n",
      "    Size : torch.Size([512, 300])\n",
      "    Value: Parameter containing:\n",
      "tensor([[ 0.0056,  0.0860,  0.0265,  ...,  0.0139, -0.0010, -0.0183],\n",
      "        [ 0.0641,  0.0734, -0.0102,  ..., -0.0379, -0.0698, -0.0288],\n",
      "        [-0.0585, -0.0168,  0.0138,  ...,  0.0799, -0.0206,  0.0139],\n",
      "        ...,\n",
      "        [-0.0581, -0.0245, -0.0166,  ...,  0.0131, -0.0610,  0.0242],\n",
      "        [ 0.0712, -0.0875,  0.0611,  ...,  0.0603, -0.0273,  0.0166],\n",
      "        [-0.0009, -0.0072, -0.0523,  ...,  0.0716,  0.0625, -0.0123]],\n",
      "       requires_grad=True)\n",
      "Parameter name: LSTM.weight_hh_l0\n",
      "    Size : torch.Size([512, 128])\n",
      "    Value: Parameter containing:\n",
      "tensor([[-0.0158, -0.0301,  0.0686,  ..., -0.0066,  0.0580,  0.0553],\n",
      "        [ 0.0731, -0.0440, -0.0877,  ...,  0.0049,  0.0454,  0.0775],\n",
      "        [ 0.0274, -0.0449, -0.0621,  ..., -0.0441, -0.0194, -0.0256],\n",
      "        ...,\n",
      "        [-0.0793, -0.0819,  0.0687,  ...,  0.0019, -0.0855, -0.0055],\n",
      "        [-0.0007, -0.0447, -0.0466,  ...,  0.0327, -0.0831,  0.0741],\n",
      "        [ 0.0008,  0.0828,  0.0102,  ..., -0.0756,  0.0526,  0.0112]],\n",
      "       requires_grad=True)\n",
      "Parameter name: LSTM.bias_ih_l0\n",
      "    Size : torch.Size([512])\n",
      "    Value: Parameter containing:\n",
      "tensor([-4.6444e-03,  2.3091e-02,  8.5980e-02, -2.4437e-03, -6.8599e-02,\n",
      "         5.0231e-02,  8.6870e-02, -3.7724e-02,  8.0026e-02, -6.5863e-02,\n",
      "         4.5153e-02,  6.8332e-02,  2.3171e-02,  6.9516e-02, -3.1332e-03,\n",
      "        -3.4812e-02, -1.7578e-02,  2.4626e-02, -6.2113e-02,  1.2426e-02,\n",
      "        -4.6558e-02, -2.4690e-03, -3.2407e-02,  1.9119e-02, -4.4323e-02,\n",
      "        -7.1786e-02, -4.0337e-02,  4.6885e-02,  6.5320e-02, -8.4251e-02,\n",
      "         8.4468e-03,  1.6101e-02, -9.7297e-03, -7.3803e-02,  5.7914e-02,\n",
      "         3.0346e-02,  7.8800e-02,  2.7870e-02,  4.3814e-02, -5.3549e-02,\n",
      "        -6.5527e-02,  3.1613e-02, -2.2654e-02, -2.8503e-02, -4.9676e-02,\n",
      "         5.8283e-03,  2.9996e-02, -2.0004e-02, -7.1461e-02,  5.5348e-02,\n",
      "         5.6263e-02, -1.4575e-02,  1.2381e-02,  2.5062e-02, -8.1482e-02,\n",
      "         4.7698e-02,  8.0071e-02, -3.2744e-02,  2.2738e-02,  4.4454e-02,\n",
      "        -4.0721e-02,  4.6602e-02, -7.4008e-02, -9.4527e-03,  8.9104e-03,\n",
      "         7.8056e-02, -5.9410e-02, -3.1674e-02, -7.2543e-02,  7.3032e-02,\n",
      "         8.6470e-02, -8.4860e-02, -1.8420e-02, -5.0024e-02,  8.2495e-02,\n",
      "         7.4502e-03,  7.8532e-02,  3.6340e-02,  6.5244e-02,  9.3459e-03,\n",
      "        -2.3880e-02,  4.3785e-02, -5.2644e-02,  4.0592e-02, -2.8011e-02,\n",
      "         4.5870e-02,  6.5610e-02, -5.0384e-02, -3.6618e-03, -5.9382e-02,\n",
      "        -3.5882e-02, -7.7342e-02, -1.8708e-02,  8.2659e-02, -4.4773e-02,\n",
      "        -6.9740e-02,  3.3905e-02,  4.9796e-02,  2.4441e-02,  3.8037e-02,\n",
      "         1.7785e-03,  4.8201e-02,  7.8187e-02,  7.4048e-02, -5.8347e-02,\n",
      "         8.0844e-02,  6.0806e-02,  4.1899e-02, -1.9887e-02, -5.3964e-02,\n",
      "         1.6826e-02, -7.4629e-02, -6.0462e-02,  7.5933e-02,  7.5887e-02,\n",
      "        -3.4920e-02,  7.4932e-03, -6.6242e-02, -5.3249e-02, -6.7119e-02,\n",
      "         8.0592e-02, -2.7134e-02, -4.4764e-02, -3.1822e-02,  2.3939e-02,\n",
      "        -7.8714e-02, -5.5100e-02, -1.7240e-02,  6.3264e-02,  2.4048e-02,\n",
      "         3.1311e-02, -4.8139e-02,  2.0761e-02,  2.9527e-02, -7.9034e-02,\n",
      "        -5.7496e-02,  2.9368e-02,  2.9749e-02,  3.9447e-03, -3.5845e-02,\n",
      "        -1.0380e-02, -1.4855e-02,  2.6868e-02,  5.3278e-02, -7.6191e-02,\n",
      "         2.8301e-02, -7.1386e-02,  6.2499e-02, -3.0773e-02,  5.7525e-02,\n",
      "         6.3620e-02,  4.2411e-03,  7.4791e-02, -2.2417e-02,  6.2606e-02,\n",
      "         4.9509e-02,  6.2474e-02,  8.0452e-02,  8.4795e-03, -5.0366e-02,\n",
      "         4.3529e-02, -7.3573e-02, -5.7298e-02, -7.6239e-02, -7.8060e-02,\n",
      "         7.9421e-02, -5.3068e-02, -1.9403e-02, -6.0582e-02, -1.5477e-02,\n",
      "        -1.5275e-02,  7.6815e-03,  6.3888e-02,  6.4136e-02,  6.2142e-02,\n",
      "        -5.8759e-02,  6.3305e-02,  7.8754e-02,  2.9165e-02, -2.7631e-02,\n",
      "        -4.0188e-02,  2.1593e-02,  7.4734e-02,  4.1767e-02,  5.4883e-03,\n",
      "         2.0779e-02, -2.8245e-02,  3.3870e-02,  2.0916e-02, -8.6935e-02,\n",
      "        -3.0018e-02,  1.9837e-02,  2.0801e-02, -3.6679e-02,  8.3960e-02,\n",
      "         7.8701e-02, -4.6306e-02, -6.2684e-02, -8.6898e-02, -7.0822e-03,\n",
      "        -4.2871e-02,  3.7454e-02, -4.9540e-02, -6.0520e-02,  5.4004e-02,\n",
      "         1.2966e-02, -4.6073e-02,  7.1155e-02, -2.8262e-02, -4.9573e-02,\n",
      "         6.8217e-03,  3.8561e-02,  2.4593e-02, -1.4143e-02,  5.7153e-02,\n",
      "        -8.8324e-02, -3.3384e-02, -6.7729e-02,  1.0022e-02,  2.9219e-03,\n",
      "         3.5581e-02, -7.2949e-02, -4.1420e-02,  3.2756e-02, -5.3660e-02,\n",
      "         3.7340e-02, -5.6883e-02, -5.8899e-02,  2.0761e-02,  5.2080e-02,\n",
      "         3.3133e-02, -1.6839e-03,  2.2007e-02, -7.1382e-02, -5.8634e-02,\n",
      "         2.8022e-02, -5.0853e-02,  1.3877e-02, -1.5863e-02, -1.2235e-02,\n",
      "        -5.6518e-02,  4.2500e-02, -8.8320e-02, -2.2612e-02,  4.5324e-02,\n",
      "         2.7821e-02,  1.1091e-02,  4.7601e-02,  7.8159e-03,  7.0909e-03,\n",
      "         4.6859e-02,  9.7762e-03, -6.3038e-02,  5.3734e-02,  2.6041e-02,\n",
      "         5.7398e-02,  4.8643e-02, -4.3918e-02, -2.6039e-02, -6.4406e-02,\n",
      "         3.8598e-02,  5.7568e-02,  4.6413e-02,  4.6033e-02, -8.3159e-02,\n",
      "         5.4101e-02, -4.9073e-02, -3.5461e-02,  2.1580e-02,  1.6065e-03,\n",
      "        -4.9061e-02, -8.0760e-02,  1.9649e-02,  5.9948e-02,  2.0411e-02,\n",
      "         2.6920e-02, -1.7681e-02,  2.8920e-02,  7.3906e-02, -1.3212e-03,\n",
      "         4.1039e-02,  2.8474e-02,  1.0548e-02, -6.7460e-02,  2.9666e-02,\n",
      "        -5.2421e-02, -7.4223e-02,  3.2499e-02, -4.9416e-02, -4.8923e-02,\n",
      "        -2.6518e-02, -7.5975e-02, -6.2651e-02, -1.3378e-02, -8.4312e-02,\n",
      "         1.1966e-02,  2.3277e-02, -7.9650e-02,  7.3041e-02,  3.8668e-02,\n",
      "        -6.6495e-02, -8.1850e-02,  1.1404e-02, -3.1353e-02,  2.2972e-02,\n",
      "        -8.6298e-03, -2.6836e-03,  1.4831e-03,  3.9112e-02, -6.1684e-02,\n",
      "        -6.3386e-02,  1.4614e-02,  6.6509e-02,  7.5957e-02,  5.4070e-02,\n",
      "         1.9191e-02,  2.9994e-02,  1.7391e-02,  6.8868e-02, -8.3405e-02,\n",
      "        -2.7639e-02,  2.0686e-02,  8.7914e-04,  2.2394e-02,  3.9677e-02,\n",
      "        -3.2338e-02, -4.6387e-02, -8.0508e-02,  3.8812e-02, -3.5861e-02,\n",
      "         8.7365e-02,  5.4949e-05,  6.0309e-02, -7.8137e-02, -6.2019e-02,\n",
      "         6.8604e-02,  6.9414e-02, -4.0844e-02,  5.4130e-02, -4.4788e-02,\n",
      "         2.2451e-03, -1.3664e-02, -4.4132e-02, -7.4593e-02, -7.3563e-02,\n",
      "         2.6527e-03, -4.1273e-04, -8.7438e-02,  7.9646e-02,  6.5090e-02,\n",
      "        -3.3211e-02, -4.9334e-02,  8.6266e-02, -7.4041e-02,  4.2276e-02,\n",
      "         7.6433e-02, -8.7355e-02, -8.0439e-02,  2.0125e-02,  1.2193e-02,\n",
      "        -3.6573e-02,  7.1605e-02,  8.6309e-02,  4.6405e-02, -2.3561e-02,\n",
      "        -5.1273e-02, -2.7189e-02, -6.7402e-02,  1.1376e-02,  3.9148e-02,\n",
      "        -1.1689e-02,  8.7406e-02, -4.0872e-02, -4.0345e-02, -6.1696e-02,\n",
      "        -8.7482e-02,  6.6783e-02,  5.0883e-02, -8.6564e-02,  3.4362e-02,\n",
      "        -6.1071e-02,  5.2565e-02, -4.2817e-02, -1.8734e-02, -3.0974e-02,\n",
      "        -6.8760e-02,  1.0347e-02, -7.2935e-02, -5.3793e-02, -1.9840e-02,\n",
      "        -2.4726e-02, -8.4312e-02, -4.3565e-02,  8.5534e-03, -1.2471e-02,\n",
      "         5.6972e-02, -8.3344e-02, -3.0692e-02, -1.4686e-02, -5.4221e-02,\n",
      "        -3.0441e-02, -4.5404e-02,  4.8642e-02,  5.4760e-02, -6.8548e-02,\n",
      "         1.0810e-02,  5.3133e-02,  7.3957e-02,  8.0084e-02, -2.5749e-02,\n",
      "        -3.1896e-02,  3.3653e-03,  4.8945e-02,  2.6290e-02,  3.6452e-02,\n",
      "        -3.0720e-02,  3.2614e-02, -3.3886e-02,  4.1632e-02, -1.7581e-03,\n",
      "         4.0506e-02,  1.0758e-02,  4.9008e-02,  8.1234e-02, -7.2796e-02,\n",
      "         1.1397e-02,  5.5138e-02,  2.0075e-02, -3.9496e-02, -1.4998e-02,\n",
      "         7.1586e-02, -7.7340e-02,  2.1682e-02, -3.5028e-02,  6.7322e-02,\n",
      "         3.7720e-03,  2.3174e-02,  6.8736e-02,  2.8165e-02, -3.1031e-02,\n",
      "        -8.5975e-02,  7.6575e-02, -1.5262e-02, -5.9225e-02, -4.6748e-03,\n",
      "        -7.6578e-02, -7.3941e-03,  6.8672e-02,  2.1410e-02,  8.6305e-02,\n",
      "         6.3986e-02,  4.6392e-02,  5.7004e-02,  7.3919e-03, -3.8216e-02,\n",
      "        -4.2585e-02, -5.0072e-02, -8.1134e-02, -6.1538e-02, -7.3007e-02,\n",
      "         5.0159e-02, -8.4784e-02,  7.3319e-02, -2.2987e-02,  6.8838e-02,\n",
      "        -2.0447e-02, -4.8364e-02, -7.3340e-02, -5.2462e-02, -4.0929e-03,\n",
      "         2.5323e-02,  8.7179e-02,  4.4633e-02,  3.0469e-02, -4.2666e-02,\n",
      "         8.3420e-02,  6.7770e-02, -7.0943e-03, -8.1990e-02, -6.6693e-02,\n",
      "        -2.9999e-02, -3.7830e-02,  4.4312e-02,  4.5954e-02,  6.5882e-02,\n",
      "        -2.0372e-03,  7.9969e-02,  8.1887e-02,  2.3469e-02,  2.1810e-03,\n",
      "         6.6883e-02, -1.7507e-02, -2.2398e-02,  7.8575e-02, -7.9595e-02,\n",
      "         6.9011e-03,  7.4364e-03,  8.2430e-02, -3.0548e-02,  4.6293e-02,\n",
      "         2.2047e-02,  2.5261e-02,  4.8329e-02, -1.6465e-02,  8.4203e-02,\n",
      "        -4.5635e-02,  6.6480e-02,  1.0801e-02, -2.1568e-02,  3.8313e-02,\n",
      "        -3.2693e-02, -3.2354e-02], requires_grad=True)\n",
      "Parameter name: LSTM.bias_hh_l0\n",
      "    Size : torch.Size([512])\n",
      "    Value: Parameter containing:\n",
      "tensor([-1.9186e-03,  7.4244e-02,  6.3423e-02, -8.8105e-02, -8.4987e-03,\n",
      "         3.4439e-02,  6.6878e-02, -6.7280e-02, -5.2795e-02,  5.9167e-02,\n",
      "        -8.4193e-02, -1.1236e-02,  4.4573e-02,  5.4321e-02,  8.6016e-02,\n",
      "         6.0998e-02,  6.4235e-02,  7.5670e-02, -1.3146e-02, -3.0272e-02,\n",
      "         5.6782e-02,  3.3464e-02, -5.0263e-02, -7.3541e-02,  6.1840e-02,\n",
      "         4.4976e-03, -2.1124e-02,  6.9971e-02, -2.6870e-02,  2.6582e-02,\n",
      "        -3.7223e-02, -2.0897e-02, -2.8208e-02, -2.7039e-03,  8.1689e-02,\n",
      "         3.0892e-02, -2.3933e-02,  3.8332e-02,  1.6528e-02,  2.3146e-02,\n",
      "         4.2283e-02, -8.8293e-02, -5.7863e-02,  4.4432e-02, -8.6982e-02,\n",
      "        -1.1958e-02, -6.6850e-02,  1.5747e-02,  3.8649e-02, -6.8087e-03,\n",
      "        -1.0034e-02, -1.4794e-02, -8.3428e-03, -3.9003e-02,  1.1263e-02,\n",
      "        -3.2334e-02, -2.9903e-02,  8.3578e-02, -8.7582e-02, -8.1627e-02,\n",
      "        -3.4317e-04, -8.4788e-02,  2.6941e-02,  8.6085e-02, -3.5837e-03,\n",
      "        -4.3760e-02,  1.6431e-02,  4.1099e-02, -5.3737e-02, -2.4814e-02,\n",
      "        -4.5523e-02,  2.2161e-02, -1.3577e-02, -6.6061e-02, -6.3423e-02,\n",
      "        -1.5378e-02,  7.7571e-02,  1.7983e-02,  8.1030e-03, -7.1945e-02,\n",
      "        -4.0080e-03, -2.1913e-02,  3.5615e-02,  8.0956e-02,  3.0481e-02,\n",
      "        -6.4125e-02, -4.2369e-02, -5.8755e-02, -6.1153e-02,  4.2564e-02,\n",
      "        -2.9021e-02, -3.8558e-02, -3.2657e-02,  3.2756e-02, -4.1203e-02,\n",
      "        -8.6492e-03,  5.7699e-02, -3.7595e-03, -9.1850e-03, -7.1587e-02,\n",
      "         4.1174e-02, -8.5029e-02, -1.6207e-02,  4.5615e-02,  4.6177e-02,\n",
      "        -4.6233e-02,  1.1507e-02, -3.3853e-02, -5.2022e-02, -6.9747e-02,\n",
      "         2.7613e-02, -7.4811e-02,  8.1599e-02,  7.0275e-02, -5.8433e-02,\n",
      "         7.3804e-02,  2.2510e-02, -8.0429e-02,  8.4566e-02,  7.1067e-02,\n",
      "         2.9764e-02,  3.9900e-02, -6.3832e-02, -4.4207e-02,  4.2005e-02,\n",
      "        -6.1974e-03, -1.9526e-02,  1.5782e-02,  5.4732e-02,  6.8286e-02,\n",
      "         8.4692e-02, -8.6183e-02, -7.3002e-02, -3.1371e-02, -5.9930e-02,\n",
      "         5.5530e-02, -2.1901e-02,  8.2950e-02,  7.6910e-02,  6.7435e-02,\n",
      "         5.0778e-02,  9.5446e-03, -4.1467e-02,  2.9366e-02,  3.1900e-02,\n",
      "         4.8362e-02, -7.8669e-02, -1.5504e-03, -1.5752e-02, -3.4448e-03,\n",
      "         5.6368e-02,  7.0626e-02, -5.5483e-02, -1.3913e-02, -3.8776e-02,\n",
      "         1.7119e-02,  1.6423e-02, -8.3701e-02,  8.3984e-02, -6.9977e-02,\n",
      "        -8.1971e-02, -3.8478e-02, -1.8317e-02,  8.3337e-03, -4.2039e-02,\n",
      "         2.7906e-02, -7.4036e-02,  8.7657e-02,  3.2022e-02, -7.9582e-02,\n",
      "         1.2812e-02,  6.1701e-02,  3.5607e-02, -4.4027e-03, -2.0701e-02,\n",
      "        -4.5978e-02, -2.2297e-02,  2.5783e-05, -2.9846e-02,  7.4417e-03,\n",
      "        -3.0924e-03,  2.4888e-02,  7.3546e-02, -7.6044e-02, -3.3115e-02,\n",
      "        -1.6808e-02, -2.5001e-02,  7.5205e-03, -3.7818e-02,  4.9556e-02,\n",
      "        -1.8545e-02, -1.9734e-02,  4.8954e-02,  8.6695e-03, -6.0674e-02,\n",
      "        -1.7131e-03, -1.9429e-02,  7.2429e-02, -2.1484e-02,  1.8678e-02,\n",
      "        -7.8116e-02, -8.1588e-02, -5.4117e-04,  6.0322e-03, -8.5987e-02,\n",
      "         5.7529e-02, -8.4568e-02,  5.7032e-02,  6.6040e-02, -7.0185e-02,\n",
      "        -8.8377e-02,  1.0845e-02,  2.4944e-02,  3.4476e-02,  5.6436e-02,\n",
      "        -3.3143e-02, -1.9886e-02, -8.4931e-02,  1.4274e-02,  7.8167e-02,\n",
      "         1.6888e-02, -5.5620e-02, -1.3474e-02,  6.3206e-02, -2.3919e-02,\n",
      "         4.2348e-02,  7.3488e-02,  6.9010e-02, -8.3245e-02,  1.7284e-02,\n",
      "         3.6573e-02,  3.4837e-02, -1.8268e-02,  3.9786e-02, -8.4745e-02,\n",
      "        -7.9067e-02,  1.5676e-02,  7.2723e-02, -3.1830e-03,  5.1281e-03,\n",
      "        -4.3972e-02, -6.3759e-02, -3.7000e-02,  8.1712e-02, -4.0048e-02,\n",
      "         4.3363e-02, -8.2662e-04, -1.2102e-02, -8.5143e-02, -8.3145e-02,\n",
      "         5.9668e-02,  2.4291e-02, -7.6314e-02,  7.6179e-02, -7.2055e-02,\n",
      "         7.5298e-02, -3.2138e-02,  4.1685e-02, -6.7515e-02,  8.0209e-02,\n",
      "        -4.0447e-02, -7.7615e-02, -4.3215e-02,  7.4104e-02, -7.0313e-02,\n",
      "        -5.3603e-02, -3.0025e-02,  2.3472e-02, -2.2900e-02, -2.8929e-02,\n",
      "        -1.4965e-02,  3.9243e-02, -5.9682e-02,  1.6634e-02, -8.4592e-02,\n",
      "        -4.0113e-02, -4.3780e-02,  8.7654e-02, -9.4238e-03, -2.7636e-02,\n",
      "        -6.5003e-03, -3.0594e-02, -7.0721e-02,  5.2565e-02, -7.3323e-02,\n",
      "        -4.6125e-02, -6.4198e-02, -4.3608e-02,  2.8576e-02,  7.2139e-02,\n",
      "         1.7702e-02, -1.0718e-02,  1.6010e-02, -3.8687e-02, -5.9999e-02,\n",
      "         3.7078e-04, -5.7765e-02, -6.8050e-02, -7.4033e-02,  1.4980e-02,\n",
      "        -2.8884e-02,  7.6423e-02,  6.0145e-02,  2.5731e-02, -6.6069e-02,\n",
      "         7.1425e-02, -7.9647e-02, -7.0947e-02,  7.1391e-02, -3.6322e-02,\n",
      "         2.5504e-02, -7.1109e-02, -7.5576e-02, -5.1232e-02, -6.6893e-02,\n",
      "        -7.2956e-03,  6.7627e-02, -4.5587e-02, -7.6175e-02, -4.7044e-02,\n",
      "         7.4738e-02, -5.5483e-02,  5.6382e-02,  6.1644e-02,  2.9530e-02,\n",
      "        -6.4976e-03,  5.3595e-02,  1.7762e-03, -7.2422e-02,  7.5563e-02,\n",
      "         8.3001e-03,  2.2952e-02,  6.7391e-02,  7.5286e-02, -5.6174e-02,\n",
      "         8.4397e-03, -3.9993e-02, -6.9791e-02, -7.8334e-02,  9.7326e-03,\n",
      "         2.4716e-03, -6.6571e-02, -8.6390e-02, -6.4314e-02,  7.5510e-02,\n",
      "        -2.4401e-02, -4.3589e-02,  8.5004e-02,  7.5037e-02,  4.9075e-02,\n",
      "         7.8135e-02,  3.0568e-02,  8.7686e-02, -8.6677e-03, -4.7090e-02,\n",
      "        -4.9866e-02, -8.5539e-02, -6.1217e-02,  2.4945e-02, -8.2010e-02,\n",
      "         8.5009e-02,  8.6517e-02,  4.6845e-02, -3.0786e-02, -8.7334e-02,\n",
      "         8.4052e-02,  7.6252e-02,  8.7903e-02,  4.1272e-02,  4.1986e-02,\n",
      "         6.4444e-02,  4.7425e-02, -2.8753e-02,  5.3699e-02, -7.7446e-04,\n",
      "        -4.4633e-02,  4.4795e-02, -2.2784e-02, -7.9438e-02,  2.8175e-02,\n",
      "        -6.4086e-02,  8.3245e-02,  9.6783e-03, -7.7690e-02,  3.6040e-02,\n",
      "         2.8425e-02, -4.4057e-02,  7.9571e-02, -1.5219e-02, -4.0063e-02,\n",
      "        -5.8443e-02,  4.6643e-02,  9.2125e-03, -8.5269e-02, -1.5314e-02,\n",
      "        -1.3420e-04, -1.4354e-02, -5.8905e-04, -3.7669e-02,  7.0744e-02,\n",
      "        -2.6280e-02, -1.6954e-02, -6.1928e-02, -2.1433e-02,  6.5387e-02,\n",
      "        -2.3082e-02, -1.4844e-02, -1.5953e-02,  7.9271e-02,  7.5558e-02,\n",
      "        -8.2004e-02,  3.1639e-02,  8.3478e-02,  2.8943e-02,  7.5826e-02,\n",
      "         6.7611e-02, -4.9978e-02,  8.8028e-03,  5.1817e-02,  7.5833e-02,\n",
      "         7.0294e-02,  9.2894e-03, -4.2455e-02,  2.8859e-02,  2.3886e-02,\n",
      "         2.3034e-02,  6.4137e-02,  1.1248e-02, -8.0412e-02, -1.2675e-02,\n",
      "         3.3570e-03, -2.9523e-02,  3.9515e-02, -3.0343e-02,  3.6710e-02,\n",
      "         5.5661e-02, -5.4711e-02, -4.6778e-02,  6.2728e-03,  8.6564e-02,\n",
      "        -1.9007e-02, -8.3979e-02, -2.5558e-02,  7.0944e-03,  5.7355e-02,\n",
      "        -2.8008e-02, -6.9189e-02,  2.7744e-02,  6.8883e-02, -3.1237e-02,\n",
      "        -7.2332e-02,  5.3695e-02, -7.1443e-02,  8.5269e-02, -6.3804e-02,\n",
      "        -4.1528e-02, -3.7333e-02,  5.3162e-02, -4.1211e-02, -1.8435e-03,\n",
      "         4.1686e-02, -4.8673e-02,  1.6480e-02,  4.3348e-02,  4.8868e-02,\n",
      "        -8.4098e-02, -5.7775e-02,  8.4357e-02,  3.8608e-03,  8.2555e-02,\n",
      "        -6.7215e-02,  2.0300e-02,  7.9216e-03,  2.7156e-02, -2.5695e-02,\n",
      "         5.6180e-02,  7.3214e-02, -3.3590e-02, -4.8792e-02,  8.3330e-02,\n",
      "        -1.6748e-02,  2.2757e-02, -4.1838e-02,  3.7114e-02,  1.4861e-02,\n",
      "        -2.8119e-02,  2.6965e-02,  3.3640e-02,  5.6320e-02, -5.9796e-02,\n",
      "         7.6366e-02,  1.8636e-02,  7.5554e-02,  1.3065e-02, -7.1959e-02,\n",
      "         8.5670e-02,  2.2581e-04, -7.8628e-02,  2.1054e-02,  7.5528e-03,\n",
      "        -7.7697e-02, -4.5746e-02, -6.1692e-02,  4.9793e-03, -3.8138e-02,\n",
      "         5.0722e-03,  6.6403e-02, -1.6606e-02, -2.7379e-02,  1.4931e-02,\n",
      "         8.1896e-02,  8.3846e-02], requires_grad=True)\n",
      "Parameter name: LSTM.weight_ih_l1\n",
      "    Size : torch.Size([512, 128])\n",
      "    Value: Parameter containing:\n",
      "tensor([[-0.0480, -0.0218,  0.0219,  ...,  0.0185,  0.0459,  0.0032],\n",
      "        [ 0.0005, -0.0117,  0.0627,  ...,  0.0436,  0.0321,  0.0440],\n",
      "        [ 0.0231, -0.0047,  0.0220,  ...,  0.0143, -0.0395,  0.0267],\n",
      "        ...,\n",
      "        [-0.0342, -0.0574,  0.0849,  ...,  0.0658,  0.0867, -0.0713],\n",
      "        [-0.0649,  0.0777, -0.0453,  ..., -0.0034,  0.0085, -0.0385],\n",
      "        [-0.0267, -0.0846,  0.0819,  ..., -0.0607, -0.0189, -0.0574]],\n",
      "       requires_grad=True)\n",
      "Parameter name: LSTM.weight_hh_l1\n",
      "    Size : torch.Size([512, 128])\n",
      "    Value: Parameter containing:\n",
      "tensor([[-0.0056,  0.0457,  0.0473,  ..., -0.0602,  0.0347,  0.0169],\n",
      "        [ 0.0705, -0.0083,  0.0427,  ..., -0.0780, -0.0731,  0.0642],\n",
      "        [ 0.0517, -0.0561, -0.0070,  ..., -0.0568, -0.0337, -0.0638],\n",
      "        ...,\n",
      "        [-0.0551,  0.0255, -0.0822,  ...,  0.0612,  0.0078, -0.0261],\n",
      "        [-0.0586,  0.0646,  0.0630,  ...,  0.0352, -0.0300, -0.0592],\n",
      "        [-0.0423,  0.0768, -0.0712,  ...,  0.0790,  0.0299, -0.0202]],\n",
      "       requires_grad=True)\n",
      "Parameter name: LSTM.bias_ih_l1\n",
      "    Size : torch.Size([512])\n",
      "    Value: Parameter containing:\n",
      "tensor([-0.0177, -0.0348,  0.0271, -0.0291, -0.0749,  0.0618, -0.0749, -0.0218,\n",
      "         0.0343,  0.0602,  0.0585, -0.0342,  0.0094,  0.0324, -0.0341, -0.0219,\n",
      "         0.0116, -0.0792, -0.0541, -0.0400, -0.0384, -0.0497, -0.0524, -0.0665,\n",
      "        -0.0544,  0.0673, -0.0282, -0.0389, -0.0208, -0.0277,  0.0059, -0.0055,\n",
      "         0.0676, -0.0152,  0.0347,  0.0266, -0.0261, -0.0851,  0.0351,  0.0060,\n",
      "        -0.0757, -0.0176,  0.0236,  0.0844,  0.0297, -0.0271, -0.0380,  0.0487,\n",
      "        -0.0390, -0.0756, -0.0511,  0.0694, -0.0546, -0.0687, -0.0306, -0.0015,\n",
      "        -0.0189,  0.0522, -0.0513, -0.0351,  0.0438,  0.0836,  0.0192, -0.0715,\n",
      "        -0.0020, -0.0648,  0.0807,  0.0672, -0.0226, -0.0278,  0.0557, -0.0852,\n",
      "        -0.0586, -0.0448, -0.0212, -0.0528,  0.0645, -0.0358, -0.0474, -0.0079,\n",
      "         0.0006, -0.0588,  0.0410, -0.0233,  0.0338, -0.0007, -0.0670,  0.0839,\n",
      "         0.0282, -0.0104, -0.0773,  0.0592, -0.0788, -0.0247,  0.0247,  0.0748,\n",
      "         0.0419, -0.0237,  0.0365, -0.0470, -0.0650,  0.0046, -0.0602, -0.0150,\n",
      "        -0.0779,  0.0775,  0.0033,  0.0809,  0.0328,  0.0421, -0.0573,  0.0637,\n",
      "        -0.0774,  0.0670,  0.0695, -0.0541,  0.0801,  0.0034, -0.0314,  0.0719,\n",
      "        -0.0041,  0.0309, -0.0764, -0.0501,  0.0544,  0.0832, -0.0521,  0.0567,\n",
      "         0.0553,  0.0460, -0.0577,  0.0704, -0.0049, -0.0219,  0.0565,  0.0521,\n",
      "         0.0514, -0.0791, -0.0196,  0.0694, -0.0196,  0.0315,  0.0530, -0.0658,\n",
      "        -0.0843, -0.0083, -0.0269, -0.0183, -0.0214, -0.0675, -0.0282, -0.0515,\n",
      "         0.0385,  0.0173,  0.0757,  0.0230,  0.0664,  0.0821, -0.0411,  0.0160,\n",
      "        -0.0128, -0.0756, -0.0446, -0.0373,  0.0112, -0.0480, -0.0771, -0.0145,\n",
      "         0.0315, -0.0462, -0.0425,  0.0223,  0.0054, -0.0582,  0.0580,  0.0230,\n",
      "        -0.0346,  0.0330,  0.0696, -0.0067, -0.0181, -0.0052,  0.0824,  0.0113,\n",
      "         0.0484,  0.0214,  0.0530, -0.0015, -0.0506,  0.0811, -0.0743,  0.0390,\n",
      "         0.0325, -0.0814, -0.0062,  0.0008,  0.0370, -0.0150,  0.0858,  0.0009,\n",
      "        -0.0616, -0.0330,  0.0082,  0.0080,  0.0437,  0.0734,  0.0064,  0.0694,\n",
      "        -0.0862, -0.0426,  0.0761,  0.0865,  0.0576, -0.0869, -0.0812, -0.0420,\n",
      "         0.0562,  0.0369,  0.0853, -0.0883, -0.0403,  0.0644, -0.0245, -0.0682,\n",
      "        -0.0100,  0.0796,  0.0516, -0.0267, -0.0779,  0.0245, -0.0284, -0.0146,\n",
      "        -0.0008,  0.0206,  0.0231, -0.0617,  0.0295, -0.0152,  0.0312, -0.0298,\n",
      "         0.0136,  0.0087, -0.0443,  0.0295,  0.0379,  0.0855, -0.0078, -0.0234,\n",
      "         0.0766, -0.0024,  0.0578,  0.0622,  0.0472, -0.0636,  0.0293, -0.0206,\n",
      "        -0.0575, -0.0550, -0.0777, -0.0242,  0.0867, -0.0795, -0.0620,  0.0671,\n",
      "        -0.0607,  0.0415, -0.0057,  0.0321,  0.0358, -0.0742,  0.0109,  0.0447,\n",
      "        -0.0426, -0.0034, -0.0874,  0.0474, -0.0553, -0.0813, -0.0736,  0.0728,\n",
      "         0.0827, -0.0004, -0.0347, -0.0110,  0.0820, -0.0783, -0.0075, -0.0076,\n",
      "        -0.0190,  0.0071,  0.0002, -0.0719, -0.0280,  0.0327,  0.0258,  0.0425,\n",
      "        -0.0289, -0.0240,  0.0163,  0.0424,  0.0823, -0.0670,  0.0838, -0.0206,\n",
      "         0.0292,  0.0688,  0.0401,  0.0561,  0.0311, -0.0412,  0.0555, -0.0686,\n",
      "         0.0220, -0.0413, -0.0743, -0.0586, -0.0641,  0.0139,  0.0159, -0.0478,\n",
      "         0.0324, -0.0517,  0.0078, -0.0456, -0.0121, -0.0328, -0.0478,  0.0505,\n",
      "        -0.0353, -0.0806, -0.0688,  0.0061,  0.0048,  0.0440, -0.0263, -0.0105,\n",
      "         0.0264, -0.0179,  0.0170,  0.0730, -0.0284, -0.0224,  0.0804, -0.0434,\n",
      "         0.0246, -0.0267, -0.0373, -0.0184,  0.0314,  0.0562, -0.0543, -0.0124,\n",
      "         0.0547, -0.0737,  0.0618,  0.0306,  0.0281,  0.0843,  0.0141, -0.0229,\n",
      "         0.0053,  0.0417,  0.0778,  0.0183,  0.0622, -0.0362, -0.0489, -0.0792,\n",
      "        -0.0288, -0.0487,  0.0776, -0.0292, -0.0228, -0.0307, -0.0609,  0.0633,\n",
      "         0.0602,  0.0429, -0.0437,  0.0660, -0.0393,  0.0728, -0.0584, -0.0074,\n",
      "         0.0568, -0.0705,  0.0229, -0.0491,  0.0843, -0.0130, -0.0725,  0.0569,\n",
      "        -0.0186, -0.0415,  0.0130, -0.0853, -0.0884, -0.0373,  0.0817,  0.0087,\n",
      "        -0.0134, -0.0182,  0.0805, -0.0460,  0.0223, -0.0339,  0.0645, -0.0388,\n",
      "         0.0421,  0.0531, -0.0831,  0.0379, -0.0545, -0.0751,  0.0393, -0.0834,\n",
      "         0.0660, -0.0317, -0.0750,  0.0182, -0.0731, -0.0665,  0.0577, -0.0633,\n",
      "        -0.0713,  0.0345,  0.0582,  0.0497, -0.0624, -0.0783,  0.0810, -0.0425,\n",
      "        -0.0108,  0.0706,  0.0013,  0.0227,  0.0699,  0.0374, -0.0676, -0.0419,\n",
      "         0.0881, -0.0142, -0.0049,  0.0439,  0.0648, -0.0390,  0.0516, -0.0873,\n",
      "         0.0084,  0.0674, -0.0365,  0.0004, -0.0281, -0.0102,  0.0497,  0.0536,\n",
      "         0.0665, -0.0513,  0.0626, -0.0251, -0.0653, -0.0299,  0.0078,  0.0854,\n",
      "        -0.0440, -0.0802, -0.0283,  0.0770,  0.0335,  0.0319,  0.0587,  0.0670,\n",
      "         0.0113,  0.0823,  0.0713, -0.0868, -0.0794, -0.0262,  0.0027, -0.0317,\n",
      "         0.0366,  0.0565,  0.0018, -0.0609,  0.0646, -0.0478, -0.0455, -0.0729,\n",
      "        -0.0604, -0.0163,  0.0587,  0.0611, -0.0210,  0.0414,  0.0155, -0.0005,\n",
      "        -0.0503,  0.0006,  0.0707, -0.0625,  0.0763, -0.0399,  0.0359,  0.0654,\n",
      "         0.0601,  0.0703,  0.0195,  0.0056,  0.0511,  0.0605, -0.0325, -0.0161],\n",
      "       requires_grad=True)\n",
      "Parameter name: LSTM.bias_hh_l1\n",
      "    Size : torch.Size([512])\n",
      "    Value: Parameter containing:\n",
      "tensor([-0.0310, -0.0538,  0.0741,  0.0791,  0.0091,  0.0786,  0.0436, -0.0655,\n",
      "        -0.0554,  0.0284,  0.0576,  0.0713,  0.0207,  0.0482,  0.0477,  0.0489,\n",
      "         0.0848, -0.0417, -0.0490, -0.0002, -0.0516, -0.0217, -0.0516, -0.0273,\n",
      "        -0.0747,  0.0401,  0.0154, -0.0489, -0.0660,  0.0370,  0.0482,  0.0365,\n",
      "        -0.0138, -0.0775, -0.0831, -0.0137,  0.0258, -0.0470, -0.0404, -0.0566,\n",
      "         0.0873, -0.0881, -0.0747,  0.0568, -0.0156, -0.0652,  0.0861,  0.0666,\n",
      "         0.0470,  0.0656,  0.0631, -0.0310,  0.0819,  0.0637,  0.0275, -0.0628,\n",
      "        -0.0848, -0.0757,  0.0261, -0.0667,  0.0131, -0.0053, -0.0809,  0.0647,\n",
      "         0.0431, -0.0684, -0.0608,  0.0146,  0.0165, -0.0614,  0.0342,  0.0382,\n",
      "         0.0362,  0.0287, -0.0579,  0.0251, -0.0362,  0.0527,  0.0570, -0.0277,\n",
      "         0.0117,  0.0328, -0.0856, -0.0050,  0.0811,  0.0074,  0.0397,  0.0457,\n",
      "        -0.0488,  0.0424,  0.0143,  0.0071,  0.0595,  0.0480, -0.0051,  0.0374,\n",
      "        -0.0311,  0.0804, -0.0109,  0.0707,  0.0634,  0.0570,  0.0249,  0.0219,\n",
      "         0.0243,  0.0717,  0.0477, -0.0289, -0.0382, -0.0767,  0.0223,  0.0306,\n",
      "         0.0738,  0.0843,  0.0310, -0.0494,  0.0324,  0.0139,  0.0276,  0.0597,\n",
      "        -0.0470, -0.0737, -0.0174, -0.0378, -0.0203, -0.0416, -0.0831,  0.0285,\n",
      "         0.0519, -0.0389,  0.0799, -0.0124, -0.0813, -0.0656, -0.0289, -0.0072,\n",
      "        -0.0564,  0.0497,  0.0635,  0.0630, -0.0220, -0.0657,  0.0419,  0.0051,\n",
      "         0.0252,  0.0081, -0.0596,  0.0629,  0.0557,  0.0849, -0.0843, -0.0780,\n",
      "        -0.0732,  0.0167,  0.0156,  0.0702, -0.0321, -0.0318,  0.0714,  0.0741,\n",
      "         0.0346,  0.0498,  0.0312, -0.0825,  0.0223,  0.0539, -0.0424,  0.0653,\n",
      "         0.0041, -0.0428,  0.0786, -0.0667, -0.0045,  0.0560, -0.0616, -0.0511,\n",
      "        -0.0246,  0.0413, -0.0709, -0.0639, -0.0086, -0.0386, -0.0091, -0.0730,\n",
      "         0.0180, -0.0064, -0.0268,  0.0791, -0.0607, -0.0218,  0.0450, -0.0729,\n",
      "        -0.0394, -0.0499, -0.0751,  0.0127,  0.0064,  0.0711, -0.0603, -0.0220,\n",
      "         0.0214,  0.0055,  0.0184,  0.0813, -0.0847,  0.0615, -0.0850,  0.0828,\n",
      "        -0.0548,  0.0783,  0.0349,  0.0315,  0.0753, -0.0314, -0.0487, -0.0478,\n",
      "        -0.0749, -0.0619, -0.0304, -0.0786, -0.0148,  0.0789,  0.0642,  0.0708,\n",
      "         0.0279, -0.0728, -0.0025, -0.0219, -0.0875,  0.0405, -0.0362, -0.0757,\n",
      "        -0.0798,  0.0738, -0.0789,  0.0234,  0.0536,  0.0649,  0.0277,  0.0098,\n",
      "         0.0328, -0.0330,  0.0695, -0.0201,  0.0697,  0.0745,  0.0257,  0.0100,\n",
      "        -0.0842, -0.0299, -0.0716,  0.0107,  0.0130,  0.0667, -0.0414,  0.0021,\n",
      "         0.0629,  0.0616,  0.0601,  0.0656, -0.0065,  0.0509,  0.0806,  0.0720,\n",
      "         0.0687,  0.0446,  0.0321, -0.0021, -0.0340, -0.0628,  0.0103,  0.0234,\n",
      "         0.0491, -0.0542, -0.0683, -0.0474, -0.0021,  0.0088, -0.0347, -0.0432,\n",
      "         0.0256, -0.0175,  0.0004,  0.0884, -0.0686,  0.0476,  0.0742, -0.0798,\n",
      "         0.0757,  0.0592,  0.0092,  0.0310,  0.0107, -0.0010,  0.0216, -0.0178,\n",
      "         0.0482,  0.0473,  0.0243, -0.0278, -0.0066,  0.0380, -0.0529,  0.0015,\n",
      "         0.0534, -0.0241,  0.0182, -0.0587,  0.0596, -0.0194,  0.0833,  0.0304,\n",
      "         0.0105,  0.0244, -0.0866,  0.0713, -0.0208,  0.0839, -0.0865, -0.0402,\n",
      "         0.0701,  0.0098, -0.0706,  0.0155,  0.0707,  0.0744,  0.0758, -0.0562,\n",
      "        -0.0076,  0.0437, -0.0497, -0.0762, -0.0402,  0.0780,  0.0719,  0.0523,\n",
      "         0.0681,  0.0291, -0.0764, -0.0193, -0.0136, -0.0147,  0.0235, -0.0167,\n",
      "         0.0748,  0.0150, -0.0141, -0.0557, -0.0400,  0.0234, -0.0822,  0.0244,\n",
      "        -0.0179,  0.0772,  0.0761,  0.0353, -0.0137,  0.0797, -0.0277, -0.0409,\n",
      "         0.0455, -0.0491, -0.0585, -0.0662,  0.0340, -0.0490,  0.0870,  0.0794,\n",
      "        -0.0845,  0.0255,  0.0392,  0.0103,  0.0187,  0.0619,  0.0761,  0.0627,\n",
      "        -0.0699,  0.0875, -0.0201,  0.0655,  0.0221, -0.0383, -0.0311,  0.0629,\n",
      "        -0.0494, -0.0873,  0.0232, -0.0562, -0.0307,  0.0847, -0.0368, -0.0012,\n",
      "         0.0375,  0.0507, -0.0284,  0.0660, -0.0162, -0.0447,  0.0001, -0.0725,\n",
      "        -0.0065, -0.0831, -0.0303,  0.0210, -0.0806, -0.0773, -0.0706,  0.0447,\n",
      "         0.0560,  0.0768, -0.0847,  0.0516, -0.0771, -0.0584,  0.0636,  0.0124,\n",
      "         0.0839, -0.0438, -0.0834,  0.0004,  0.0276,  0.0171,  0.0015,  0.0667,\n",
      "         0.0250,  0.0394,  0.0247,  0.0824, -0.0363, -0.0028,  0.0400,  0.0164,\n",
      "         0.0860, -0.0640, -0.0843, -0.0280,  0.0404, -0.0740,  0.0105,  0.0702,\n",
      "         0.0180,  0.0171, -0.0334, -0.0073,  0.0517, -0.0067,  0.0460,  0.0773,\n",
      "         0.0667, -0.0691,  0.0307, -0.0683,  0.0787,  0.0819, -0.0015, -0.0572,\n",
      "         0.0402, -0.0091,  0.0482, -0.0488, -0.0623,  0.0694,  0.0550, -0.0856,\n",
      "        -0.0721,  0.0233, -0.0244, -0.0002,  0.0412, -0.0726, -0.0498,  0.0830,\n",
      "         0.0261,  0.0364,  0.0229, -0.0587, -0.0459,  0.0265, -0.0376,  0.0400,\n",
      "        -0.0651,  0.0660,  0.0643, -0.0824, -0.0013, -0.0743, -0.0470,  0.0135,\n",
      "        -0.0880,  0.0614, -0.0053,  0.0463, -0.0657,  0.0308,  0.0460, -0.0737,\n",
      "         0.0155, -0.0653,  0.0731, -0.0624, -0.0158,  0.0211, -0.0272,  0.0036,\n",
      "         0.0506, -0.0582, -0.0811, -0.0357, -0.0738, -0.0223, -0.0513,  0.0490],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "input_dim = len(de_vocab)\n",
    "output_dim = len(en_vocab)\n",
    "encoder_embedding_dim = 300\n",
    "decoder_embedding_dim = 300\n",
    "hidden_dim = 128\n",
    "num_layers = 2\n",
    "encoder_dropout = 0.5\n",
    "decoder_dropout = 0.5\n",
    "pad_index = pad_index\n",
    "lr = 5e-4\n",
    "\n",
    "encoder = Encoder(input_dim= input_dim,\n",
    "                  embedding_dim= encoder_embedding_dim,\n",
    "                  hidden_dim= hidden_dim,\n",
    "                  num_layers= num_layers,\n",
    "                  dropout_rate= encoder_dropout,\n",
    "                  pad_idx= pad_index)\n",
    "\n",
    "decoder = Decoder(output_dim= output_dim,\n",
    "                  embedding_dim= decoder_embedding_dim,\n",
    "                  hidden_dim= hidden_dim,\n",
    "                  num_layers= num_layers,\n",
    "                  dropout_rate= decoder_dropout,\n",
    "                  pad_idx= pad_index)\n",
    "\n",
    "model = seq2seq_Translation(encoder, decoder)\n",
    "\n",
    "pprint(\"Model's state_dict:\")\n",
    "for name, param in encoder.named_parameters():\n",
    "    print(f\"Parameter name: {name}\")\n",
    "    print(f\"    Size : {param.size()}\")\n",
    "    print(f\"    Value: {param}\")\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(ignore_index= pad_index)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-3. Weight Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            torch.nn.init.xavier_uniform_(param)\n",
    "        if 'bias' in name:\n",
    "            nn.init.constant_(param, 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "seq2seq_Translation(\n",
       "  (Encoder): Encoder(\n",
       "    (embedding): Embedding(18669, 300, padding_idx=1)\n",
       "    (LSTM): LSTM(300, 128, num_layers=2, batch_first=True, dropout=0.5)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (Decoder): Decoder(\n",
       "    (embedding): Embedding(9797, 300, padding_idx=1)\n",
       "    (LSTM): LSTM(300, 128, num_layers=2, batch_first=True, dropout=0.5)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (fc): Linear(in_features=128, out_features=9797, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 614,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.apply(initialize_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Model's state_dict:\"\n",
      "Parameter name: Encoder.embedding.weight\n",
      "    Size : torch.Size([18669, 300])\n",
      "    Value: Parameter containing:\n",
      "tensor([[ 0.0176,  0.0123, -0.0130,  ...,  0.0082,  0.0014,  0.0100],\n",
      "        [ 0.0031, -0.0149,  0.0064,  ...,  0.0079, -0.0143, -0.0139],\n",
      "        [-0.0052, -0.0144, -0.0024,  ..., -0.0143, -0.0132,  0.0173],\n",
      "        ...,\n",
      "        [ 0.0121,  0.0175, -0.0127,  ...,  0.0029, -0.0003, -0.0037],\n",
      "        [ 0.0057, -0.0128, -0.0040,  ..., -0.0007,  0.0061, -0.0090],\n",
      "        [ 0.0131,  0.0146,  0.0012,  ...,  0.0006, -0.0146,  0.0121]],\n",
      "       requires_grad=True)\n",
      "Parameter name: Encoder.LSTM.weight_ih_l0\n",
      "    Size : torch.Size([512, 300])\n",
      "    Value: Parameter containing:\n",
      "tensor([[ 0.0150, -0.0537,  0.0305,  ...,  0.0462,  0.0269,  0.0478],\n",
      "        [-0.0723, -0.0568, -0.0062,  ...,  0.0343,  0.0125, -0.0799],\n",
      "        [ 0.0311,  0.0803, -0.0012,  ...,  0.0083,  0.0809,  0.0230],\n",
      "        ...,\n",
      "        [ 0.0247,  0.0680, -0.0270,  ..., -0.0469, -0.0583,  0.0703],\n",
      "        [ 0.0263, -0.0394,  0.0369,  ...,  0.0038,  0.0058,  0.0364],\n",
      "        [ 0.0023, -0.0745, -0.0426,  ...,  0.0263,  0.0588,  0.0734]],\n",
      "       requires_grad=True)\n",
      "Parameter name: Encoder.LSTM.weight_hh_l0\n",
      "    Size : torch.Size([512, 128])\n",
      "    Value: Parameter containing:\n",
      "tensor([[ 0.0846, -0.0452, -0.0940,  ...,  0.0486,  0.0882,  0.0630],\n",
      "        [ 0.0247, -0.0497,  0.0536,  ...,  0.0712,  0.0145,  0.0262],\n",
      "        [ 0.0294, -0.0111, -0.0550,  ...,  0.0709, -0.0548, -0.0431],\n",
      "        ...,\n",
      "        [ 0.0297,  0.0144, -0.0939,  ...,  0.0569,  0.0582,  0.0963],\n",
      "        [-0.0072,  0.0699,  0.0612,  ...,  0.0370,  0.0529, -0.0804],\n",
      "        [ 0.0373,  0.0963, -0.0670,  ..., -0.0618,  0.0957,  0.0960]],\n",
      "       requires_grad=True)\n",
      "Parameter name: Encoder.LSTM.bias_ih_l0\n",
      "    Size : torch.Size([512])\n",
      "    Value: Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter name: Encoder.LSTM.bias_hh_l0\n",
      "    Size : torch.Size([512])\n",
      "    Value: Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter name: Encoder.LSTM.weight_ih_l1\n",
      "    Size : torch.Size([512, 128])\n",
      "    Value: Parameter containing:\n",
      "tensor([[-0.0614,  0.0008, -0.0834,  ...,  0.0153, -0.0946,  0.0819],\n",
      "        [-0.0923, -0.0483,  0.0684,  ...,  0.0511,  0.0862,  0.0329],\n",
      "        [ 0.0038,  0.0074, -0.0645,  ..., -0.0432,  0.0376, -0.0698],\n",
      "        ...,\n",
      "        [-0.0769,  0.0896,  0.0261,  ..., -0.0226,  0.0587, -0.0288],\n",
      "        [ 0.0775, -0.0121, -0.0754,  ..., -0.0200,  0.0791,  0.0275],\n",
      "        [-0.0591, -0.0235, -0.0547,  ..., -0.0873, -0.0026,  0.0191]],\n",
      "       requires_grad=True)\n",
      "Parameter name: Encoder.LSTM.weight_hh_l1\n",
      "    Size : torch.Size([512, 128])\n",
      "    Value: Parameter containing:\n",
      "tensor([[-8.4702e-02,  4.7244e-02,  9.5867e-02,  ...,  6.0931e-02,\n",
      "         -2.4037e-02,  9.4047e-05],\n",
      "        [-3.8415e-02,  6.1884e-03, -4.8984e-02,  ..., -5.7042e-02,\n",
      "          6.7367e-02, -5.7983e-02],\n",
      "        [-7.6025e-02, -3.4797e-02,  9.1241e-02,  ..., -2.5832e-02,\n",
      "         -6.7302e-02, -7.6373e-02],\n",
      "        ...,\n",
      "        [-5.6122e-02, -5.9140e-02, -5.1000e-02,  ...,  1.9249e-02,\n",
      "          8.7319e-02,  6.7888e-02],\n",
      "        [-4.4763e-02, -5.4527e-02,  6.3612e-02,  ..., -1.2684e-02,\n",
      "          3.8807e-02,  7.1097e-02],\n",
      "        [ 4.6182e-02,  6.9006e-02,  3.4982e-02,  ...,  8.7510e-02,\n",
      "          3.6071e-02,  4.5559e-02]], requires_grad=True)\n",
      "Parameter name: Encoder.LSTM.bias_ih_l1\n",
      "    Size : torch.Size([512])\n",
      "    Value: Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter name: Encoder.LSTM.bias_hh_l1\n",
      "    Size : torch.Size([512])\n",
      "    Value: Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter name: Decoder.embedding.weight\n",
      "    Size : torch.Size([9797, 300])\n",
      "    Value: Parameter containing:\n",
      "tensor([[ 0.0037, -0.0166,  0.0228,  ...,  0.0038, -0.0102,  0.0082],\n",
      "        [-0.0068, -0.0117,  0.0125,  ...,  0.0066, -0.0220, -0.0228],\n",
      "        [-0.0035,  0.0233, -0.0008,  ..., -0.0081,  0.0197,  0.0135],\n",
      "        ...,\n",
      "        [-0.0185, -0.0027,  0.0141,  ..., -0.0084,  0.0097, -0.0195],\n",
      "        [ 0.0077, -0.0156, -0.0114,  ..., -0.0019, -0.0036,  0.0075],\n",
      "        [-0.0159,  0.0180,  0.0241,  ..., -0.0030, -0.0045, -0.0007]],\n",
      "       requires_grad=True)\n",
      "Parameter name: Decoder.LSTM.weight_ih_l0\n",
      "    Size : torch.Size([512, 300])\n",
      "    Value: Parameter containing:\n",
      "tensor([[-0.0088,  0.0830, -0.0459,  ..., -0.0155, -0.0516, -0.0504],\n",
      "        [ 0.0170, -0.0270, -0.0839,  ...,  0.0078,  0.0820, -0.0837],\n",
      "        [ 0.0727, -0.0634,  0.0571,  ...,  0.0272, -0.0803,  0.0520],\n",
      "        ...,\n",
      "        [-0.0372, -0.0603,  0.0372,  ..., -0.0568,  0.0839, -0.0219],\n",
      "        [-0.0697, -0.0714,  0.0467,  ...,  0.0277,  0.0828,  0.0622],\n",
      "        [ 0.0613,  0.0052,  0.0014,  ..., -0.0650, -0.0852, -0.0765]],\n",
      "       requires_grad=True)\n",
      "Parameter name: Decoder.LSTM.weight_hh_l0\n",
      "    Size : torch.Size([512, 128])\n",
      "    Value: Parameter containing:\n",
      "tensor([[-0.0368,  0.0857, -0.0018,  ...,  0.0911,  0.0723, -0.0272],\n",
      "        [ 0.0741,  0.0678, -0.0651,  ..., -0.0687,  0.0659,  0.0578],\n",
      "        [ 0.0883, -0.0763, -0.0895,  ...,  0.0235, -0.0785, -0.0700],\n",
      "        ...,\n",
      "        [ 0.0919,  0.0380, -0.0058,  ...,  0.0091, -0.0359,  0.0700],\n",
      "        [-0.0010, -0.0363,  0.0398,  ..., -0.0013,  0.0477, -0.0392],\n",
      "        [ 0.0177, -0.0479, -0.0339,  ..., -0.0660, -0.0658,  0.0859]],\n",
      "       requires_grad=True)\n",
      "Parameter name: Decoder.LSTM.bias_ih_l0\n",
      "    Size : torch.Size([512])\n",
      "    Value: Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter name: Decoder.LSTM.bias_hh_l0\n",
      "    Size : torch.Size([512])\n",
      "    Value: Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter name: Decoder.LSTM.weight_ih_l1\n",
      "    Size : torch.Size([512, 128])\n",
      "    Value: Parameter containing:\n",
      "tensor([[ 0.0252,  0.0238, -0.0736,  ..., -0.0145,  0.0413, -0.0229],\n",
      "        [ 0.0072,  0.0198, -0.0445,  ...,  0.0963, -0.0770, -0.0260],\n",
      "        [-0.0421, -0.0253,  0.0928,  ...,  0.0692, -0.0009,  0.0609],\n",
      "        ...,\n",
      "        [ 0.0464,  0.0811,  0.0228,  ..., -0.0488, -0.0931,  0.0220],\n",
      "        [ 0.0303, -0.0380, -0.0936,  ...,  0.0094, -0.0577,  0.0399],\n",
      "        [-0.0347, -0.0135, -0.0298,  ...,  0.0782, -0.0488, -0.0539]],\n",
      "       requires_grad=True)\n",
      "Parameter name: Decoder.LSTM.weight_hh_l1\n",
      "    Size : torch.Size([512, 128])\n",
      "    Value: Parameter containing:\n",
      "tensor([[-0.0760, -0.0089,  0.0227,  ..., -0.0435,  0.0381,  0.0571],\n",
      "        [ 0.0910,  0.0448,  0.0042,  ...,  0.0186,  0.0171, -0.0843],\n",
      "        [ 0.0755, -0.0135,  0.0948,  ...,  0.0411,  0.0444, -0.0084],\n",
      "        ...,\n",
      "        [-0.0866, -0.0351,  0.0075,  ...,  0.0120,  0.0002,  0.0404],\n",
      "        [-0.0620,  0.0352, -0.0606,  ...,  0.0549, -0.0899, -0.0755],\n",
      "        [ 0.0676, -0.0530,  0.0375,  ..., -0.0435, -0.0518,  0.0123]],\n",
      "       requires_grad=True)\n",
      "Parameter name: Decoder.LSTM.bias_ih_l1\n",
      "    Size : torch.Size([512])\n",
      "    Value: Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter name: Decoder.LSTM.bias_hh_l1\n",
      "    Size : torch.Size([512])\n",
      "    Value: Parameter containing:\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n",
      "Parameter name: Decoder.fc.weight\n",
      "    Size : torch.Size([9797, 128])\n",
      "    Value: Parameter containing:\n",
      "tensor([[-0.0029,  0.0116,  0.0013,  ..., -0.0062,  0.0220,  0.0228],\n",
      "        [-0.0193,  0.0175, -0.0018,  ..., -0.0086,  0.0224, -0.0219],\n",
      "        [ 0.0015, -0.0141,  0.0153,  ..., -0.0182, -0.0160, -0.0245],\n",
      "        ...,\n",
      "        [-0.0184, -0.0217,  0.0186,  ...,  0.0108, -0.0165,  0.0119],\n",
      "        [-0.0146,  0.0123, -0.0068,  ...,  0.0126, -0.0232, -0.0076],\n",
      "        [-0.0151, -0.0203, -0.0059,  ..., -0.0091,  0.0181, -0.0005]],\n",
      "       requires_grad=True)\n",
      "Parameter name: Decoder.fc.bias\n",
      "    Size : torch.Size([9797])\n",
      "    Value: Parameter containing:\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "pprint(\"Model's state_dict:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Parameter name: {name}\")\n",
    "    print(f\"    Size : {param.size()}\")\n",
    "    print(f\"    Value: {param}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 10,508,125 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "print(f\"The model has {count_parameters(model):,} trainable parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": 617,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)\n",
    "criterion.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(model, trainloader, criterion, optimizer, clip, teacher_forcing_ratio):\n",
    "        \n",
    "    model.train()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for batch in tqdm(trainloader):\n",
    "        \n",
    "        # source: Tensor, 'batch_size, seq_length'\n",
    "        # target: Tensor, 'batch_size, seq_length'\n",
    "        source = batch['de_ids'].to(device)\n",
    "        target = batch['en_ids'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # logit_seq: Tensor, 'batch_size, seq_length, output_dim'\n",
    "        logit_seq = model(source = source, \n",
    "                          target = target, \n",
    "                          teacher_forcing_ratio = teacher_forcing_ratio)\n",
    "        \n",
    "        output_dim = model.Decoder.output_dim\n",
    "\n",
    "        # logits = 'batch_size * seq_length - 1), output_dim'\n",
    "        # target: Tensor, 'batch_size * (seq_length - 1)'\n",
    "        logits = logit_seq[:, 1:, :].reshape(-1, output_dim)\n",
    "        target = target[:, 1:].reshape(-1)\n",
    "\n",
    "        loss = criterion(logits, target)\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * source.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(trainloader.dataset)\n",
    "    \n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_fn(model, validloader, criterion, teacher_forcing_ratio):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(validloader):\n",
    "\n",
    "            # source: Tensor, 'batch_size, seq_length'\n",
    "            # target: Tensor, 'batch_size, seq_length'\n",
    "            source = batch['de_ids'].to(device)\n",
    "            target = batch['en_ids'].to(device)\n",
    "\n",
    "            # logit_seq: Tensor, 'batch_size, seq_length, output_dim'\n",
    "            logit_seq = model(source = source, \n",
    "                              target = target, \n",
    "                              teacher_forcing_ratio = teacher_forcing_ratio)\n",
    "\n",
    "            output_dim = model.Decoder.output_dim\n",
    "\n",
    "            # logits: Tensor, 'batch_size * (seq_length - 1), output_dim'\n",
    "            # target: Tensor, 'batch_size * (seq_length - 1)'\n",
    "            logits = logit_seq[:, 1:, :].reshape(-1, output_dim)\n",
    "            target = target[:, 1:].reshape(-1)\n",
    "\n",
    "            loss = criterion(logits, target)\n",
    "            \n",
    "            running_loss += loss.item() * source.size(0)\n",
    "        \n",
    "        epoch_loss = running_loss / len(validloader.dataset)\n",
    "        \n",
    "    return epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, trainloader, validloader, clip, teacher_forcing_ratio, num_epochs):\n",
    "    print(\"-----Training Started------\")\n",
    "\n",
    "    best_valid_loss = float(\"inf\")\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "              \n",
    "        train_loss = train_fn(model= model,\n",
    "                              trainloader= trainloader,\n",
    "                              criterion= criterion,\n",
    "                              optimizer= optimizer,\n",
    "                              clip = clip,\n",
    "                              teacher_forcing_ratio= teacher_forcing_ratio)\n",
    "        \n",
    "        valid_loss = evaluate_fn(model= model,\n",
    "                                 validloader= validloader,\n",
    "                                 criterion= criterion,\n",
    "                                 teacher_forcing_ratio= 0.0)\n",
    "\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "\n",
    "            torch.save(model.state_dict(), model_dir)\n",
    "            \n",
    "        print(f\"\\tTrain Loss: {train_loss:7.3f} | Train PPL: {np.exp(train_loss):7.3f}\")\n",
    "        print(f\"\\tValid Loss: {valid_loss:7.3f} | Valid PPL: {np.exp(valid_loss):7.3f}\")\n",
    "    \n",
    "    print(\"-----Training Completed-----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Training Started------\n",
      "Epoch [1/16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [00:25<00:00,  8.75it/s]\n",
      "100%|██████████| 227/227 [00:15<00:00, 14.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   5.966 | Train PPL: 389.767\n",
      "\tValid Loss:   5.352 | Valid PPL: 210.935\n",
      "Epoch [2/16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [00:26<00:00,  8.59it/s]\n",
      "100%|██████████| 227/227 [00:15<00:00, 14.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   5.309 | Train PPL: 202.160\n",
      "\tValid Loss:   5.234 | Valid PPL: 187.585\n",
      "Epoch [3/16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [00:25<00:00,  8.82it/s]\n",
      "100%|██████████| 227/227 [00:15<00:00, 14.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   5.180 | Train PPL: 177.697\n",
      "\tValid Loss:   5.095 | Valid PPL: 163.204\n",
      "Epoch [4/16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [00:25<00:00,  8.83it/s]\n",
      "100%|██████████| 227/227 [00:15<00:00, 14.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   4.995 | Train PPL: 147.710\n",
      "\tValid Loss:   5.012 | Valid PPL: 150.146\n",
      "Epoch [5/16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [00:25<00:00,  8.87it/s]\n",
      "100%|██████████| 227/227 [00:15<00:00, 14.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   4.832 | Train PPL: 125.488\n",
      "\tValid Loss:   4.991 | Valid PPL: 147.093\n",
      "Epoch [6/16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [00:26<00:00,  8.65it/s]\n",
      "100%|██████████| 227/227 [00:15<00:00, 14.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   4.712 | Train PPL: 111.233\n",
      "\tValid Loss:   4.934 | Valid PPL: 138.959\n",
      "Epoch [7/16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [00:26<00:00,  8.58it/s]\n",
      "100%|██████████| 227/227 [00:15<00:00, 14.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   4.602 | Train PPL:  99.667\n",
      "\tValid Loss:   4.871 | Valid PPL: 130.504\n",
      "Epoch [8/16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [00:26<00:00,  8.53it/s]\n",
      "100%|██████████| 227/227 [00:15<00:00, 14.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   4.478 | Train PPL:  88.071\n",
      "\tValid Loss:   4.753 | Valid PPL: 115.910\n",
      "Epoch [9/16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [00:26<00:00,  8.56it/s]\n",
      "100%|██████████| 227/227 [00:15<00:00, 14.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   4.375 | Train PPL:  79.450\n",
      "\tValid Loss:   4.692 | Valid PPL: 109.051\n",
      "Epoch [10/16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [00:26<00:00,  8.59it/s]\n",
      "100%|██████████| 227/227 [00:15<00:00, 14.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   4.286 | Train PPL:  72.704\n",
      "\tValid Loss:   4.640 | Valid PPL: 103.579\n",
      "Epoch [11/16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [00:26<00:00,  8.65it/s]\n",
      "100%|██████████| 227/227 [00:15<00:00, 14.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   4.219 | Train PPL:  67.934\n",
      "\tValid Loss:   4.599 | Valid PPL:  99.336\n",
      "Epoch [12/16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [00:25<00:00,  8.79it/s]\n",
      "100%|██████████| 227/227 [00:15<00:00, 14.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   4.164 | Train PPL:  64.307\n",
      "\tValid Loss:   4.556 | Valid PPL:  95.200\n",
      "Epoch [13/16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [00:26<00:00,  8.55it/s]\n",
      "100%|██████████| 227/227 [00:15<00:00, 14.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   4.105 | Train PPL:  60.631\n",
      "\tValid Loss:   4.518 | Valid PPL:  91.676\n",
      "Epoch [14/16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [00:26<00:00,  8.57it/s]\n",
      "100%|██████████| 227/227 [00:15<00:00, 14.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   4.047 | Train PPL:  57.201\n",
      "\tValid Loss:   4.494 | Valid PPL:  89.507\n",
      "Epoch [15/16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [00:26<00:00,  8.58it/s]\n",
      "100%|██████████| 227/227 [00:15<00:00, 14.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   4.004 | Train PPL:  54.794\n",
      "\tValid Loss:   4.434 | Valid PPL:  84.252\n",
      "Epoch [16/16]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 227/227 [00:26<00:00,  8.54it/s]\n",
      "100%|██████████| 227/227 [00:15<00:00, 14.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tTrain Loss:   3.960 | Train PPL:  52.479\n",
      "\tValid Loss:   4.379 | Valid PPL:  79.739\n",
      "-----Training Completed-----\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 16\n",
    "\n",
    "clip = 1.0\n",
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "train_model(model, criterion, optimizer, trainloader, validloader, clip, teacher_forcing_ratio, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 13.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 4.603 | Test PPL:  99.784 |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss = evaluate_fn(model, testloader, criterion, teacher_forcing_ratio = 0)\n",
    "\n",
    "print(f\"| Test Loss: {test_loss:.3f} | Test PPL: {np.exp(test_loss):7.3f} |\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Inference"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study-mldl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
