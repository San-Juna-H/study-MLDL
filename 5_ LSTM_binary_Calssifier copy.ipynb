{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Introduction\n","\n","based on : https://github.com/bentrevett/pytorch-sentiment-analysis\n","\n","one-layer RNN Classifier with IMDB datasets\n","used pytorch LSTM"]},{"cell_type":"markdown","metadata":{},"source":["# 0. Set Environment"]},{"cell_type":"code","execution_count":126,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T05:51:20.087127Z","iopub.status.busy":"2024-05-09T05:51:20.086594Z","iopub.status.idle":"2024-05-09T05:51:20.094575Z","shell.execute_reply":"2024-05-09T05:51:20.092979Z","shell.execute_reply.started":"2024-05-09T05:51:20.087090Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n","import torchtext\n","torchtext.disable_torchtext_deprecation_warning()\n","from torchtext.data import get_tokenizer\n","from torchtext.vocab import build_vocab_from_iterator\n","from torch.utils.tensorboard import SummaryWriter\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","from pprint import pprint\n","\n","import subprocess\n","import os\n","import sys\n","\n","import datasets"]},{"cell_type":"code","execution_count":127,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T04:33:02.055460Z","iopub.status.busy":"2024-05-09T04:33:02.055071Z","iopub.status.idle":"2024-05-09T04:33:02.061661Z","shell.execute_reply":"2024-05-09T04:33:02.060618Z","shell.execute_reply.started":"2024-05-09T04:33:02.055426Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Selected device: cuda\n"]}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(\"Selected device:\", device)"]},{"cell_type":"code","execution_count":128,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T04:33:02.063226Z","iopub.status.busy":"2024-05-09T04:33:02.062835Z","iopub.status.idle":"2024-05-09T04:33:02.076477Z","shell.execute_reply":"2024-05-09T04:33:02.075456Z","shell.execute_reply.started":"2024-05-09T04:33:02.063197Z"},"trusted":true},"outputs":[],"source":["seed = 42\n","\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)\n","torch.backends.cudnn.deterministic = True"]},{"cell_type":"code","execution_count":129,"metadata":{},"outputs":[],"source":["model_dir = './models/LSTM_Classifier_model.pth'\n","pretrained_embedding_dir = './models/Glove_pretrained.pth'"]},{"cell_type":"markdown","metadata":{},"source":["# 1. Data processing"]},{"cell_type":"markdown","metadata":{},"source":["## 1-1. Get Data"]},{"cell_type":"code","execution_count":130,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T04:33:02.087466Z","iopub.status.busy":"2024-05-09T04:33:02.087111Z","iopub.status.idle":"2024-05-09T04:33:08.436868Z","shell.execute_reply":"2024-05-09T04:33:08.435884Z","shell.execute_reply.started":"2024-05-09T04:33:02.087440Z"},"trusted":true},"outputs":[],"source":["train_data, test_data = datasets.load_dataset(\"imdb\", split=[\"train\", \"test\"])"]},{"cell_type":"markdown","metadata":{},"source":["## 1-2. Tokenize"]},{"cell_type":"code","execution_count":131,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T04:33:12.928637Z","iopub.status.busy":"2024-05-09T04:33:12.928257Z","iopub.status.idle":"2024-05-09T04:33:12.934105Z","shell.execute_reply":"2024-05-09T04:33:12.933039Z","shell.execute_reply.started":"2024-05-09T04:33:12.928609Z"},"trusted":true},"outputs":[],"source":["tokenizer = get_tokenizer(\"basic_english\")"]},{"cell_type":"code","execution_count":132,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T04:33:17.496593Z","iopub.status.busy":"2024-05-09T04:33:17.495530Z","iopub.status.idle":"2024-05-09T04:33:17.500898Z","shell.execute_reply":"2024-05-09T04:33:17.500118Z","shell.execute_reply.started":"2024-05-09T04:33:17.496548Z"},"trusted":true},"outputs":[],"source":["def tokenize_example(example, tokenizer, max_length):\n","    tokens = tokenizer(example[\"text\"])[:max_length]\n","    length = len(tokens)\n","    return {\"tokens\": tokens, \"length\": length}"]},{"cell_type":"code","execution_count":133,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T04:33:18.079017Z","iopub.status.busy":"2024-05-09T04:33:18.076194Z","iopub.status.idle":"2024-05-09T04:33:18.092531Z","shell.execute_reply":"2024-05-09T04:33:18.091640Z","shell.execute_reply.started":"2024-05-09T04:33:18.078945Z"},"trusted":true},"outputs":[],"source":["max_length = 256\n","\n","train_data = train_data.map(\n","    tokenize_example, fn_kwargs={\"tokenizer\": tokenizer, \"max_length\": max_length}\n",")\n","test_data = test_data.map(\n","    tokenize_example, fn_kwargs={\"tokenizer\": tokenizer, \"max_length\": max_length}\n",")"]},{"cell_type":"markdown","metadata":{},"source":["## 1-3. Build Vocab "]},{"cell_type":"code","execution_count":134,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T04:33:50.933785Z","iopub.status.busy":"2024-05-09T04:33:50.933393Z","iopub.status.idle":"2024-05-09T04:33:57.179373Z","shell.execute_reply":"2024-05-09T04:33:57.178242Z","shell.execute_reply.started":"2024-05-09T04:33:50.933754Z"},"trusted":true},"outputs":[],"source":["min_freq = 5\n","special_tokens = [\"<unk>\", \"<pad>\"]\n","\n","vocab = build_vocab_from_iterator(train_data['tokens'],\n","                                  min_freq = min_freq,\n","                                  specials = special_tokens)"]},{"cell_type":"code","execution_count":135,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T04:34:23.087226Z","iopub.status.busy":"2024-05-09T04:34:23.086817Z","iopub.status.idle":"2024-05-09T04:34:23.092281Z","shell.execute_reply":"2024-05-09T04:34:23.091119Z","shell.execute_reply.started":"2024-05-09T04:34:23.087194Z"},"trusted":true},"outputs":[],"source":["unk_index = vocab[\"<unk>\"]\n","pad_index = vocab[\"<pad>\"]\n","\n","vocab.set_default_index(unk_index)"]},{"cell_type":"markdown","metadata":{},"source":["## 1-4. Numericalize Text"]},{"cell_type":"code","execution_count":136,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T04:41:08.959882Z","iopub.status.busy":"2024-05-09T04:41:08.958858Z","iopub.status.idle":"2024-05-09T04:41:08.964755Z","shell.execute_reply":"2024-05-09T04:41:08.963746Z","shell.execute_reply.started":"2024-05-09T04:41:08.959844Z"},"trusted":true},"outputs":[],"source":["def numericalize_example(example, vocab):\n","    ids = vocab.lookup_indices(example[\"tokens\"])\n","    return {\"ids\": ids}"]},{"cell_type":"code","execution_count":137,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T04:41:09.115654Z","iopub.status.busy":"2024-05-09T04:41:09.115293Z","iopub.status.idle":"2024-05-09T04:42:03.364867Z","shell.execute_reply":"2024-05-09T04:42:03.363650Z","shell.execute_reply.started":"2024-05-09T04:41:09.115628Z"},"trusted":true},"outputs":[],"source":["train_data = train_data.map(numericalize_example, fn_kwargs={\"vocab\": vocab})\n","test_data = test_data.map(numericalize_example, fn_kwargs={\"vocab\": vocab})"]},{"cell_type":"code","execution_count":138,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T04:44:34.503457Z","iopub.status.busy":"2024-05-09T04:44:34.502345Z","iopub.status.idle":"2024-05-09T04:44:34.511254Z","shell.execute_reply":"2024-05-09T04:44:34.510035Z","shell.execute_reply.started":"2024-05-09T04:44:34.503402Z"},"trusted":true},"outputs":[],"source":["train_data = train_data.with_format(type=\"torch\", columns=[\"ids\", \"label\", \"length\"])\n","test_data = test_data.with_format(type=\"torch\", columns=[\"ids\", \"label\", \"length\"])"]},{"cell_type":"markdown","metadata":{},"source":["## 1-5. Word Embedding"]},{"cell_type":"code","execution_count":139,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T04:47:01.763729Z","iopub.status.busy":"2024-05-09T04:47:01.763352Z","iopub.status.idle":"2024-05-09T05:01:19.461687Z","shell.execute_reply":"2024-05-09T05:01:19.457096Z","shell.execute_reply.started":"2024-05-09T04:47:01.763701Z"},"trusted":true},"outputs":[],"source":["if not os.path.exists(pretrained_embedding_dir):\n","    vectors = torchtext.vocab.GloVe()\n","    pretrained_embedding = vectors.get_vecs_by_tokens(vocab.get_itos())\n","    torch.save(pretrained_embedding, pretrained_embedding_dir)\n","else:\n","    pretrained_embedding = torch.load(pretrained_embedding_dir)"]},{"cell_type":"markdown","metadata":{},"source":["## 1-6. Prepare for Data Loading"]},{"cell_type":"code","execution_count":140,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T06:32:36.896177Z","iopub.status.busy":"2024-05-09T06:32:36.894792Z","iopub.status.idle":"2024-05-09T06:32:36.902278Z","shell.execute_reply":"2024-05-09T06:32:36.901112Z","shell.execute_reply.started":"2024-05-09T06:32:36.896132Z"},"trusted":true},"outputs":[],"source":["class CustomDataset(Dataset):\n","    def __init__(self, data):\n","        self.data = data\n","    \n","    def __len__(self):\n","        return len(self.data)\n","    \n","    def __getitem__(self, idx):\n","        item = self.data[idx]\n","        return item"]},{"cell_type":"code","execution_count":141,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T06:32:37.040510Z","iopub.status.busy":"2024-05-09T06:32:37.040090Z","iopub.status.idle":"2024-05-09T06:32:37.046037Z","shell.execute_reply":"2024-05-09T06:32:37.044861Z","shell.execute_reply.started":"2024-05-09T06:32:37.040475Z"},"trusted":true},"outputs":[],"source":["train_dataset = CustomDataset(train_data)\n","test_dataset = CustomDataset(test_data)"]},{"cell_type":"code","execution_count":142,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T06:32:37.192543Z","iopub.status.busy":"2024-05-09T06:32:37.191817Z","iopub.status.idle":"2024-05-09T06:32:37.198607Z","shell.execute_reply":"2024-05-09T06:32:37.197333Z","shell.execute_reply.started":"2024-05-09T06:32:37.192501Z"},"trusted":true},"outputs":[],"source":["def custom_collate_fn(batch):\n","    \n","    batch_inputs = [sample['ids'] for sample in batch]\n","    batch_labels = [sample['label'] for sample in batch]\n","    \n","    collate_inputs = pad_sequence(batch_inputs, \n","                                  padding_value = pad_index, \n","                                  batch_first = True)\n","    collate_labels = torch.tensor(batch_labels)\n","    \n","    return collate_inputs, collate_labels"]},{"cell_type":"code","execution_count":143,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T06:32:37.329915Z","iopub.status.busy":"2024-05-09T06:32:37.328765Z","iopub.status.idle":"2024-05-09T06:32:37.336910Z","shell.execute_reply":"2024-05-09T06:32:37.335768Z","shell.execute_reply.started":"2024-05-09T06:32:37.329870Z"},"trusted":true},"outputs":[],"source":["batch_size = 128\n","pad_index = pad_index\n","shuffle = True\n","\n","trainloader = DataLoader(dataset = train_dataset,\n","                         batch_size = batch_size,\n","                         collate_fn = custom_collate_fn,\n","                         shuffle = shuffle)\n","testloader = DataLoader(dataset = test_dataset,\n","                         batch_size = batch_size,\n","                         collate_fn = custom_collate_fn,\n","                         shuffle = shuffle)"]},{"cell_type":"markdown","metadata":{},"source":["# 2. Define Model"]},{"cell_type":"markdown","metadata":{},"source":["## 2-1. Model Structure"]},{"cell_type":"code","execution_count":144,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T06:33:20.862529Z","iopub.status.busy":"2024-05-09T06:33:20.862120Z","iopub.status.idle":"2024-05-09T06:33:20.873691Z","shell.execute_reply":"2024-05-09T06:33:20.872514Z","shell.execute_reply.started":"2024-05-09T06:33:20.862497Z"},"trusted":true},"outputs":[],"source":["class DeepLSTM(nn.Module):\n","    def __init__(self, input_dim, embedding_dim, hidden_dim, num_layers, output_dim, pad_index):\n","        super().__init__()\n","        self.embedding_dim = embedding_dim\n","        self.hidden_dim = hidden_dim\n","        self.num_layers = num_layers\n","        self.output_dim = output_dim\n","        \n","        self.embedding = nn.Embedding(input_dim, embedding_dim, padding_idx = pad_index)\n","        self.embedding.requires_grad_(False)\n","\n","        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first = True)\n","\n","        self.fc1 = nn.Linear(hidden_dim, embedding_dim)\n","        self.fc2 = nn.Linear(hidden_dim, output_dim)\n","\n","    def forward(self, inputs):\n","\n","        batch_size = inputs.size(0)\n","        seq_length = inputs.size(1)\n","\n","        x = self.embedding(inputs)\n","            \n","        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(device)\n","        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(device)\n","        hidden = (h0, c0)\n","\n","        output, (h, c) = self.lstm(x, hidden)\n","\n","        logit = self.fc2(h[-1, :, :])\n","\n","        return logit"]},{"cell_type":"markdown","metadata":{},"source":["## 2-2. Hyperparameter & functions"]},{"cell_type":"code","execution_count":145,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T06:33:21.025116Z","iopub.status.busy":"2024-05-09T06:33:21.024663Z","iopub.status.idle":"2024-05-09T06:33:21.111777Z","shell.execute_reply":"2024-05-09T06:33:21.110479Z","shell.execute_reply.started":"2024-05-09T06:33:21.025080Z"},"trusted":true},"outputs":[],"source":["vocab_size = len(vocab)\n","embedding_dim = 300\n","hidden_dim = 128\n","num_layers = 3\n","output_dim = 1\n","pad_index = pad_index\n","lr = 5e-4\n","\n","model = DeepLSTM(vocab_size, embedding_dim, hidden_dim, num_layers, output_dim, pad_index)\n","\n","criterion = nn.BCEWithLogitsLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr)"]},{"cell_type":"markdown","metadata":{},"source":["## 2-3. Weight Initialization"]},{"cell_type":"code","execution_count":146,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T06:33:21.345375Z","iopub.status.busy":"2024-05-09T06:33:21.344933Z","iopub.status.idle":"2024-05-09T06:33:21.352661Z","shell.execute_reply":"2024-05-09T06:33:21.351278Z","shell.execute_reply.started":"2024-05-09T06:33:21.345343Z"},"trusted":true},"outputs":[],"source":["def initialize_weights(m):\n","    if isinstance(m, nn.Linear):\n","        nn.init.xavier_normal_(m.weight)\n","        nn.init.zeros_(m.bias)\n","    elif isinstance(m, nn.LSTM):\n","        for name, param in m.named_parameters():\n","            if \"bias\" in name:\n","                nn.init.zeros_(param)\n","            else:\n","                nn.init.orthogonal_(param)"]},{"cell_type":"code","execution_count":147,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T06:33:21.522657Z","iopub.status.busy":"2024-05-09T06:33:21.522278Z","iopub.status.idle":"2024-05-09T06:33:21.532722Z","shell.execute_reply":"2024-05-09T06:33:21.531867Z","shell.execute_reply.started":"2024-05-09T06:33:21.522629Z"},"trusted":true},"outputs":[{"data":{"text/plain":["DeepLSTM(\n","  (embedding): Embedding(24897, 300, padding_idx=1)\n","  (lstm): LSTM(300, 128, num_layers=3, batch_first=True)\n","  (fc1): Linear(in_features=128, out_features=300, bias=True)\n","  (fc2): Linear(in_features=128, out_features=1, bias=True)\n",")"]},"execution_count":147,"metadata":{},"output_type":"execute_result"}],"source":["model.apply(initialize_weights)"]},{"cell_type":"code","execution_count":148,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T06:33:21.675452Z","iopub.status.busy":"2024-05-09T06:33:21.674714Z","iopub.status.idle":"2024-05-09T06:33:21.679695Z","shell.execute_reply":"2024-05-09T06:33:21.678909Z","shell.execute_reply.started":"2024-05-09T06:33:21.675417Z"},"trusted":true},"outputs":[],"source":["model.embedding.weight.data = pretrained_embedding"]},{"cell_type":"code","execution_count":149,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\"Model's state_dict:\"\n","Parameter name: embedding.weight\n","    Size : torch.Size([24897, 300])\n","    Value: Parameter containing:\n","tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [ 0.2720, -0.0620, -0.1884,  ...,  0.1302, -0.1832,  0.1323],\n","        ...,\n","        [ 0.6701, -0.2717,  0.4766,  ...,  0.2786,  0.3312,  0.0230],\n","        [-0.1503,  0.5624, -0.5622,  ..., -0.4224, -0.6836,  0.0726],\n","        [ 1.1741, -0.4386,  0.3310,  ...,  0.3193, -0.2292, -0.0887]])\n","Parameter name: lstm.weight_ih_l0\n","    Size : torch.Size([512, 300])\n","    Value: Parameter containing:\n","tensor([[ 0.0455, -0.0546, -0.0071,  ..., -0.0428,  0.0080,  0.0017],\n","        [-0.0767, -0.0010, -0.0131,  ..., -0.0353,  0.0438,  0.0575],\n","        [-0.0591, -0.0995,  0.0224,  ..., -0.0677,  0.0174, -0.0077],\n","        ...,\n","        [-0.0056, -0.0513,  0.0004,  ..., -0.0784,  0.0689,  0.0528],\n","        [ 0.0969, -0.0112, -0.0040,  ...,  0.0192, -0.0788, -0.0455],\n","        [ 0.0084, -0.0439,  0.0374,  ...,  0.0980,  0.0141, -0.0282]],\n","       requires_grad=True)\n","Parameter name: lstm.weight_hh_l0\n","    Size : torch.Size([512, 128])\n","    Value: Parameter containing:\n","tensor([[-0.0202, -0.0408, -0.0979,  ..., -0.0340, -0.0232, -0.1308],\n","        [-0.0151, -0.0158,  0.0103,  ..., -0.0426, -0.0335, -0.0588],\n","        [-0.0288,  0.0081,  0.0295,  ..., -0.0182,  0.0034, -0.0677],\n","        ...,\n","        [-0.0155,  0.0673, -0.0535,  ...,  0.0299, -0.0332, -0.0388],\n","        [ 0.0184, -0.0150, -0.0043,  ...,  0.0628,  0.0025, -0.0108],\n","        [ 0.0294,  0.0017, -0.0119,  ...,  0.1139, -0.0118, -0.0584]],\n","       requires_grad=True)\n","Parameter name: lstm.bias_ih_l0\n","    Size : torch.Size([512])\n","    Value: Parameter containing:\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n","Parameter name: lstm.bias_hh_l0\n","    Size : torch.Size([512])\n","    Value: Parameter containing:\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n","Parameter name: lstm.weight_ih_l1\n","    Size : torch.Size([512, 128])\n","    Value: Parameter containing:\n","tensor([[ 0.0368,  0.0463, -0.0127,  ...,  0.0573, -0.0776, -0.0194],\n","        [ 0.0087,  0.0048,  0.0316,  ..., -0.0171, -0.0207,  0.0007],\n","        [ 0.0417, -0.0033, -0.0055,  ..., -0.0142, -0.0081,  0.0156],\n","        ...,\n","        [-0.0326,  0.0661, -0.0742,  ..., -0.0067, -0.0364,  0.0645],\n","        [-0.0285, -0.0522, -0.0054,  ...,  0.0810, -0.0411,  0.0364],\n","        [-0.0025,  0.0226,  0.0122,  ..., -0.0444, -0.0378,  0.0034]],\n","       requires_grad=True)\n","Parameter name: lstm.weight_hh_l1\n","    Size : torch.Size([512, 128])\n","    Value: Parameter containing:\n","tensor([[-0.0367, -0.0463,  0.0002,  ...,  0.0540,  0.0236,  0.0467],\n","        [ 0.0360, -0.0781, -0.0198,  ...,  0.0642,  0.0123,  0.0810],\n","        [-0.0187, -0.0035,  0.0732,  ..., -0.0449,  0.0195,  0.0585],\n","        ...,\n","        [-0.0100, -0.0861, -0.0385,  ..., -0.0443, -0.0713,  0.0252],\n","        [-0.0767,  0.0591,  0.0674,  ...,  0.0083,  0.0068, -0.0612],\n","        [-0.0196, -0.0157,  0.0406,  ..., -0.0027, -0.0479,  0.0029]],\n","       requires_grad=True)\n","Parameter name: lstm.bias_ih_l1\n","    Size : torch.Size([512])\n","    Value: Parameter containing:\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n","Parameter name: lstm.bias_hh_l1\n","    Size : torch.Size([512])\n","    Value: Parameter containing:\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n","Parameter name: lstm.weight_ih_l2\n","    Size : torch.Size([512, 128])\n","    Value: Parameter containing:\n","tensor([[-0.0007, -0.0295,  0.0436,  ...,  0.0688, -0.0282,  0.0129],\n","        [ 0.0146, -0.0259, -0.0085,  ...,  0.0010, -0.0091, -0.0452],\n","        [-0.0644,  0.0122, -0.0933,  ..., -0.0804,  0.1328,  0.0251],\n","        ...,\n","        [ 0.0230,  0.0070, -0.0145,  ...,  0.0063, -0.0186,  0.0290],\n","        [ 0.0593,  0.0193, -0.0379,  ..., -0.0907,  0.0220, -0.0511],\n","        [ 0.0011, -0.0100,  0.0219,  ...,  0.0660,  0.0189,  0.0868]],\n","       requires_grad=True)\n","Parameter name: lstm.weight_hh_l2\n","    Size : torch.Size([512, 128])\n","    Value: Parameter containing:\n","tensor([[-0.0112, -0.0446,  0.0408,  ..., -0.0055, -0.0254, -0.0279],\n","        [ 0.0840,  0.0089,  0.0757,  ...,  0.0239,  0.0579, -0.0647],\n","        [-0.0038,  0.0397, -0.0080,  ..., -0.0327,  0.0006, -0.0526],\n","        ...,\n","        [-0.0123,  0.0060,  0.0186,  ..., -0.0094,  0.0286, -0.0234],\n","        [-0.0757,  0.0299,  0.0530,  ...,  0.0204, -0.0525,  0.0115],\n","        [-0.0853, -0.0020,  0.0015,  ...,  0.0740,  0.0372,  0.0257]],\n","       requires_grad=True)\n","Parameter name: lstm.bias_ih_l2\n","    Size : torch.Size([512])\n","    Value: Parameter containing:\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n","Parameter name: lstm.bias_hh_l2\n","    Size : torch.Size([512])\n","    Value: Parameter containing:\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n","Parameter name: fc1.weight\n","    Size : torch.Size([300, 128])\n","    Value: Parameter containing:\n","tensor([[-3.0094e-02,  5.2173e-02, -3.0275e-02,  ..., -3.1936e-02,\n","         -5.5489e-02, -2.8165e-02],\n","        [-1.0983e-02, -9.0797e-02,  1.8576e-02,  ..., -8.0555e-02,\n","         -8.0984e-02, -5.0622e-02],\n","        [ 2.9928e-02,  4.2960e-03, -3.9165e-02,  ...,  1.7734e-01,\n","         -1.5864e-01,  1.2454e-01],\n","        ...,\n","        [-5.4127e-03,  7.0784e-02,  1.3004e-01,  ...,  4.4073e-05,\n","          1.1917e-01,  2.0089e-02],\n","        [-9.3602e-02,  5.1292e-02, -3.5932e-02,  ..., -5.8559e-03,\n","          3.6101e-03,  3.0938e-02],\n","        [ 4.1176e-02,  4.0198e-02,  5.4676e-04,  ...,  7.8006e-02,\n","         -1.4994e-02,  6.7024e-02]], requires_grad=True)\n","Parameter name: fc1.bias\n","    Size : torch.Size([300])\n","    Value: Parameter containing:\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n","Parameter name: fc2.weight\n","    Size : torch.Size([1, 128])\n","    Value: Parameter containing:\n","tensor([[-0.1776, -0.0076, -0.1487, -0.1318,  0.1298, -0.0317,  0.1907,  0.0205,\n","          0.1122,  0.0213, -0.1435, -0.2626,  0.2592,  0.0374,  0.0108, -0.1851,\n","         -0.0820,  0.0628, -0.3096, -0.0746, -0.2075, -0.2909,  0.2058,  0.0393,\n","          0.0017, -0.1178, -0.0861,  0.0157,  0.0376,  0.0437, -0.0165,  0.1083,\n","         -0.1095, -0.3390,  0.0655, -0.0446, -0.2207, -0.0762,  0.1952, -0.1475,\n","          0.0896,  0.2341,  0.1144,  0.0683,  0.1534,  0.0624, -0.0942,  0.0388,\n","         -0.0142,  0.0377, -0.1127,  0.1417, -0.0351,  0.0838, -0.0589, -0.0512,\n","         -0.1843,  0.0886, -0.2371, -0.2533,  0.1602,  0.0289,  0.0730, -0.1592,\n","         -0.0206, -0.2862,  0.0119, -0.0833, -0.0506,  0.0252,  0.0105,  0.2741,\n","          0.0901, -0.0810, -0.1157,  0.1467,  0.1657, -0.1811,  0.1194,  0.3110,\n","         -0.1901, -0.0678, -0.0873, -0.0371,  0.1180, -0.1093, -0.1106,  0.1109,\n","         -0.0092, -0.0186,  0.2421,  0.2077, -0.0520, -0.1231,  0.0233,  0.1299,\n","         -0.0647,  0.0460,  0.0539, -0.1078, -0.0335,  0.1195,  0.0067,  0.0153,\n","          0.3667, -0.2205,  0.0745, -0.0526, -0.0047,  0.1645,  0.0696, -0.1813,\n","          0.1507, -0.0351, -0.0867, -0.1824, -0.1324, -0.0496,  0.1145, -0.0911,\n","          0.2128, -0.1272, -0.2101, -0.1904,  0.0400,  0.1349,  0.0504, -0.2063]],\n","       requires_grad=True)\n","Parameter name: fc2.bias\n","    Size : torch.Size([1])\n","    Value: Parameter containing:\n","tensor([0.], requires_grad=True)\n"]}],"source":["pprint(\"Model's state_dict:\")\n","for name, param in model.named_parameters():\n","    print(f\"Parameter name: {name}\")\n","    print(f\"    Size : {param.size()}\")\n","    print(f\"    Value: {param}\")"]},{"cell_type":"code","execution_count":150,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T06:33:21.189251Z","iopub.status.busy":"2024-05-09T06:33:21.188799Z","iopub.status.idle":"2024-05-09T06:33:21.194891Z","shell.execute_reply":"2024-05-09T06:33:21.193696Z","shell.execute_reply.started":"2024-05-09T06:33:21.189216Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["The model has 523,181 trainable parameters\n"]}],"source":["def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","\n","print(f\"The model has {count_parameters(model):,} trainable parameters\")"]},{"cell_type":"code","execution_count":151,"metadata":{},"outputs":[{"data":{"text/plain":["BCEWithLogitsLoss()"]},"execution_count":151,"metadata":{},"output_type":"execute_result"}],"source":["model.to(device)\n","criterion.to(device)"]},{"cell_type":"markdown","metadata":{},"source":["## 2-4. Tensorboard"]},{"cell_type":"code","execution_count":152,"metadata":{},"outputs":[],"source":["writer = SummaryWriter()"]},{"cell_type":"markdown","metadata":{},"source":["# 3. Train Model"]},{"cell_type":"code","execution_count":153,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T06:33:22.006416Z","iopub.status.busy":"2024-05-09T06:33:22.005155Z","iopub.status.idle":"2024-05-09T06:33:22.014644Z","shell.execute_reply":"2024-05-09T06:33:22.013435Z","shell.execute_reply.started":"2024-05-09T06:33:22.006378Z"},"trusted":true},"outputs":[],"source":["def train_model(model, criterion, optimizer, trainloader, num_epochs):\n","    print(\"-----Training Started------\")\n","    for epoch in range(num_epochs):\n","        \n","        model.train()\n","        \n","        running_loss = 0.0\n","        \n","        for inputs, labels in tqdm(trainloader):\n","            \n","            inputs, labels = inputs.to(device), labels.to(device)\n","            \n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            loss = criterion(outputs.view(-1), labels.float())\n","            loss.backward()\n","            optimizer.step()\n","\n","            writer.add_scalar('Loss/train', loss.item(), epoch)\n","\n","            running_loss += loss.item() * inputs.size(0)\n","\n","        epoch_loss = running_loss / len(trainloader.dataset)\n","        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss: .4f}\")\n","\n","        torch.save(model.state_dict(), model_dir)\n","    \n","    writer.close()\n","    \n","    print(\"-----Training Completed-----\")"]},{"cell_type":"code","execution_count":154,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T06:33:22.183260Z","iopub.status.busy":"2024-05-09T06:33:22.182381Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["-----Training Started------\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 196/196 [00:09<00:00, 20.24it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/16], Loss:  0.6783\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 196/196 [00:10<00:00, 19.46it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [2/16], Loss:  0.6588\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 196/196 [00:09<00:00, 19.64it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [3/16], Loss:  0.6886\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 196/196 [00:10<00:00, 19.19it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [4/16], Loss:  0.6929\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 196/196 [00:10<00:00, 19.27it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [5/16], Loss:  0.6612\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 196/196 [00:10<00:00, 19.45it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [6/16], Loss:  0.6774\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 196/196 [00:10<00:00, 19.34it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [7/16], Loss:  0.6948\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 196/196 [00:10<00:00, 19.41it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [8/16], Loss:  0.6937\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 196/196 [00:10<00:00, 19.43it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [9/16], Loss:  0.6919\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 196/196 [00:10<00:00, 19.55it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [10/16], Loss:  0.6732\n"]},{"name":"stderr","output_type":"stream","text":[" 39%|███▉      | 76/196 [00:03<00:05, 22.36it/s]\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[154], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m16\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[153], line 9\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, trainloader, num_epochs)\u001b[0m\n\u001b[1;32m      5\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      7\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m inputs, labels \u001b[38;5;129;01min\u001b[39;00m tqdm(trainloader):\n\u001b[1;32m     11\u001b[0m     inputs, labels \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     13\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n","File \u001b[0;32m~/miniconda3/envs/study-mldl/lib/python3.10/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/study-mldl/lib/python3.10/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m~/miniconda3/envs/study-mldl/lib/python3.10/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m~/miniconda3/envs/study-mldl/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","File \u001b[0;32m~/miniconda3/envs/study-mldl/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n","Cell \u001b[0;32mIn[140], line 9\u001b[0m, in \u001b[0;36mCustomDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[0;32m----> 9\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m item\n","File \u001b[0;32m~/miniconda3/envs/study-mldl/lib/python3.10/site-packages/datasets/arrow_dataset.py:2861\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2859\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[1;32m   2860\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2861\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/study-mldl/lib/python3.10/site-packages/datasets/arrow_dataset.py:2846\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[0;34m(self, key, **kwargs)\u001b[0m\n\u001b[1;32m   2844\u001b[0m formatter \u001b[38;5;241m=\u001b[39m get_formatter(format_type, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mfeatures, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[1;32m   2845\u001b[0m pa_subtable \u001b[38;5;241m=\u001b[39m query_table(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, key, indices\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_indices)\n\u001b[0;32m-> 2846\u001b[0m formatted_output \u001b[38;5;241m=\u001b[39m \u001b[43mformat_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2847\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpa_subtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformat_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_all_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_all_columns\u001b[49m\n\u001b[1;32m   2848\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2849\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n","File \u001b[0;32m~/miniconda3/envs/study-mldl/lib/python3.10/site-packages/datasets/formatting/formatting.py:641\u001b[0m, in \u001b[0;36mformat_table\u001b[0;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    640\u001b[0m     pa_table_to_format \u001b[38;5;241m=\u001b[39m pa_table\u001b[38;5;241m.\u001b[39mdrop(col \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m pa_table\u001b[38;5;241m.\u001b[39mcolumn_names \u001b[38;5;28;01mif\u001b[39;00m col \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m format_columns)\n\u001b[0;32m--> 641\u001b[0m     formatted_output \u001b[38;5;241m=\u001b[39m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table_to_format\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    642\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m output_all_columns:\n\u001b[1;32m    643\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(formatted_output, MutableMapping):\n","File \u001b[0;32m~/miniconda3/envs/study-mldl/lib/python3.10/site-packages/datasets/formatting/formatting.py:397\u001b[0m, in \u001b[0;36mFormatter.__call__\u001b[0;34m(self, pa_table, query_type)\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, pa_table: pa\u001b[38;5;241m.\u001b[39mTable, query_type: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[RowFormat, ColumnFormat, BatchFormat]:\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 397\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_row\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    398\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m query_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    399\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_column(pa_table)\n","File \u001b[0;32m~/miniconda3/envs/study-mldl/lib/python3.10/site-packages/datasets/formatting/torch_formatter.py:100\u001b[0m, in \u001b[0;36mTorchFormatter.format_row\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m     98\u001b[0m row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy_arrow_extractor()\u001b[38;5;241m.\u001b[39mextract_row(pa_table)\n\u001b[1;32m     99\u001b[0m row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_features_decoder\u001b[38;5;241m.\u001b[39mdecode_row(row)\n\u001b[0;32m--> 100\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecursive_tensorize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/study-mldl/lib/python3.10/site-packages/datasets/formatting/torch_formatter.py:95\u001b[0m, in \u001b[0;36mTorchFormatter.recursive_tensorize\u001b[0;34m(self, data_struct)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrecursive_tensorize\u001b[39m(\u001b[38;5;28mself\u001b[39m, data_struct: \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m---> 95\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmap_nested\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_recursive_tensorize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_struct\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/study-mldl/lib/python3.10/site-packages/datasets/utils/py_utils.py:513\u001b[0m, in \u001b[0;36mmap_nested\u001b[0;34m(function, data_struct, dict_only, map_list, map_tuple, map_numpy, num_proc, parallel_min_length, batched, batch_size, types, disable_tqdm, desc)\u001b[0m\n\u001b[1;32m    509\u001b[0m         batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mlen\u001b[39m(iterable) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m num_proc \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(iterable) \u001b[38;5;241m%\u001b[39m num_proc \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    510\u001b[0m     iterable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(iter_batched(iterable, batch_size))\n\u001b[1;32m    511\u001b[0m mapped \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    512\u001b[0m     _single_map_nested((function, obj, batched, batch_size, types, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m--> 513\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m \u001b[43mhf_tqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdisable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdisable_tqdm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    514\u001b[0m ]\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m batched:\n\u001b[1;32m    516\u001b[0m     mapped \u001b[38;5;241m=\u001b[39m [mapped_item \u001b[38;5;28;01mfor\u001b[39;00m mapped_batch \u001b[38;5;129;01min\u001b[39;00m mapped \u001b[38;5;28;01mfor\u001b[39;00m mapped_item \u001b[38;5;129;01min\u001b[39;00m mapped_batch]\n","File \u001b[0;32m~/miniconda3/envs/study-mldl/lib/python3.10/site-packages/datasets/utils/tqdm.py:114\u001b[0m, in \u001b[0;36mtqdm.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m are_progress_bars_disabled():\n\u001b[1;32m    113\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisable\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/miniconda3/envs/study-mldl/lib/python3.10/site-packages/tqdm/notebook.py:223\u001b[0m, in \u001b[0;36mtqdm_notebook.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m colour \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcolour\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    222\u001b[0m display_here \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdisplay\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 223\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm_notebook\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisable \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgui\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[1;32m    225\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39m_, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m__: \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m~/miniconda3/envs/study-mldl/lib/python3.10/site-packages/tqdm/asyncio.py:24\u001b[0m, in \u001b[0;36mtqdm_asyncio.__init__\u001b[0;34m(self, iterable, *args, **kwargs)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, iterable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 24\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm_asyncio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m(iterable, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miterable_awaitable \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m iterable \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m~/miniconda3/envs/study-mldl/lib/python3.10/functools.py:401\u001b[0m, in \u001b[0;36mpartialmethod.__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m    397\u001b[0m new_func \u001b[38;5;241m=\u001b[39m get(obj, \u001b[38;5;28mcls\u001b[39m)\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc:\n\u001b[1;32m    399\u001b[0m     \u001b[38;5;66;03m# Assume __get__ returning something new indicates the\u001b[39;00m\n\u001b[1;32m    400\u001b[0m     \u001b[38;5;66;03m# creation of an appropriate callable\u001b[39;00m\n\u001b[0;32m--> 401\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeywords\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    403\u001b[0m         result\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m \u001b[38;5;241m=\u001b[39m new_func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["num_epochs = 16\n","\n","train_model(model, criterion, optimizer, trainloader, num_epochs)"]},{"cell_type":"markdown","metadata":{},"source":["# 4. Test"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def test_model(model, testloader):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    TP = 0  # True Positives\n","    TN = 0  # True Negatives\n","    FP = 0  # False Positives\n","    FN = 0  # False Negatives\n","\n","    with torch.no_grad():\n","        for inputs, labels in testloader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            outputs = model(inputs)\n","            predictions = torch.round(F.sigmoid(outputs))\n","            total += labels.size(0)\n","\n","            predictions, labels = predictions.view(-1).cpu(), labels.cpu()\n","            \n","            correct += (predictions == labels).sum().item()\n","\n","            TP += ((predictions == 1) & (labels == 1)).sum().item()\n","            TN += ((predictions == 0) & (labels == 0)).sum().item()\n","            FP += ((predictions == 1) & (labels == 0)).sum().item()\n","            FN += ((predictions == 0) & (labels == 1)).sum().item()\n","\n","    accuracy = correct / total\n","    precision = TP / (TP + FP) if TP + FP != 0 else 0\n","    recall = TP / (TP + FN) if TP + FN != 0 else 0\n","    f1 = 2 * (precision * recall) / (precision + recall) if precision + recall != 0 else 0\n","\n","    print(f\"Accuracy on test set: {accuracy:.4f}\")\n","    print(f\"Precision on test set: {precision:.4f}\")\n","    print(f\"Recall on test set: {recall:.4f}\")\n","    print(f\"F1 Score on test set: {f1:.4f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["DeepLSTM(\n","  (embedding): Embedding(24897, 300, padding_idx=1)\n","  (lstm): LSTM(300, 128, num_layers=3, batch_first=True)\n","  (fc1): Linear(in_features=128, out_features=300, bias=True)\n","  (fc2): Linear(in_features=128, out_features=1, bias=True)\n",")"]},"execution_count":118,"metadata":{},"output_type":"execute_result"}],"source":["model.load_state_dict(torch.load(model_dir))\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy on test set: 0.8368\n","Precision on test set: 0.8195\n","Recall on test set: 0.8638\n","F1 Score on test set: 0.8411\n"]}],"source":["test_model(model, testloader)"]},{"cell_type":"markdown","metadata":{},"source":["# 5. Inference"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def inference(text, model, tokenizer, vocab):\n","    tokens = tokenizer(text)\n","    ids = vocab.lookup_indices(tokens)\n","    tensor = torch.LongTensor(ids).unsqueeze(dim=0).to(device)\n","\n","    output = model(tensor)\n","\n","    prediction = torch.round(F.sigmoid(output))\n","\n","    return prediction"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["DeepLSTM(\n","  (embedding): Embedding(24897, 300, padding_idx=1)\n","  (lstm): LSTM(300, 128, num_layers=3, batch_first=True)\n","  (fc1): Linear(in_features=128, out_features=300, bias=True)\n","  (fc2): Linear(in_features=128, out_features=1, bias=True)\n",")"]},"execution_count":121,"metadata":{},"output_type":"execute_result"}],"source":["model.load_state_dict(torch.load(model_dir))\n","model.to(device)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.0\n"]}],"source":["text = 'This film is terrible!'\n","\n","prediction = inference(text, model, tokenizer, vocab)\n","\n","print(prediction.item())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1.0\n"]}],"source":["text = 'This film is great!'\n","\n","prediction = inference(text, model, tokenizer, vocab)\n","\n","print(prediction.item())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["1.0\n"]}],"source":["text = 'The best film I have ever seen!'\n","\n","prediction = inference(text, model, tokenizer, vocab)\n","\n","print(prediction.item())"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.0\n"]}],"source":["text = \"This film is not terrible, it's great!\"\n","\n","prediction = inference(text, model, tokenizer, vocab)\n","\n","print(prediction.item())"]},{"cell_type":"markdown","metadata":{},"source":["# Limitation\n","\n","padding 토큰 연산 제외 / dropout / validation"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30698,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
