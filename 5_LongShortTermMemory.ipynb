{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Introduction\n","\n","based on : https://github.com/bentrevett/pytorch-sentiment-analysis"]},{"cell_type":"markdown","metadata":{},"source":["Task : Binary Classification(sentimental analysis)  \n","Method : Long-Short Term Memory(LSTM) with pytorch nn    \n","Dataset : IMDB"]},{"cell_type":"markdown","metadata":{},"source":["# 0. Set Environment"]},{"cell_type":"code","execution_count":68,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T05:51:20.087127Z","iopub.status.busy":"2024-05-09T05:51:20.086594Z","iopub.status.idle":"2024-05-09T05:51:20.094575Z","shell.execute_reply":"2024-05-09T05:51:20.092979Z","shell.execute_reply.started":"2024-05-09T05:51:20.087090Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n","import torchtext\n","torchtext.disable_torchtext_deprecation_warning()\n","from torchtext.data import get_tokenizer\n","from torchtext.vocab import build_vocab_from_iterator\n","from torch.utils.tensorboard import SummaryWriter\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","from pprint import pprint\n","\n","import subprocess\n","import os\n","import sys\n","\n","import datasets"]},{"cell_type":"code","execution_count":69,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T04:33:02.055460Z","iopub.status.busy":"2024-05-09T04:33:02.055071Z","iopub.status.idle":"2024-05-09T04:33:02.061661Z","shell.execute_reply":"2024-05-09T04:33:02.060618Z","shell.execute_reply.started":"2024-05-09T04:33:02.055426Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Selected device: cuda\n"]}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(\"Selected device:\", device)"]},{"cell_type":"code","execution_count":70,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T04:33:02.063226Z","iopub.status.busy":"2024-05-09T04:33:02.062835Z","iopub.status.idle":"2024-05-09T04:33:02.076477Z","shell.execute_reply":"2024-05-09T04:33:02.075456Z","shell.execute_reply.started":"2024-05-09T04:33:02.063197Z"},"trusted":true},"outputs":[],"source":["seed = 42\n","\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)\n","torch.backends.cudnn.deterministic = True"]},{"cell_type":"code","execution_count":71,"metadata":{},"outputs":[],"source":["model_dir = './models/LSTM_Classifier_model.pth'\n","pretrained_embedding_dir = './models/Glove_pretrained.pth'"]},{"cell_type":"markdown","metadata":{},"source":["# 1. Process Data"]},{"cell_type":"markdown","metadata":{},"source":["## 1-1. Download Data"]},{"cell_type":"code","execution_count":72,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T04:33:02.087466Z","iopub.status.busy":"2024-05-09T04:33:02.087111Z","iopub.status.idle":"2024-05-09T04:33:08.436868Z","shell.execute_reply":"2024-05-09T04:33:08.435884Z","shell.execute_reply.started":"2024-05-09T04:33:02.087440Z"},"trusted":true},"outputs":[],"source":["train_data, test_data = datasets.load_dataset(\"imdb\", split=[\"train\", \"test\"])"]},{"cell_type":"markdown","metadata":{},"source":["## 1-2. Tokenize"]},{"cell_type":"code","execution_count":73,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T04:33:12.928637Z","iopub.status.busy":"2024-05-09T04:33:12.928257Z","iopub.status.idle":"2024-05-09T04:33:12.934105Z","shell.execute_reply":"2024-05-09T04:33:12.933039Z","shell.execute_reply.started":"2024-05-09T04:33:12.928609Z"},"trusted":true},"outputs":[],"source":["tokenizer = get_tokenizer(\"basic_english\")"]},{"cell_type":"code","execution_count":74,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T04:33:17.496593Z","iopub.status.busy":"2024-05-09T04:33:17.495530Z","iopub.status.idle":"2024-05-09T04:33:17.500898Z","shell.execute_reply":"2024-05-09T04:33:17.500118Z","shell.execute_reply.started":"2024-05-09T04:33:17.496548Z"},"trusted":true},"outputs":[],"source":["def tokenize_example(example, tokenizer, max_length):\n","    tokens = tokenizer(example[\"text\"])[:max_length]\n","    length = len(tokens)\n","    return {\"tokens\": tokens, \"length\": length}"]},{"cell_type":"code","execution_count":75,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T04:33:18.079017Z","iopub.status.busy":"2024-05-09T04:33:18.076194Z","iopub.status.idle":"2024-05-09T04:33:18.092531Z","shell.execute_reply":"2024-05-09T04:33:18.091640Z","shell.execute_reply.started":"2024-05-09T04:33:18.078945Z"},"trusted":true},"outputs":[],"source":["max_length = 256\n","\n","train_data = train_data.map(\n","    tokenize_example, fn_kwargs={\"tokenizer\": tokenizer, \"max_length\": max_length}\n",")\n","test_data = test_data.map(\n","    tokenize_example, fn_kwargs={\"tokenizer\": tokenizer, \"max_length\": max_length}\n",")"]},{"cell_type":"markdown","metadata":{},"source":["## 1-3. Build Vocab "]},{"cell_type":"code","execution_count":76,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T04:33:50.933785Z","iopub.status.busy":"2024-05-09T04:33:50.933393Z","iopub.status.idle":"2024-05-09T04:33:57.179373Z","shell.execute_reply":"2024-05-09T04:33:57.178242Z","shell.execute_reply.started":"2024-05-09T04:33:50.933754Z"},"trusted":true},"outputs":[],"source":["min_freq = 5\n","special_tokens = [\"<unk>\", \"<pad>\"]\n","\n","vocab = build_vocab_from_iterator(train_data['tokens'],\n","                                  min_freq = min_freq,\n","                                  specials = special_tokens)"]},{"cell_type":"code","execution_count":77,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T04:34:23.087226Z","iopub.status.busy":"2024-05-09T04:34:23.086817Z","iopub.status.idle":"2024-05-09T04:34:23.092281Z","shell.execute_reply":"2024-05-09T04:34:23.091119Z","shell.execute_reply.started":"2024-05-09T04:34:23.087194Z"},"trusted":true},"outputs":[],"source":["unk_index = vocab[\"<unk>\"]\n","pad_index = vocab[\"<pad>\"]\n","\n","vocab.set_default_index(unk_index)"]},{"cell_type":"markdown","metadata":{},"source":["## 1-4. Numericalize Text"]},{"cell_type":"code","execution_count":78,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T04:41:08.959882Z","iopub.status.busy":"2024-05-09T04:41:08.958858Z","iopub.status.idle":"2024-05-09T04:41:08.964755Z","shell.execute_reply":"2024-05-09T04:41:08.963746Z","shell.execute_reply.started":"2024-05-09T04:41:08.959844Z"},"trusted":true},"outputs":[],"source":["def numericalize_example(example, vocab):\n","    ids = vocab.lookup_indices(example[\"tokens\"])\n","    return {\"ids\": ids}"]},{"cell_type":"code","execution_count":79,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T04:41:09.115654Z","iopub.status.busy":"2024-05-09T04:41:09.115293Z","iopub.status.idle":"2024-05-09T04:42:03.364867Z","shell.execute_reply":"2024-05-09T04:42:03.363650Z","shell.execute_reply.started":"2024-05-09T04:41:09.115628Z"},"trusted":true},"outputs":[],"source":["train_data = train_data.map(numericalize_example, fn_kwargs={\"vocab\": vocab})\n","test_data = test_data.map(numericalize_example, fn_kwargs={\"vocab\": vocab})"]},{"cell_type":"code","execution_count":80,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T04:44:34.503457Z","iopub.status.busy":"2024-05-09T04:44:34.502345Z","iopub.status.idle":"2024-05-09T04:44:34.511254Z","shell.execute_reply":"2024-05-09T04:44:34.510035Z","shell.execute_reply.started":"2024-05-09T04:44:34.503402Z"},"trusted":true},"outputs":[],"source":["train_data = train_data.with_format(type=\"torch\", columns=[\"ids\", \"label\", \"length\"])\n","test_data = test_data.with_format(type=\"torch\", columns=[\"ids\", \"label\", \"length\"])"]},{"cell_type":"markdown","metadata":{},"source":["## 1-5. Word Embedding"]},{"cell_type":"code","execution_count":81,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T04:47:01.763729Z","iopub.status.busy":"2024-05-09T04:47:01.763352Z","iopub.status.idle":"2024-05-09T05:01:19.461687Z","shell.execute_reply":"2024-05-09T05:01:19.457096Z","shell.execute_reply.started":"2024-05-09T04:47:01.763701Z"},"trusted":true},"outputs":[],"source":["if not os.path.exists(pretrained_embedding_dir):\n","    vectors = torchtext.vocab.GloVe()\n","    pretrained_embedding = vectors.get_vecs_by_tokens(vocab.get_itos())\n","    torch.save(pretrained_embedding, pretrained_embedding_dir)\n","else:\n","    pretrained_embedding = torch.load(pretrained_embedding_dir)"]},{"cell_type":"markdown","metadata":{},"source":["## 1-6. Prepare for Data Loading"]},{"cell_type":"code","execution_count":82,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T06:32:36.896177Z","iopub.status.busy":"2024-05-09T06:32:36.894792Z","iopub.status.idle":"2024-05-09T06:32:36.902278Z","shell.execute_reply":"2024-05-09T06:32:36.901112Z","shell.execute_reply.started":"2024-05-09T06:32:36.896132Z"},"trusted":true},"outputs":[],"source":["class CustomDataset(Dataset):\n","    def __init__(self, data):\n","        self.data = data\n","    \n","    def __len__(self):\n","        return len(self.data)\n","    \n","    def __getitem__(self, idx):\n","        item = self.data[idx]\n","        return item"]},{"cell_type":"code","execution_count":83,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T06:32:37.040510Z","iopub.status.busy":"2024-05-09T06:32:37.040090Z","iopub.status.idle":"2024-05-09T06:32:37.046037Z","shell.execute_reply":"2024-05-09T06:32:37.044861Z","shell.execute_reply.started":"2024-05-09T06:32:37.040475Z"},"trusted":true},"outputs":[],"source":["train_dataset = CustomDataset(train_data)\n","test_dataset = CustomDataset(test_data)"]},{"cell_type":"code","execution_count":84,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T06:32:37.192543Z","iopub.status.busy":"2024-05-09T06:32:37.191817Z","iopub.status.idle":"2024-05-09T06:32:37.198607Z","shell.execute_reply":"2024-05-09T06:32:37.197333Z","shell.execute_reply.started":"2024-05-09T06:32:37.192501Z"},"trusted":true},"outputs":[],"source":["def custom_collate_fn(batch):\n","    \n","    batch_inputs = [sample['ids'] for sample in batch]\n","    batch_labels = [sample['label'] for sample in batch]\n","    \n","    collate_inputs = pad_sequence(batch_inputs, \n","                                  padding_value = pad_index, \n","                                  batch_first = True)\n","    collate_labels = torch.tensor(batch_labels)\n","    \n","    return collate_inputs, collate_labels"]},{"cell_type":"code","execution_count":85,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T06:32:37.329915Z","iopub.status.busy":"2024-05-09T06:32:37.328765Z","iopub.status.idle":"2024-05-09T06:32:37.336910Z","shell.execute_reply":"2024-05-09T06:32:37.335768Z","shell.execute_reply.started":"2024-05-09T06:32:37.329870Z"},"trusted":true},"outputs":[],"source":["batch_size = 128\n","pad_index = pad_index\n","shuffle = True\n","\n","trainloader = DataLoader(dataset = train_dataset,\n","                         batch_size = batch_size,\n","                         collate_fn = custom_collate_fn,\n","                         shuffle = shuffle)\n","testloader = DataLoader(dataset = test_dataset,\n","                         batch_size = batch_size,\n","                         collate_fn = custom_collate_fn,\n","                         shuffle = shuffle)"]},{"cell_type":"markdown","metadata":{},"source":["# 2. Define Model"]},{"cell_type":"markdown","metadata":{},"source":["## 2-1. Model Structure"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class CustomLSTMCell(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, bias = True):\n","        super().__init__()\n","        self.input_dim = input_dim\n","        self.hidden_dim = hidden_dim\n","        self.bias = bias\n","\n","        self.Wi = nn.Linear(input_dim + hidden_dim, hidden_dim, bias = bias)\n","        self.Wf = nn.Linear(input_dim + hidden_dim, hidden_dim, bias = bias)\n","        self.Wo = nn.Linear(input_dim + hidden_dim, hidden_dim, bias = bias)\n","        self.Wh = nn.Linear(input_dim + hidden_dim, hidden_dim, bias = bias)\n","        \n","    def forward(self, input, hidden):\n","        h, c = hidden\n","        concat_ih = torch.cat((input, h), 1)\n","\n","        input_gate = F.sigmoid(self.Wi(concat_ih))\n","        forget_gate = F.sigmoid(self.Wf(concat_ih))\n","        output_gate = F.sigmoid(self.Wo(concat_ih))\n","        cell_gate = F.tanh(self.Wh(concat_ih))\n","\n","        c_new = forget_gate * c + input_gate * cell_gate\n","        h_new = output_gate * F.tanh(c)\n","\n","        return h_new, c_new"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class CustomLSTM(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, num_layers):\n","        super().__init__()\n","        self.hidden_dim = hidden_dim\n","        self.num_layers = num_layers\n","        self.Layers = nn.ModuleList([CustomLSTMCell(input_dim, hidden_dim)])\n","        for _ in range(1, num_layers):\n","            self.Layers.append(CustomLSTMCell(hidden_dim, hidden_dim))\n","\n","    def forward(self, inputs, hidden):\n","        \n","        batch_size = inputs.size(0)\n","        seq_length = inputs.size(1)\n","\n","        h0, c0 = hidden\n","\n","        output_h = torch.zeros(self.num_layers, batch_size, seq_length, self.hidden_dim).to(device)\n","        output_c = torch.zeros(self.num_layers, batch_size, seq_length, self.hidden_dim).to(device)\n","\n","        for layer_idx, layer in enumerate(self.Layers):\n","\n","            if layer_idx == 0:\n","                layer_inputs = inputs\n","            else:\n","                layer_inputs = output_h[layer_idx - 1, :, :, :]\n","            \n","            h , c = h0[layer_idx, : :], c0[layer_idx, : :]\n","            for t in range(seq_length):\n","                h, c = layer(layer_inputs[:, t, :], (h, c))\n","                output_h[layer_idx, :, t, :] = h\n","                output_c[layer_idx, :, t, :] = c\n","\n","        return output_h[-1, :, :, :], (output_h[:, :, -1, :], output_c[:, :, -1, :])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class CustomLSTMClassifier(nn.Module):\n","    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, num_layers, pad_index):\n","        super().__init__()\n","        self.embedding_dim = embedding_dim\n","        self.hidden_dim = hidden_dim\n","        self.output_dim = output_dim\n","        self.num_layers = num_layers\n","        \n","        self.embedding = nn.Embedding(input_dim, embedding_dim, padding_idx = pad_index)\n","        self.embedding.requires_grad_(False)\n","        \n","        self.lstm = CustomLSTM(embedding_dim, hidden_dim, num_layers)\n","\n","        self.fc = nn.Linear(hidden_dim, output_dim)\n","\n","    def forward(self, inputs):\n","\n","        batch_size = inputs.size(0)\n","        seq_length = inputs.size(1)\n","\n","        x = self.embedding(inputs)\n","\n","        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(device)\n","        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(device)\n","\n","        output, (h, c) = self.lstm(x, (h0, c0))\n","\n","        logit = self.fc(h[-1, :, :])\n","\n","        return logit"]},{"cell_type":"code","execution_count":86,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T06:33:20.862529Z","iopub.status.busy":"2024-05-09T06:33:20.862120Z","iopub.status.idle":"2024-05-09T06:33:20.873691Z","shell.execute_reply":"2024-05-09T06:33:20.872514Z","shell.execute_reply.started":"2024-05-09T06:33:20.862497Z"},"trusted":true},"outputs":[],"source":["class DeepLSTM(nn.Module):\n","    def __init__(self, input_dim, embedding_dim, hidden_dim, num_layers, output_dim, pad_index):\n","        super().__init__()\n","        self.embedding_dim = embedding_dim\n","        self.hidden_dim = hidden_dim\n","        self.num_layers = num_layers\n","        self.output_dim = output_dim\n","        \n","        self.embedding = nn.Embedding(input_dim, embedding_dim, padding_idx = pad_index)\n","        self.embedding.requires_grad_(False)\n","\n","        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first = True)\n","\n","        self.fc = nn.Linear(hidden_dim, output_dim)\n","\n","    def forward(self, inputs):\n","\n","        batch_size = inputs.size(0)\n","        seq_length = inputs.size(1)\n","\n","        x = self.embedding(inputs)\n","            \n","        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(device)\n","        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim).to(device)\n","        hidden = (h0, c0)\n","\n","        output, (h, c) = self.lstm(x, hidden)\n","\n","        logit = self.fc(h[-1, :, :])\n","\n","        return logit"]},{"cell_type":"markdown","metadata":{},"source":["## 2-2. Hyperparameter & functions"]},{"cell_type":"code","execution_count":87,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T06:33:21.025116Z","iopub.status.busy":"2024-05-09T06:33:21.024663Z","iopub.status.idle":"2024-05-09T06:33:21.111777Z","shell.execute_reply":"2024-05-09T06:33:21.110479Z","shell.execute_reply.started":"2024-05-09T06:33:21.025080Z"},"trusted":true},"outputs":[],"source":["vocab_size = len(vocab)\n","embedding_dim = 300\n","hidden_dim = 128\n","num_layers = 3\n","output_dim = 1\n","pad_index = pad_index\n","lr = 5e-4\n","\n","model = DeepLSTM(vocab_size, embedding_dim, hidden_dim, num_layers, output_dim, pad_index)\n","\n","criterion = nn.BCEWithLogitsLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=lr)"]},{"cell_type":"markdown","metadata":{},"source":["## 2-3. Weight Initialization"]},{"cell_type":"code","execution_count":88,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T06:33:21.345375Z","iopub.status.busy":"2024-05-09T06:33:21.344933Z","iopub.status.idle":"2024-05-09T06:33:21.352661Z","shell.execute_reply":"2024-05-09T06:33:21.351278Z","shell.execute_reply.started":"2024-05-09T06:33:21.345343Z"},"trusted":true},"outputs":[],"source":["def initialize_weights(m):\n","    if isinstance(m, nn.Linear):\n","        nn.init.xavier_normal_(m.weight)\n","        nn.init.zeros_(m.bias)\n","    elif isinstance(m, nn.LSTM):\n","        for name, param in m.named_parameters():\n","            if \"bias\" in name:\n","                nn.init.zeros_(param)\n","            else:\n","                nn.init.orthogonal_(param)"]},{"cell_type":"code","execution_count":89,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T06:33:21.522657Z","iopub.status.busy":"2024-05-09T06:33:21.522278Z","iopub.status.idle":"2024-05-09T06:33:21.532722Z","shell.execute_reply":"2024-05-09T06:33:21.531867Z","shell.execute_reply.started":"2024-05-09T06:33:21.522629Z"},"trusted":true},"outputs":[{"data":{"text/plain":["DeepLSTM(\n","  (embedding): Embedding(24897, 300, padding_idx=1)\n","  (lstm): LSTM(300, 128, num_layers=3, batch_first=True)\n","  (fc): Linear(in_features=128, out_features=1, bias=True)\n",")"]},"execution_count":89,"metadata":{},"output_type":"execute_result"}],"source":["model.apply(initialize_weights)"]},{"cell_type":"code","execution_count":90,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T06:33:21.675452Z","iopub.status.busy":"2024-05-09T06:33:21.674714Z","iopub.status.idle":"2024-05-09T06:33:21.679695Z","shell.execute_reply":"2024-05-09T06:33:21.678909Z","shell.execute_reply.started":"2024-05-09T06:33:21.675417Z"},"trusted":true},"outputs":[],"source":["model.embedding.weight.data = pretrained_embedding"]},{"cell_type":"code","execution_count":91,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\"Model's state_dict:\"\n","Parameter name: embedding.weight\n","    Size : torch.Size([24897, 300])\n","    Value: Parameter containing:\n","tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n","        [ 0.2720, -0.0620, -0.1884,  ...,  0.1302, -0.1832,  0.1323],\n","        ...,\n","        [ 0.6701, -0.2717,  0.4766,  ...,  0.2786,  0.3312,  0.0230],\n","        [-0.1503,  0.5624, -0.5622,  ..., -0.4224, -0.6836,  0.0726],\n","        [ 1.1741, -0.4386,  0.3310,  ...,  0.3193, -0.2292, -0.0887]])\n","Parameter name: lstm.weight_ih_l0\n","    Size : torch.Size([512, 300])\n","    Value: Parameter containing:\n","tensor([[ 0.0368,  0.0056,  0.0037,  ..., -0.0523, -0.0331, -0.0096],\n","        [ 0.0420,  0.0362,  0.0005,  ..., -0.0153, -0.0853, -0.0116],\n","        [-0.0242,  0.0780,  0.0058,  ...,  0.0269, -0.0336,  0.0658],\n","        ...,\n","        [ 0.0519, -0.0377, -0.0782,  ...,  0.0321, -0.0625, -0.0284],\n","        [ 0.0116, -0.0343, -0.0144,  ..., -0.0320,  0.0377,  0.0200],\n","        [-0.0151, -0.0376, -0.0213,  ...,  0.0197,  0.0447,  0.0062]],\n","       requires_grad=True)\n","Parameter name: lstm.weight_hh_l0\n","    Size : torch.Size([512, 128])\n","    Value: Parameter containing:\n","tensor([[-0.0617,  0.0146, -0.0440,  ..., -0.0346,  0.0601,  0.0536],\n","        [ 0.0405,  0.0052,  0.0171,  ..., -0.0643, -0.0292, -0.0028],\n","        [ 0.0304,  0.0144, -0.0132,  ..., -0.0149,  0.0305, -0.0119],\n","        ...,\n","        [-0.0475,  0.0638, -0.0431,  ...,  0.0019, -0.0949,  0.0148],\n","        [-0.0303, -0.0189, -0.0196,  ...,  0.0106,  0.0295, -0.0660],\n","        [ 0.0207,  0.0643, -0.0553,  ..., -0.0276,  0.0568,  0.0147]],\n","       requires_grad=True)\n","Parameter name: lstm.bias_ih_l0\n","    Size : torch.Size([512])\n","    Value: Parameter containing:\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n","Parameter name: lstm.bias_hh_l0\n","    Size : torch.Size([512])\n","    Value: Parameter containing:\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n","Parameter name: lstm.weight_ih_l1\n","    Size : torch.Size([512, 128])\n","    Value: Parameter containing:\n","tensor([[-0.0155, -0.0009, -0.0214,  ..., -0.0429, -0.0213, -0.0477],\n","        [ 0.1079,  0.0846, -0.0513,  ...,  0.0667,  0.0149,  0.0257],\n","        [-0.0146, -0.0455,  0.0466,  ...,  0.0351, -0.0027, -0.0568],\n","        ...,\n","        [-0.0306, -0.0307,  0.0049,  ...,  0.1225,  0.1093,  0.0216],\n","        [ 0.0661, -0.0738,  0.0347,  ...,  0.0002, -0.0042, -0.0078],\n","        [-0.0581, -0.0325,  0.0291,  ..., -0.0463,  0.0051, -0.0118]],\n","       requires_grad=True)\n","Parameter name: lstm.weight_hh_l1\n","    Size : torch.Size([512, 128])\n","    Value: Parameter containing:\n","tensor([[-0.0276, -0.0515,  0.0268,  ..., -0.0130, -0.0725, -0.0526],\n","        [ 0.0433,  0.0490, -0.0328,  ...,  0.0332, -0.0360,  0.0473],\n","        [ 0.0535,  0.0124, -0.0151,  ..., -0.0108,  0.0326, -0.0170],\n","        ...,\n","        [ 0.0342,  0.0091,  0.1183,  ..., -0.0291, -0.0755, -0.0257],\n","        [ 0.0171, -0.0371, -0.0737,  ...,  0.0290,  0.0562, -0.0518],\n","        [ 0.0582,  0.0049,  0.0642,  ...,  0.0027, -0.0500, -0.0701]],\n","       requires_grad=True)\n","Parameter name: lstm.bias_ih_l1\n","    Size : torch.Size([512])\n","    Value: Parameter containing:\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n","Parameter name: lstm.bias_hh_l1\n","    Size : torch.Size([512])\n","    Value: Parameter containing:\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n","Parameter name: lstm.weight_ih_l2\n","    Size : torch.Size([512, 128])\n","    Value: Parameter containing:\n","tensor([[ 0.0867, -0.0256,  0.0630,  ..., -0.0689, -0.0339,  0.0573],\n","        [ 0.0167,  0.0862,  0.0967,  ...,  0.0067,  0.0086,  0.0182],\n","        [-0.0276,  0.0946, -0.0070,  ...,  0.0388,  0.0279,  0.0073],\n","        ...,\n","        [ 0.0432,  0.0212,  0.0082,  ...,  0.0026, -0.0576, -0.0100],\n","        [-0.0501, -0.0176, -0.0051,  ..., -0.0183, -0.0218,  0.0403],\n","        [-0.0101, -0.0446,  0.0800,  ...,  0.0193, -0.0171, -0.0216]],\n","       requires_grad=True)\n","Parameter name: lstm.weight_hh_l2\n","    Size : torch.Size([512, 128])\n","    Value: Parameter containing:\n","tensor([[ 0.0060, -0.0164,  0.0102,  ...,  0.0121,  0.0564, -0.0168],\n","        [ 0.0200, -0.0372,  0.0695,  ...,  0.0049, -0.0650, -0.0882],\n","        [-0.0056,  0.0255,  0.0182,  ..., -0.0171,  0.0378, -0.0284],\n","        ...,\n","        [ 0.0363, -0.0210, -0.0077,  ...,  0.0848,  0.0143, -0.0093],\n","        [-0.0463, -0.0407,  0.0485,  ..., -0.0701,  0.0566, -0.0362],\n","        [ 0.0270,  0.0134, -0.0607,  ..., -0.0182,  0.0003, -0.0014]],\n","       requires_grad=True)\n","Parameter name: lstm.bias_ih_l2\n","    Size : torch.Size([512])\n","    Value: Parameter containing:\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n","Parameter name: lstm.bias_hh_l2\n","    Size : torch.Size([512])\n","    Value: Parameter containing:\n","tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","        0., 0., 0., 0., 0., 0., 0., 0.], requires_grad=True)\n","Parameter name: fc.weight\n","    Size : torch.Size([1, 128])\n","    Value: Parameter containing:\n","tensor([[-7.6929e-02, -2.1156e-01,  1.5072e-04,  1.9915e-02,  1.1800e-02,\n","          5.0222e-02,  4.1316e-02, -1.1877e-02,  1.8188e-01,  1.0071e-01,\n","         -1.1977e-01,  6.3903e-02, -2.2823e-01,  2.4347e-02,  6.6348e-02,\n","          1.6156e-02,  1.5755e-01, -1.5379e-02, -1.5172e-01,  4.6583e-03,\n","          1.0172e-01, -5.2060e-02, -2.9247e-02, -8.9301e-03,  5.4856e-02,\n","          4.0436e-03, -1.0743e-02, -6.0682e-04,  2.3474e-01, -2.4618e-02,\n","          7.8669e-02, -1.8598e-01,  6.4569e-02,  1.7027e-01,  1.1949e-01,\n","         -1.9564e-01,  1.0887e-01, -3.8236e-02, -3.0005e-02,  2.7469e-03,\n","          3.0671e-01,  4.4734e-02, -3.0449e-02, -2.5363e-01, -8.4518e-02,\n","         -1.6206e-01, -2.1237e-01, -1.5492e-01,  1.0208e-01, -3.2947e-02,\n","         -7.1255e-02,  1.6063e-01,  1.4028e-03, -1.2662e-01, -1.1264e-01,\n","         -3.0966e-02,  5.7335e-02, -6.9795e-02, -1.5513e-01,  2.4264e-01,\n","         -6.3438e-02, -1.4687e-02, -1.5656e-01, -5.2505e-02,  4.0689e-02,\n","         -8.2726e-02, -2.4630e-01,  1.3285e-02,  3.6990e-03, -2.2100e-01,\n","          2.5545e-01, -8.8833e-02, -3.3488e-01,  2.0822e-03, -1.8097e-02,\n","         -5.9194e-02, -3.1604e-02,  5.5281e-02,  3.9390e-02,  1.6193e-01,\n","         -4.0894e-02, -2.6137e-01,  9.0021e-02,  7.4246e-02, -9.0768e-03,\n","          4.7818e-02,  2.4571e-02,  2.3505e-01,  1.5073e-03, -7.5566e-02,\n","          1.4280e-01,  4.1108e-03, -1.5054e-01, -1.3298e-01,  1.2219e-01,\n","          1.2315e-01, -4.1589e-02,  1.5927e-02, -4.1088e-02,  9.8522e-02,\n","         -2.2930e-01, -4.7939e-02, -1.9997e-02, -1.1294e-01, -1.0331e-01,\n","          1.1551e-01, -2.6731e-01, -1.0342e-01,  1.6694e-01, -1.6172e-01,\n","         -5.5629e-02, -8.5709e-02,  4.9630e-03,  8.6126e-02, -8.7365e-03,\n","         -1.8140e-02, -8.0779e-02,  1.4451e-01,  7.3204e-02,  4.1572e-02,\n","         -5.9141e-02, -3.5200e-02,  1.8438e-01,  2.2416e-02,  1.1733e-01,\n","          4.1683e-02, -5.7450e-02,  1.4942e-01]], requires_grad=True)\n","Parameter name: fc.bias\n","    Size : torch.Size([1])\n","    Value: Parameter containing:\n","tensor([0.], requires_grad=True)\n"]}],"source":["pprint(\"Model's state_dict:\")\n","for name, param in model.named_parameters():\n","    print(f\"Parameter name: {name}\")\n","    print(f\"    Size : {param.size()}\")\n","    print(f\"    Value: {param}\")"]},{"cell_type":"code","execution_count":92,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T06:33:21.189251Z","iopub.status.busy":"2024-05-09T06:33:21.188799Z","iopub.status.idle":"2024-05-09T06:33:21.194891Z","shell.execute_reply":"2024-05-09T06:33:21.193696Z","shell.execute_reply.started":"2024-05-09T06:33:21.189216Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["The model has 484,481 trainable parameters\n"]}],"source":["def count_parameters(model):\n","    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n","\n","\n","print(f\"The model has {count_parameters(model):,} trainable parameters\")"]},{"cell_type":"code","execution_count":93,"metadata":{},"outputs":[{"data":{"text/plain":["BCEWithLogitsLoss()"]},"execution_count":93,"metadata":{},"output_type":"execute_result"}],"source":["model.to(device)\n","criterion.to(device)"]},{"cell_type":"markdown","metadata":{},"source":["# 3. Train Model"]},{"cell_type":"code","execution_count":95,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T06:33:22.006416Z","iopub.status.busy":"2024-05-09T06:33:22.005155Z","iopub.status.idle":"2024-05-09T06:33:22.014644Z","shell.execute_reply":"2024-05-09T06:33:22.013435Z","shell.execute_reply.started":"2024-05-09T06:33:22.006378Z"},"trusted":true},"outputs":[],"source":["def train_model(model, criterion, optimizer, trainloader, num_epochs):\n","    print(\"-----Training Started------\")\n","    for epoch in range(num_epochs):\n","        \n","        model.train()\n","        \n","        running_loss = 0.0\n","        \n","        for inputs, labels in tqdm(trainloader):\n","            \n","            inputs, labels = inputs.to(device), labels.to(device)\n","            \n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            loss = criterion(outputs.view(-1), labels.float())\n","            loss.backward()\n","            optimizer.step()\n","\n","            running_loss += loss.item() * inputs.size(0)\n","\n","        epoch_loss = running_loss / len(trainloader.dataset)\n","        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss: .4f}\")\n","\n","        torch.save(model.state_dict(), model_dir)\n","    \n","    print(\"-----Training Completed-----\")"]},{"cell_type":"code","execution_count":96,"metadata":{"execution":{"iopub.execute_input":"2024-05-09T06:33:22.183260Z","iopub.status.busy":"2024-05-09T06:33:22.182381Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["-----Training Started------\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 196/196 [00:12<00:00, 15.16it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [1/16], Loss:  0.6876\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 196/196 [00:12<00:00, 15.13it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [2/16], Loss:  0.6897\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 196/196 [00:11<00:00, 17.51it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [3/16], Loss:  0.6943\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 196/196 [00:10<00:00, 18.93it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [4/16], Loss:  0.6911\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 196/196 [00:10<00:00, 18.94it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [5/16], Loss:  0.6885\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 196/196 [00:10<00:00, 18.94it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [6/16], Loss:  0.6927\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 196/196 [00:10<00:00, 18.98it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [7/16], Loss:  0.6915\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 196/196 [00:10<00:00, 18.87it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [8/16], Loss:  0.6859\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 196/196 [00:10<00:00, 18.93it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [9/16], Loss:  0.6873\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 196/196 [00:10<00:00, 18.97it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [10/16], Loss:  0.6629\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 196/196 [00:10<00:00, 18.90it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [11/16], Loss:  0.6674\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 196/196 [00:10<00:00, 18.99it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [12/16], Loss:  0.6939\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 196/196 [00:10<00:00, 18.75it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [13/16], Loss:  0.6893\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 196/196 [00:10<00:00, 18.97it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [14/16], Loss:  0.6780\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 196/196 [00:10<00:00, 18.99it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Epoch [15/16], Loss:  0.6579\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 196/196 [00:10<00:00, 19.03it/s]"]},{"name":"stdout","output_type":"stream","text":["Epoch [16/16], Loss:  0.6971\n","-----Training Completed-----\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["num_epochs = 16\n","\n","train_model(model, criterion, optimizer, trainloader, num_epochs)"]},{"cell_type":"markdown","metadata":{},"source":["# 4. Test"]},{"cell_type":"code","execution_count":97,"metadata":{},"outputs":[],"source":["def test_model(model, testloader):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    TP = 0  # True Positives\n","    TN = 0  # True Negatives\n","    FP = 0  # False Positives\n","    FN = 0  # False Negatives\n","\n","    with torch.no_grad():\n","        for inputs, labels in testloader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            outputs = model(inputs)\n","            predictions = torch.round(F.sigmoid(outputs))\n","            total += labels.size(0)\n","\n","            predictions, labels = predictions.view(-1).cpu(), labels.cpu()\n","            \n","            correct += (predictions == labels).sum().item()\n","\n","            TP += ((predictions == 1) & (labels == 1)).sum().item()\n","            TN += ((predictions == 0) & (labels == 0)).sum().item()\n","            FP += ((predictions == 1) & (labels == 0)).sum().item()\n","            FN += ((predictions == 0) & (labels == 1)).sum().item()\n","\n","    accuracy = correct / total\n","    precision = TP / (TP + FP) if TP + FP != 0 else 0\n","    recall = TP / (TP + FN) if TP + FN != 0 else 0\n","    f1 = 2 * (precision * recall) / (precision + recall) if precision + recall != 0 else 0\n","\n","    print(f\"Accuracy on test set: {accuracy:.4f}\")\n","    print(f\"Precision on test set: {precision:.4f}\")\n","    print(f\"Recall on test set: {recall:.4f}\")\n","    print(f\"F1 Score on test set: {f1:.4f}\")\n"]},{"cell_type":"code","execution_count":98,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["DeepLSTM(\n","  (embedding): Embedding(24897, 300, padding_idx=1)\n","  (lstm): LSTM(300, 128, num_layers=3, batch_first=True)\n","  (fc): Linear(in_features=128, out_features=1, bias=True)\n",")"]},"execution_count":98,"metadata":{},"output_type":"execute_result"}],"source":["model.load_state_dict(torch.load(model_dir))\n","model.to(device)"]},{"cell_type":"code","execution_count":99,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy on test set: 0.5515\n","Precision on test set: 0.5359\n","Recall on test set: 0.7685\n","F1 Score on test set: 0.6315\n"]}],"source":["test_model(model, testloader)"]},{"cell_type":"markdown","metadata":{},"source":["# 5. Inference"]},{"cell_type":"code","execution_count":100,"metadata":{},"outputs":[],"source":["def inference(text, model, tokenizer, vocab):\n","    tokens = tokenizer(text)\n","    ids = vocab.lookup_indices(tokens)\n","    tensor = torch.LongTensor(ids).unsqueeze(dim=0).to(device)\n","\n","    output = model(tensor)\n","\n","    prediction = torch.round(F.sigmoid(output))\n","\n","    return prediction"]},{"cell_type":"code","execution_count":101,"metadata":{},"outputs":[{"data":{"text/plain":["DeepLSTM(\n","  (embedding): Embedding(24897, 300, padding_idx=1)\n","  (lstm): LSTM(300, 128, num_layers=3, batch_first=True)\n","  (fc): Linear(in_features=128, out_features=1, bias=True)\n",")"]},"execution_count":101,"metadata":{},"output_type":"execute_result"}],"source":["model.load_state_dict(torch.load(model_dir))\n","model.to(device)"]},{"cell_type":"code","execution_count":102,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.0\n"]}],"source":["text = 'This film is terrible!'\n","\n","prediction = inference(text, model, tokenizer, vocab)\n","\n","print(prediction.item())"]},{"cell_type":"code","execution_count":103,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.0\n"]}],"source":["text = 'This film is great!'\n","\n","prediction = inference(text, model, tokenizer, vocab)\n","\n","print(prediction.item())"]},{"cell_type":"code","execution_count":104,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.0\n"]}],"source":["text = 'The best film I have ever seen!'\n","\n","prediction = inference(text, model, tokenizer, vocab)\n","\n","print(prediction.item())"]},{"cell_type":"code","execution_count":105,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.0\n"]}],"source":["text = \"This film is not terrible, it's great!\"\n","\n","prediction = inference(text, model, tokenizer, vocab)\n","\n","print(prediction.item())"]},{"cell_type":"markdown","metadata":{},"source":["# 6. Visualize Results"]},{"cell_type":"markdown","metadata":{},"source":["# Limitation\n","\n","padding 토큰 연산 제외 / dropout / validation"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30698,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
